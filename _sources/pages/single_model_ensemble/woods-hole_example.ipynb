{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0294a2d1-ac11-44c6-8d4c-f09066b4ce27",
   "metadata": {},
   "source": [
    "# Example\n",
    "In this example, we'll use CESM1-LE to diagnose the forced response to external forcing near Woods Hole.  \n",
    "{download}`Download notebook<./woods-hole_example.ipynb>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ea7642-50d7-4e56-b847-f9d0af63f9b5",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daaf53e-f603-40ac-b7a6-968a9eef13dc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import cmocean\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.ticker as mticker\n",
    "import copy\n",
    "import pandas as pd\n",
    "import time\n",
    "import intake\n",
    "import xesmf as xe\n",
    "\n",
    "## (optional) remove gridlines from plots\n",
    "sns.set(rc={\"axes.facecolor\": \"white\", \"axes.grid\": False})\n",
    "\n",
    "## should we save figs?\n",
    "SAVE_FIGS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de6686d-1f50-4cd2-99e3-ec18c930e6c0",
   "metadata": {},
   "source": [
    "## Misc. functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ad8ace-6902-4bb7-8b3d-ea4c19d33506",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_setup(fig, projection, lon_range, lat_range, xticks=None, yticks=None):\n",
    "    \"\"\"Add a subplot to the figure with the given map projection\n",
    "    and lon/lat range. Returns an Axes object.\"\"\"\n",
    "\n",
    "    ## increase resolution for projection\n",
    "    ## (otherwise lines plotted on surface won't follow curved trajectories)\n",
    "    projection.threshold /= 1000\n",
    "\n",
    "    ## Create subplot with given projection\n",
    "    ax = fig.add_subplot(projection=projection)\n",
    "\n",
    "    ## Subset to given region\n",
    "    extent = [*lon_range, *lat_range]\n",
    "    ax.set_extent(extent, crs=ccrs.PlateCarree())\n",
    "\n",
    "    ## draw coastlines\n",
    "    ax.coastlines(linewidths=0.5)\n",
    "\n",
    "    ## add tick labels\n",
    "    if xticks is not None:\n",
    "\n",
    "        ## add lon/lat labels\n",
    "        gl = ax.gridlines(\n",
    "            draw_labels=True,\n",
    "            linestyle=\"-\",\n",
    "            alpha=0.1,\n",
    "            linewidth=0.5,\n",
    "            color=\"k\",\n",
    "            zorder=1.05,\n",
    "        )\n",
    "\n",
    "        ## specify which axes to label\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "\n",
    "        ## specify ticks\n",
    "        gl.ylocator = mticker.FixedLocator(yticks)\n",
    "        gl.xlocator = mticker.FixedLocator(xticks)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_box_outline(ax, lon_range, lat_range, c=\"k\"):\n",
    "    \"\"\"\n",
    "    Plot box outlining the specifed lon/lat range on given\n",
    "    ax object.\n",
    "    \"\"\"\n",
    "\n",
    "    ## get width and height\n",
    "    height = lat_range[1] - lat_range[0]\n",
    "    width = lon_range[1] - lon_range[0]\n",
    "\n",
    "    ## add rectangle to plot\n",
    "    ax.add_patch(\n",
    "        mpatches.Rectangle(\n",
    "            xy=[lon_range[0], lat_range[0]],\n",
    "            height=height,\n",
    "            width=width,\n",
    "            transform=ccrs.PlateCarree(),\n",
    "            facecolor=\"none\",\n",
    "            edgecolor=c,\n",
    "            linewidth=1,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_setup_woodshole(fig):\n",
    "    \"\"\"Plot zoomed-in view of Woods Hole\"\"\"\n",
    "\n",
    "    ## adjust figure size\n",
    "    fig.set_size_inches(5, 3)\n",
    "\n",
    "    ## set map projection to orthographic\n",
    "    proj = ccrs.Orthographic(central_longitude=-67.5, central_latitude=40)\n",
    "\n",
    "    ## Get ax object based on generic plotting function\n",
    "    ax = plot_setup(\n",
    "        fig,\n",
    "        proj,\n",
    "        lon_range=[-80, -60],\n",
    "        lat_range=[35, 45],\n",
    "        xticks=[-80, -70, -60],\n",
    "        yticks=[35, 40, 45],\n",
    "    )\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def make_cb_range(amp, delta):\n",
    "    \"\"\"Make colorbar_range for cmo.balance\n",
    "    Args:\n",
    "        - 'amp': amplitude of maximum value for colorbar\n",
    "        - 'delta': increment for colorbar\n",
    "    \"\"\"\n",
    "    return np.concatenate(\n",
    "        [np.arange(-amp, 0, delta), np.arange(delta, amp + delta, delta)]\n",
    "    )\n",
    "\n",
    "\n",
    "def get_empirical_pdf(x, bin_edges=None):\n",
    "    \"\"\"\n",
    "    Estimate the \"empirical\" probability distribution function for the data x.\n",
    "    In this case the result is a normalized histogram,\n",
    "    Normalized means that integrating over the histogram yields 1.\n",
    "    Returns the PDF (normalized histogram) and edges of the histogram bins\n",
    "    \"\"\"\n",
    "\n",
    "    ## compute histogram\n",
    "    if bin_edges is None:\n",
    "        hist, bin_edges = np.histogram(x)\n",
    "\n",
    "    else:\n",
    "        hist, _ = np.histogram(x, bins=bin_edges)\n",
    "\n",
    "    ## normalize to a probability distribution (PDF)\n",
    "    bin_width = bin_edges[1:] - bin_edges[:-1]\n",
    "    pdf = hist / (hist * bin_width).sum()\n",
    "\n",
    "    return pdf, bin_edges\n",
    "\n",
    "\n",
    "def plot_quantiles(ax, x, label=None, month=None, time_dim=\"time\", **kwargs):\n",
    "    \"\"\"plot .1, .5, and .9 quantiles on given ax object\"\"\"\n",
    "\n",
    "    ## filter for month if specified\n",
    "    if month is not None:\n",
    "        x = x.sel(time=(x.time.dt.month == month))\n",
    "\n",
    "    ## compute quantiles\n",
    "    x_quantiles = x.quantile([0.1, 0.5, 0.9], dim=\"member_id\")\n",
    "\n",
    "    ## plot median\n",
    "    ax.plot(\n",
    "        x_quantiles[time_dim],\n",
    "        x_quantiles.sel(quantile=0.5),\n",
    "        lw=2,\n",
    "        label=label,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    ## plot upper/lower bounds\n",
    "    for q in [0.1, 0.9]:\n",
    "        ax.plot(\n",
    "            x_quantiles[time_dim],\n",
    "            x_quantiles.sel(quantile=q),\n",
    "            lw=1,\n",
    "            alpha=0.5,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333948ce-71b3-45c2-a758-89326cac7d36",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415ec868-d39b-42bb-b7aa-9cd8ac776067",
   "metadata": {},
   "source": [
    "### Data-loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed8c4db-51c4-4210-9adf-27530c92fdeb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def load_from_server_fn(\n",
    "    lens_fp, simulation_type, lon_range, lat_range, n_members=2, varname=\"SST\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Load ensemble data for CESM-LE from server.\n",
    "    Args:\n",
    "        - lens_fp: filepath to LENS data on CMIP server\n",
    "        - simulation type: either \"hist\" or \"rcp85\"\n",
    "        - n_members: number of ensemble members to load\n",
    "        - varname: one of \"SST\" or \"PSL\"\n",
    "    \"\"\"\n",
    "\n",
    "    ## get filename pattern\n",
    "    if simulation_type == \"historical\":\n",
    "        pattern = f\"*20TRC*.nc\"\n",
    "\n",
    "    elif simulation_type == \"future\":\n",
    "        pattern = f\"*RCP85*2006*.nc\"\n",
    "\n",
    "    else:\n",
    "        print(\"not a valid simulation type\")\n",
    "        return\n",
    "\n",
    "    ## get (sorted) list of files\n",
    "    files = pathlib.Path(lens_fp, varname).glob(pattern)\n",
    "    files = sorted(list(files))\n",
    "\n",
    "    ## get subset of files to load\n",
    "    files = files[:n_members]\n",
    "\n",
    "    ## open the data (but don't load to memory)\n",
    "    data = xr.open_mfdataset(\n",
    "        files,\n",
    "        concat_dim=\"member_id\",\n",
    "        decode_timedelta=True,\n",
    "        combine=\"nested\",\n",
    "        chunks=dict({\"time\": 1872}),\n",
    "        parallel=True,\n",
    "    )\n",
    "\n",
    "    ## trim in time (gets around NaN values)\n",
    "    data = data.sel(time=slice(\"1921\", \"2080\"))\n",
    "\n",
    "    ## drop vertical coord if it exists\n",
    "    if \"z_t\" in data.dims:\n",
    "        data = data.drop_vars(\"z_t\").squeeze()\n",
    "\n",
    "    ## rename TLONG/TLAT coords\n",
    "    if \"TLONG\" in data.coords:\n",
    "        data = data.rename({\"TLONG\": \"lon\", \"TLAT\": \"lat\"})\n",
    "\n",
    "    return data[varname]\n",
    "\n",
    "\n",
    "def load_from_cloud_fn(\n",
    "    simulation_type,\n",
    "    lon_range,\n",
    "    lat_range,\n",
    "    varname=\"TREFHT\",\n",
    "    n_members=2,\n",
    "):\n",
    "    \"\"\"Load CESM data from cloud. Args:\n",
    "    - simulation type: either \"historical\" or \"future\"\n",
    "    - preprocess_func: preprocessing function\n",
    "    - varname: variable to load (\"TREFHT\" is 2m-temperature)\n",
    "    - n_members: number of ensemble members to load\n",
    "    \"\"\"\n",
    "\n",
    "    ## get catalog of available data\n",
    "    catalog = intake.open_esm_datastore(\n",
    "        \"https://raw.githubusercontent.com/NCAR/cesm2-le-aws/main/intake-catalogs/aws-cesm2-le.json\"\n",
    "    )\n",
    "\n",
    "    ## subset for temperature data\n",
    "    ## to look at available data, use: catalog.df\n",
    "    catalog_subset = catalog.search(variable=varname, frequency=\"monthly\")\n",
    "\n",
    "    ## kwargs for opening data\n",
    "    kwargs = dict(\n",
    "        aggregate=True,\n",
    "        xarray_open_kwargs=dict(\n",
    "            engine=\"zarr\",\n",
    "            decode_timedelta=True,\n",
    "        ),\n",
    "        zarr_kwargs={\"consolidated\": True},\n",
    "        storage_options={\"anon\": True},\n",
    "    )\n",
    "\n",
    "    ## open data (but don't load to memory)\n",
    "    dsets = catalog_subset.to_dataset_dict(**kwargs)\n",
    "\n",
    "    ## load future or historical\n",
    "    if simulation_type == \"historical\":\n",
    "        data = dsets[\"atm.historical.monthly.cmip6\"]\n",
    "\n",
    "    elif simulation_type == \"future\":\n",
    "        data = dsets[\"atm.ssp370.monthly.cmip6\"]\n",
    "\n",
    "    else:\n",
    "        print(\"Not a valid simulation type\")\n",
    "\n",
    "    ## subset for ensemble members\n",
    "    data = data.isel(member_id=slice(None, n_members))\n",
    "\n",
    "    return data[varname]\n",
    "\n",
    "\n",
    "def load_datasets(\n",
    "    varname, lon_range, lat_range, lens_fp=None, load_from_cloud=True, n_members=2\n",
    "):\n",
    "    \"\"\"\n",
    "    Load historical and future datasets for specified variable.\n",
    "    Args:\n",
    "        - varname: name of variable to load\n",
    "        - lon_range, lat_range: 2-elements lists specifying bounds of region to load\n",
    "        - lens_fp: filepath to LENS directory on CMIP server (only required if using server)\n",
    "        - load_from_cloud: boolean specifying whether to load from cloud\n",
    "        - n_members: number of ensemble members to load\n",
    "    \"\"\"\n",
    "\n",
    "    ## dictionaries with arguments\n",
    "    kwargs = dict(\n",
    "        varname=varname, n_members=n_members, lon_range=lon_range, lat_range=lat_range\n",
    "    )\n",
    "\n",
    "    ## handle loading from cloud/server\n",
    "    if load_from_cloud:\n",
    "        load_fn = load_from_cloud_fn\n",
    "\n",
    "    else:\n",
    "        load_fn = load_from_server_fn\n",
    "        kwargs[\"lens_fp\"] = lens_fp\n",
    "\n",
    "    ## open the data\n",
    "    data_hist = load_fn(simulation_type=\"historical\", **kwargs)\n",
    "    data_fut = load_fn(simulation_type=\"future\", **kwargs)\n",
    "\n",
    "    ## Load LSM (for regridding)\n",
    "    lsm = load_lsm(lon_range=lon_range, lat_range=lat_range)\n",
    "    regridder = xe.Regridder(data_hist, lsm, \"bilinear\", ignore_degenerate=False)\n",
    "\n",
    "    ## do the regridding\n",
    "    data_hist = regridder(data_hist)\n",
    "    data_fut = regridder(data_fut)\n",
    "\n",
    "    return data_hist, data_fut\n",
    "\n",
    "\n",
    "def load_lsm(lon_range, lat_range):\n",
    "    \"\"\"Create mask from OISST data on cloud\"\"\"\n",
    "\n",
    "    ## load sst data\n",
    "    sst = xr.open_dataset(\n",
    "        r\"http://psl.noaa.gov/thredds/dodsC/Datasets/noaa.oisst.v2/new/sst.oisst.mon.ltm.1991-2020.nc\",\n",
    "        decode_times=False,\n",
    "    )\n",
    "    sst = sst[\"sst\"].isel(time=0).drop_vars(\"time\")\n",
    "\n",
    "    ## convert to lsm (fill ones over ocean)\n",
    "    lsm = sst.where(np.isnan(sst), other=1.0)\n",
    "\n",
    "    ## sel lon/lat range\n",
    "    lsm = lsm.sel(lon=slice(*lon_range), lat=slice(*lat_range))\n",
    "\n",
    "    # ## add binary mask for regridding\n",
    "    lsm[\"mask\"] = ~np.isnan(lsm)\n",
    "\n",
    "    return lsm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672dd796-55ea-4cee-8c9c-f20d7fc14aae",
   "metadata": {},
   "source": [
    "### Initialize dask cluster (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc88356-4a51-48e4-947c-c1df38b79cdb",
   "metadata": {},
   "source": [
    "````{note} Dask cluster\n",
    "**If you'd like to use a Dask cluster, uncomment the lines in the cell below** (the ```n_workers``` argument specifies how many processes/CPUs to use). You can copy and paste the Dashboard url into a separate browser tab to monitor the cluster.\n",
    "\n",
    "Using a cluster may speed up the data preprocessing via parallelization. E.g., rather than loading all ensemble members, then trimming them in lon/lat space, we assign a separate \"worker\" (e.g., CPU) to trim data for each ensemble member separately.\n",
    "\n",
    "In our experience, using a cluster leads to a larger speed-up when using Poseidon than when remotely connected to the CMIP server (possibly because the network/download is the bottleneck, rather than compute resources). The cluster may also exacerbate the much-feared ```NetCDF:HDF``` error and trigger other hard-to-decipher errors.\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc859601-b81a-4adc-b8e4-e7eaacd44abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dask.distributed import LocalCluster, Client\n",
    "# cluster = LocalCluster(n_workers=4)\n",
    "# client = Client(cluster)\n",
    "# client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8df5bcb-2ed0-4b0f-81ec-eefd08ad80fc",
   "metadata": {},
   "source": [
    "### Set pre-processing specs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0d79ad-d4a5-4de5-a396-8df76af36df5",
   "metadata": {},
   "source": [
    "````{admonition} To-do\n",
    "Update the constants below (see code cell for description).\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83adb8f7-a702-4df5-87f3-a76852d14393",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "````{warning} \n",
    "**Preprocessing the data in the code cell below is slow** ($\\sim 20$ minutes on a laptop). To speed up the process, here are a few options (pick one):\n",
    "1. Download [pre-processed data from Google Drive](https://drive.google.com/drive/folders/1sBa-Z1-b6iKaBHo_UDCdSL5d4zz9GVJE?usp=sharing). Save the files in ```SAVE_FP``` (specify ```SAVE_FP``` below).\n",
    "2. Load less ensemble members (e.g., reduce ```n_members``` from 35 to 9 in the code cell below).\n",
    "3. Use Poseidon (takes less than a minute to run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d588911c-c8af-44b8-abd4-9085da3e3364",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## specify \"save\" filepath: directory where to save the data\n",
    "## (so we don't have to load from server/cloud every time)\n",
    "SAVE_FP = pathlib.Path(\"./data/server\")\n",
    "\n",
    "## should we load from the cloud?\n",
    "LOAD_FROM_CLOUD = False\n",
    "\n",
    "## path to LENS on CMIP server (uncomment second line for windows)\n",
    "LENS_FP = pathlib.Path(\"/Volumes/cmip6/data/cmip6/CMIP/NCAR/LENS\")\n",
    "# LENS_FP = pathlib.Path(\"Z:/data/cmip6/CMIP/NCAR/LENS\")\n",
    "\n",
    "## variable name\n",
    "## suggested: \"SST\" if on server and \"TREFHT\" if on cloud (2m atmos. temp)\n",
    "VARNAME = \"SST\"  # use TREFHT for cloud\n",
    "\n",
    "## number of ensemble members to load\n",
    "N_MEMBERS = 35\n",
    "\n",
    "## lon/lat range\n",
    "LON_RANGE = [280, 300]\n",
    "LAT_RANGE = [35, 45]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ba3a94-aae7-4d35-96ca-2cddacab74c3",
   "metadata": {},
   "source": [
    "### Open data (but don't load to memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f70c84-0c63-4eee-88ef-6d11c6cce544",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check if data exists:\n",
    "files_exist = pathlib.Path(SAVE_FP, \"data_hist.nc\").is_file()\n",
    "\n",
    "## try to load pre-computed data\n",
    "if files_exist:\n",
    "    data_hist = xr.open_dataarray(pathlib.Path(SAVE_FP, \"data_hist.nc\"))\n",
    "    data_fut = xr.open_dataarray(pathlib.Path(SAVE_FP, \"data_fut.nc\"))\n",
    "\n",
    "else:\n",
    "    ## load the data\n",
    "    data_hist, data_fut = load_datasets(\n",
    "        varname=VARNAME,\n",
    "        n_members=N_MEMBERS,\n",
    "        lon_range=LON_RANGE,\n",
    "        lat_range=LAT_RANGE,\n",
    "        lens_fp=LENS_FP,\n",
    "        load_from_cloud=LOAD_FROM_CLOUD,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5d13b5-d41d-4c90-a565-faf51133fe50",
   "metadata": {},
   "source": [
    "### Now, load to memory (this is the slow part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da97410-c53d-4da4-bf6f-3ad274955e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading historical data\")\n",
    "t0 = time.time()\n",
    "data_hist.load()\n",
    "t1 = time.time()\n",
    "print(f\"Elapsed time: {(t1-t0)/60:.1f} minutes\\n\")\n",
    "\n",
    "print(\"Loading future data\")\n",
    "t0 = time.time()\n",
    "data_fut.load()\n",
    "t1 = time.time()\n",
    "print(f\"Elapsed time: {(t1-t0)/60:.1f} minutes\\n\")\n",
    "\n",
    "## save to file\n",
    "if not files_exist:\n",
    "    data_hist.to_netcdf(pathlib.Path(SAVE_FP, \"data_hist.nc\"))\n",
    "    data_fut.to_netcdf(pathlib.Path(SAVE_FP, \"data_fut.nc\"))\n",
    "\n",
    "## Concatenate in time\n",
    "data = xr.concat([data_hist, data_fut], dim=\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d314c3-21bb-442d-a21e-9c3975c19be9",
   "metadata": {},
   "source": [
    "## Plot a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf7619b-ed04-4c0f-bcc2-66b659ff0a95",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## blank canvas\n",
    "fig = plt.figure()\n",
    "\n",
    "## plot background\n",
    "fig, ax = plot_setup_woodshole(fig)\n",
    "\n",
    "\n",
    "## plot the data\n",
    "plot_data = ax.pcolormesh(\n",
    "    data.lon,\n",
    "    data.lat,\n",
    "    data.isel(member_id=0, time=0),\n",
    "    cmap=\"cmo.thermal\",\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "\n",
    "## make a colorbar\n",
    "cb = fig.colorbar(plot_data, fraction=0.015, pad=0.05)\n",
    "\n",
    "## plot outline of region\n",
    "ax = plot_box_outline(ax, lon_range=[287.5, 293.5], lat_range=[39, 44])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d351eff-fdf0-42ac-ad9f-aaac49259080",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2c49dc-0c82-49d3-9045-1f1cc630f150",
   "metadata": {},
   "source": [
    "### Compute index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99dcfda-c529-43b4-b109-bcd9586dca29",
   "metadata": {},
   "source": [
    "````{admonition} To-do\n",
    "If you'd like to look at a different index, modify the function below.\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bb35d3-deaa-477b-8d6d-92a4ad2bba22",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_T_wh(x):\n",
    "    \"\"\"Compute Woods Hole temperature index\"\"\"\n",
    "\n",
    "    ## get subset of data inside the box\n",
    "    data_subset = data.sel(lon=slice(287.5, 293.5), lat=slice(39, 44))\n",
    "\n",
    "    ## compute spatial average\n",
    "    return data_subset.mean([\"lon\", \"lat\"])\n",
    "\n",
    "\n",
    "## do the computation here\n",
    "idx = compute_T_wh(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bea78c-1401-438a-853b-624f255ff55a",
   "metadata": {},
   "source": [
    "### Separate forced response from internal variability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650bce34-a919-4095-a9c2-7a263493e7d3",
   "metadata": {},
   "source": [
    "Estimate forced response and internval variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b91a62-1f48-42b1-9de6-7281c6c8e285",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define forced response as ensemble mean\n",
    "idx_forced = idx.mean(\"member_id\")\n",
    "\n",
    "## internal variability is the residual\n",
    "idx_iv = idx - idx_forced\n",
    "\n",
    "## compute annual means\n",
    "get_ann_mean = lambda x: x.groupby(\"time.year\").mean()\n",
    "idx_forced_ann = get_ann_mean(idx_forced)\n",
    "idx_iv_ann = get_ann_mean(idx_iv)\n",
    "idx_ann = get_ann_mean(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c2ed4c-4540-4fdf-be56-5d6b331e2718",
   "metadata": {},
   "source": [
    "Lets plot the annual mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba63602-95a7-4b87-af52-59682de06a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up plot\n",
    "fig, axs = plt.subplots(1, 2, figsize=(7, 2.75), layout=\"constrained\")\n",
    "\n",
    "## plot ensemble median and 10%/90% percentiles\n",
    "plot_quantiles(axs[0], idx_ann, c=\"k\", time_dim=\"year\", label=\"Ensemble median\")\n",
    "\n",
    "## plot forced response (ensemble mean)\n",
    "axs[0].plot(idx_forced_ann.year, idx_forced_ann, c=\"r\", lw=2, label=\"Ensemble mean\")\n",
    "\n",
    "## plot internval variability\n",
    "kwargs = dict(lw=0.5, alpha=0.5, c=\"gray\")\n",
    "for m in idx_iv_ann.member_id[:10]:\n",
    "    axs[1].plot(idx_iv_ann.year, idx_iv_ann.sel(member_id=m), **kwargs)\n",
    "\n",
    "\n",
    "## label plots\n",
    "for ax in axs:\n",
    "    ax.set_xticks([1920, 2000, 2080])\n",
    "    ax.set_xlabel(\"Year\")\n",
    "    ax.set_ylabel(r\"$^{\\circ}$C\")\n",
    "\n",
    "# axs[0].set_yticks([18, 20, 22])\n",
    "axs[1].set_yticks([-1, 0, 1])\n",
    "axs[0].set_title(\"Forced response\")\n",
    "axs[1].set_title(\"Internal variability (10/35 members)\")\n",
    "axs[1].axhline(0, ls=\"--\", c=\"k\", zorder=0.5)\n",
    "axs[1].yaxis.tick_right()\n",
    "axs[1].yaxis.set_label_position(\"right\")\n",
    "axs[0].legend(prop=dict(size=8))\n",
    "\n",
    "## save fig\n",
    "if SAVE_FIGS:\n",
    "    fig.savefig(\"figs/forced-response.svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2445d40-5dc2-41ea-be4f-a1ed8d4cfb08",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Compare warming rates in Mar and Sep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321aee43-ad8d-41be-8d01-8ab7033077c2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Get smoothed timeseries for Mar/Sep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ace95ed-08b6-4d4e-99ef-fd0e4e08b0a3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Function to do the smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f1e868-9425-4766-8808-ca72a8f07908",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_idx(idx, month):\n",
    "    \"\"\"\n",
    "    Preprocess index for plotting:\n",
    "    1. select specified month (integer from 1 to 12)\n",
    "    2. normalize by subtracting mean over first 10 years\n",
    "    3. smooth the index with a 9-year rolling mean\n",
    "    \"\"\"\n",
    "\n",
    "    ## 1. select month (and rename time index from \"month\" to \"year\"\n",
    "    is_month = idx.time.dt.month == month\n",
    "    idx_ = idx.isel(time=is_month)\n",
    "\n",
    "    ## update time coordinate\n",
    "    year = idx_.time.dt.year.values\n",
    "    idx_ = idx_.rename({\"time\": \"year\"}).assign_coords({\"year\": year})\n",
    "\n",
    "    ## 2. Normalize data (subtract mean over first 30 years)\n",
    "    baseline = idx_.isel(year=slice(None, 10)).mean([\"member_id\", \"year\"])\n",
    "    idx_ = idx_ - baseline\n",
    "\n",
    "    ## 3. Smooth timeseries with 9-year rolling mean\n",
    "    idx_ = idx_.rolling({\"year\": 9}, center=True).mean()\n",
    "    idx_ = idx_.isel(year=slice(4, -4))\n",
    "\n",
    "    return idx_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc84ff2-3477-4d90-ab6c-7031e2480593",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Do the computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c9c0ab-c5ae-4499-b59d-b7cfe506b7e5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## compute values for Mar/Sep\n",
    "idx_mar_norm = preprocess_idx(idx, month=3)\n",
    "idx_sep_norm = preprocess_idx(idx, month=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d9f207-2985-4048-b371-a13a4852175e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Plot timeseries of forced response for Mar/Sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c445fa55-ceb7-41ec-b21b-158fefd53945",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## get colors for plot\n",
    "colors = sns.color_palette()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3.5, 2.75), layout=\"constrained\")\n",
    "\n",
    "## plot data\n",
    "plot_quantiles(ax, idx_mar_norm, c=colors[0], label=\"Mar\", time_dim=\"year\")\n",
    "plot_quantiles(ax, idx_sep_norm, c=colors[1], label=\"Sep\", time_dim=\"year\")\n",
    "\n",
    "## label\n",
    "ax.legend(prop=dict(size=8))\n",
    "ax.set_ylabel(r\"$\\Delta T$ ($^{\\circ}$C)\")\n",
    "# ax.set_xticks([\"1920\", \"2000\", \"2080\"])\n",
    "ax.set_xticks([1920, 2000, 2080])\n",
    "ax.set_xlabel(\"Year\")\n",
    "\n",
    "## save to file\n",
    "if SAVE_FIGS:\n",
    "    fig.savefig(\"figs/forced-response_by-seasonal.svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e51754-423c-4351-af7c-19f63a0d2959",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Compare histograms for early/late period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b09e6ad-b368-4369-8cb0-838ac205b19d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Function to compute histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d78b011-23d9-42da-96c6-de4ab9dcdc3f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_delta_T_pdf(T, t0, t1, bin_edges):\n",
    "    \"\"\"function to compute PDFs of temperature difference between two periods\"\"\"\n",
    "\n",
    "    ## get delta T\n",
    "    delta_T = T.sel(year=t1).squeeze() - T.sel(year=t0).squeeze()\n",
    "\n",
    "    ## create PDF\n",
    "    pdf, _ = get_empirical_pdf(delta_T, bin_edges)\n",
    "\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32bb0fc-acd3-4cfd-9474-ad73d7ca9fd1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Do the computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69123b2b-79be-4921-bbb9-486050d48e2f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## specify params for PDF\n",
    "kwargs0 = dict(t0=1925, t1=2000, bin_edges=np.arange(-0.3, 1.9, 0.15))\n",
    "kwargs1 = dict(t0=2000, t1=2075, bin_edges=np.arange(2, 4.5, 0.2))\n",
    "\n",
    "## compute PDFs for each period\n",
    "pdf_mar_0 = get_delta_T_pdf(idx_mar_norm, **kwargs0)\n",
    "pdf_sep_0 = get_delta_T_pdf(idx_sep_norm, **kwargs0)\n",
    "pdf_mar_1 = get_delta_T_pdf(idx_mar_norm, **kwargs1)\n",
    "pdf_sep_1 = get_delta_T_pdf(idx_sep_norm, **kwargs1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811623fb-7bfd-4d41-8bbc-0ff82ed330f0",
   "metadata": {},
   "source": [
    "Plot result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9371f7-d29b-47b7-b1de-b6207bfbfb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up plot\n",
    "fig, axs = plt.subplots(1, 2, figsize=(5, 2.75), layout=\"constrained\")\n",
    "\n",
    "## plot style for march\n",
    "mar_kwargs = dict(fill=True, alpha=0.3, label=\"Mar\")\n",
    "sep_kwargs = dict(lw=1.5, label=\"Sep\")\n",
    "\n",
    "## plot temperature change for first period\n",
    "axs[0].stairs(pdf_mar_0, edges=kwargs0[\"bin_edges\"], **mar_kwargs)\n",
    "axs[0].stairs(pdf_sep_0, edges=kwargs0[\"bin_edges\"], **sep_kwargs)\n",
    "\n",
    "## plot for second period\n",
    "axs[1].stairs(pdf_mar_1, edges=kwargs1[\"bin_edges\"], **mar_kwargs)\n",
    "axs[1].stairs(pdf_sep_1, edges=kwargs1[\"bin_edges\"], **sep_kwargs)\n",
    "\n",
    "## set axis limits\n",
    "axs[0].set_xlim([-0.75, 2.25])\n",
    "axs[1].set_xlim([1.5, 4.5])\n",
    "for ax in axs:\n",
    "    ax.set_ylim([0, 3])\n",
    "\n",
    "## label\n",
    "axs[0].legend(prop=dict(size=8))\n",
    "axs[0].set_title(f\"{kwargs0['t0']}-{kwargs0['t1']}\")\n",
    "axs[1].set_title(f\"{kwargs1['t0']}-{kwargs1['t1']}\")\n",
    "axs[0].set_xticks([-0.5, 0.5, 1.5])\n",
    "axs[1].set_xticks([2, 3, 4])\n",
    "axs[0].set_yticks([0, 1.5, 3])\n",
    "axs[1].set_yticks([])\n",
    "axs[0].set_ylabel(\"Prob. density\")\n",
    "for ax in axs:\n",
    "    ax.set_xlabel(r\"$\\Delta T$ ($^{\\circ}$C)\")\n",
    "\n",
    "## save to file\n",
    "if SAVE_FIGS:\n",
    "    fig.savefig(\"figs/histograms.svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f62f27-5356-440d-8241-044e82dd47a8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Look at change in standard deviation (spatial pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b82c18b-a8cb-46ef-82c1-69401ae07c13",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Compute change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca482d3-b0e2-4173-83d5-5ef5d87d4b62",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## get internval variability signal\n",
    "data_iv = data - data.mean(\"member_id\")\n",
    "\n",
    "## compute standard dev over first/last 30 years of simulation\n",
    "std_init = data_iv.isel(time=slice(None, 360)).std([\"time\", \"member_id\"], skipna=False)\n",
    "std_end = data_iv.isel(time=slice(-360, None)).std([\"time\", \"member_id\"], skipna=False)\n",
    "\n",
    "## get percentage change\n",
    "std_pct_change = 100 * (std_end - std_init) / std_init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6107117-45ca-4ac3-b583-45e88e7af2a8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Plot initial standard deviation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14e829b-1e2b-4258-87ba-c3126415c37e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## blank canvas\n",
    "fig = plt.figure(layout=\"constrained\")\n",
    "\n",
    "## plot background\n",
    "fig, ax = plot_setup_woodshole(fig)\n",
    "\n",
    "\n",
    "## plot the data\n",
    "plot_data = ax.pcolormesh(\n",
    "    std_init.lon,\n",
    "    std_init.lat,\n",
    "    std_init,\n",
    "    cmap=\"cmo.amp\",\n",
    "    vmax=1.0,\n",
    "    vmin=0.3,\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "\n",
    "## make a colorbar\n",
    "cb = fig.colorbar(\n",
    "    plot_data,\n",
    "    fraction=0.04,\n",
    "    label=r\"Std. dev. ($^{\\circ}$C)\",\n",
    ")\n",
    "\n",
    "## plot outline of region\n",
    "ax = plot_box_outline(ax, lon_range=[287.5, 293.5], lat_range=[39, 44])\n",
    "\n",
    "## Label\n",
    "ax.set_title(\"Standard dev. of SST (1920-1950)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c14e81-8d7f-42dc-901d-4875026ce46c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Plot % change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5c4912-f937-4348-b509-c88a044766bb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## blank canvas\n",
    "fig = plt.figure(layout=\"constrained\")\n",
    "\n",
    "## plot background\n",
    "fig, ax = plot_setup_woodshole(fig)\n",
    "\n",
    "\n",
    "## plot the data\n",
    "plot_data = ax.pcolormesh(\n",
    "    std_init.lon,\n",
    "    std_init.lat,\n",
    "    std_pct_change,\n",
    "    cmap=\"cmo.balance\",\n",
    "    vmax=30,\n",
    "    vmin=-30,\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "\n",
    "## make a colorbar\n",
    "cb = fig.colorbar(\n",
    "    plot_data, fraction=0.015, pad=0.05, ticks=[-30, 0, 30], label=\"% change\"\n",
    ")\n",
    "\n",
    "## plot outline of region\n",
    "ax = plot_box_outline(ax, lon_range=[287.5, 293.5], lat_range=[39, 44])\n",
    "\n",
    "## label\n",
    "ax.set_title(\"Change in standard dev. of SST (1935-2065)\")\n",
    "\n",
    "## save to  file\n",
    "if SAVE_FIGS:\n",
    "    fig.savefig(\"figs/sigma-change.svg\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
