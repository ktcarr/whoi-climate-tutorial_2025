{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9acfce2d-05a3-4911-a9db-9492daacaf80",
   "metadata": {},
   "source": [
    "# Xarray reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e0832c-bcae-43d2-bf3e-cddc35962480",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Loading and prepping data from WHOI's \"CMIP\" server\n",
    "\n",
    "The goal of this script is to demonstrate – and provide a reference for – how to load and pre-process gridded climate data from WHOI's servers. We'll start by [opening](opening-data) and [plotting](plotting-data) some temperature data and perform some common pre-processing steps, including [spatial averaging](spatial-averaging), [removing the seasonal cycle](seasonal-cycle), [interpolation and resampling](interp), [detrending](detrending), [computing correlations](correlation), and [regridding](regridding). These examples are not necessarily the \"best\" (e.g., most efficient) way to do things and are intended as a starting point (the 2-dimenstional dataset we're working with is small enough that it doesn't matter too much if we do things inefficiently).\n",
    "\n",
    "Whenever possible, we've attempted to use built-in functions from [xarray](https://xarray.dev/), a Python package useful for working with gridded climate data and netcdf files. I think of it as a high-level \"wrapper\" for lower-level packages like ```numpy``` and ```pandas```. While the core of a ```xarray.DataArray``` object is a ```numpy.array```, the ```xarray``` object includes dimension names and additional metadata. This tends to make code easier to interpret: for example, to average over latitudes in a ```numpy``` array, you have to keep track of which array dimension corresponds to latitude – e.g., ```data.mean(axis=2)```, if latitude is the 2$^{nd}$ dimension – whereas in ```xarray``` you don't: ```data.mean(dim=\"latitude\")```.  \n",
    "\n",
    "For a more complete tutorial on the ```xarray``` package, I highly recommend the developers' official [45-minute tutorial](https://tutorial.xarray.dev/overview/xarray-in-45-min.html).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9dafd6-eb92-451d-8326-0a4a635e98b4",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f319a253-bef7-456e-b46b-f824a0c74014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cmocean\n",
    "from matplotlib.dates import DateFormatter\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import cftime\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.dates as mdates\n",
    "import os.path\n",
    "\n",
    "## set plotting style\n",
    "sns.set(rc={\"axes.facecolor\": \"white\", \"axes.grid\": False})\n",
    "\n",
    "## initialize random number generator\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ce9c22-4963-4411-8720-53da9857cb28",
   "metadata": {},
   "source": [
    "(opening-data)=\n",
    "## Open the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc84e76-90dd-41b4-bf26-de0fc2bf538d",
   "metadata": {},
   "source": [
    "```{admonition} To-do\n",
    "Specify the path to the file server in the following code cell.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed31d48f-cc4e-48a1-8231-6f9409c26549",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To-do: update path to WHOI file server on your machine\n",
    "## On Mac, the default location is \"/Volumes\"\n",
    "server_path = pathlib.Path(\"/Volumes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c11bdf-011f-4d7b-822c-94bd0fa2e1e6",
   "metadata": {},
   "source": [
    "### Specify file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38882629-ecaa-4a35-a069-74687ee337d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Path to ERA5 T2m data\n",
    "t2m_path_on_server = pathlib.Path(\n",
    "    \"cmip6/data/era5/reanalysis/single-levels/monthly-means/2m_temperature\"\n",
    ")\n",
    "\n",
    "#### Path to ERA5 SLP data\n",
    "slp_path_on_server = pathlib.Path(\n",
    "    \"cmip6/data/era5/reanalysis/single-levels/monthly-means/mean_sea_level_pressure\"\n",
    ")\n",
    "\n",
    "#### Path to MIROC6 SST data\n",
    "sst_path_on_server = pathlib.Path(\n",
    "    \"cmip6/data/cmip6/CMIP/MIROC/MIROC6/historical/r1i1p1f1/Omon/tos/gn/1\"\n",
    ")\n",
    "\n",
    "## append these relative filepaths to the server filepath\n",
    "t2m_path = pathlib.Path(server_path, t2m_path_on_server)\n",
    "slp_path = pathlib.Path(server_path, slp_path_on_server)\n",
    "sst_path = pathlib.Path(server_path, sst_path_on_server)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866f248b-4640-4e33-9e1a-0cb594181ec8",
   "metadata": {},
   "source": [
    "## Opening data\n",
    "We're going to work with a \"reanalysis\" product located on the CMIP6 archive. As a reminder from lecture, a reanalysis is a hybrid of model output and observations. Observations (e.g., of rainfall, temperature, or ocean salinity) are sparse (& irregular) in time in space. The purpose of the reanalysis is to fill in the gaps, creating a nice \"gridded\" dataset which *is* regular in time and space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddbcc89-1931-481d-af8f-99b21db8d24f",
   "metadata": {},
   "source": [
    "Note: for the ERA5 reanalysis, each year of data has a separate file. We'll print out the names of the first 4 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3194f3-f9f7-4853-92a2-394338678bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## List the first few files in the 2m-temperature folder\n",
    "file_list = list(t2m_path.glob(\"*.nc\"))\n",
    "print(np.sort(file_list)[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426736fb-cf5f-45dc-befb-06c84e599f71",
   "metadata": {},
   "source": [
    "To open the dataset, use ```xr.open_dataset``` (single file) or ```xr.open_mfdataset``` (multiple files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596beb39-4a23-4683-af1b-45ab6959dccf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Load a single file using xarray\n",
    "T2m_1980 = xr.open_dataset(pathlib.Path(t2m_path, \"1980_2m_temperature.nc\"))\n",
    "T2m_1980.load()\n",
    "# loads into memory\n",
    "\n",
    "## open the first 3 files (but don't load to memory)\n",
    "T2m = xr.open_mfdataset(file_list[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f74c47-df73-4ae5-bf6c-0e643e09758f",
   "metadata": {},
   "source": [
    "To subset data, use the ```.isel``` / ```.sel``` functions. We'll write a function which trims data to the North Atlantic region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34adb9d-aadf-43d3-92b8-682a131db5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## select data for Jan 1., two different ways\n",
    "print(\n",
    "    np.allclose(\n",
    "        T2m_1980[\"t2m\"].isel(time=0).values,\n",
    "        T2m_1980[\"t2m\"].sel(time=\"1980-01-01\").values,\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "def trim_to_north_atl(x):\n",
    "    \"\"\"trims data to the North Atlantic region\"\"\"\n",
    "\n",
    "    ## lon/lat boundaries for N. Atlantic\n",
    "    lon_range = [260, 360]\n",
    "    lat_range = [70, 3]\n",
    "\n",
    "    ## trim the data\n",
    "    x_trimmed = x.sel(longitude=slice(*lon_range), latitude=slice(*lat_range))\n",
    "\n",
    "    return x_trimmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105c7349-c247-44c3-a49b-711994d337dc",
   "metadata": {},
   "source": [
    "If we only care about a subset of the data (i.e., not the whole globe), it can be helpful to subset it *while* loading. To do this, pass a subsetting function to ```xr.open_mfdataset```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3728702-95d4-47ef-a0d2-e1b519428e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load trimmed data\n",
    "T2m_trimmed = xr.open_mfdataset(file_list[:3], preprocess=trim_to_north_atl).compute()\n",
    "\n",
    "## Compare size to original data\n",
    "print(f\"Shape of raw data:     {T2m['t2m'].shape}\")\n",
    "print(f\"Shape of trimmed data: {T2m_trimmed['t2m'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f7d37c-05a8-4f90-b1c3-5d3f7acb9e37",
   "metadata": {},
   "source": [
    "(plotting-data)=\n",
    "## Plotting data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7a8d82-b7ad-4ec1-a079-d43766e8e099",
   "metadata": {},
   "source": [
    "### Plot setup and gridlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eee878-fb80-441a-b0e6-2187447d0cf4",
   "metadata": {},
   "source": [
    "First, let's define a function which draws a blank map (don't worry about the details for now)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bae3b0e-1dfe-4b8f-8b9d-6621eb1ae29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First, a generic plot setup function\n",
    "def plot_setup(ax, lon_range, lat_range, xticks, yticks, scale):\n",
    "    \"\"\"\n",
    "    Create map background for plotting spatial data.\n",
    "    Arguments:\n",
    "        - ax: Matplotlib object containing everything in the plot.\n",
    "            (I think of it as the plot \"canvas\")\n",
    "        - lon_range/lat_range: 2-element arrays, representing plot boundaries\n",
    "        - xticks/yticks: location for lon/lat labels\n",
    "        - scale: number which controls linewidth and fontsize\n",
    "\n",
    "    Returns a modified 'ax' object.\n",
    "    \"\"\"\n",
    "\n",
    "    ## specify transparency/linewidths\n",
    "    grid_alpha = 0.1 * scale\n",
    "    grid_linewidth = 0.5 * scale\n",
    "    coastline_linewidth = 0.3 * scale\n",
    "    label_size = 8 * scale\n",
    "\n",
    "    ## crop map and plot coastlines\n",
    "    ax.set_extent([*lon_range, *lat_range], crs=ccrs.PlateCarree())\n",
    "    ax.coastlines(linewidth=coastline_linewidth)\n",
    "\n",
    "    ## plot grid\n",
    "    gl = ax.gridlines(\n",
    "        draw_labels=True,\n",
    "        linestyle=\"--\",\n",
    "        alpha=grid_alpha,\n",
    "        linewidth=grid_linewidth,\n",
    "        color=\"k\",\n",
    "        zorder=1.05,\n",
    "    )\n",
    "\n",
    "    ## add tick labels\n",
    "    gl.bottom_labels = False\n",
    "    gl.right_labels = False\n",
    "    gl.xlabel_style = {\"size\": label_size}\n",
    "    gl.ylabel_style = {\"size\": label_size}\n",
    "    gl.ylocator = mticker.FixedLocator(yticks)\n",
    "    gl.xlocator = mticker.FixedLocator(xticks)\n",
    "\n",
    "    return ax, gl\n",
    "\n",
    "\n",
    "## Next, a function to plot the North Atlantic\n",
    "def plot_setup_north_atl(ax, scale=1):\n",
    "    \"\"\"Create map background for plotting spatial data.\n",
    "    Returns modified 'ax' object.\"\"\"\n",
    "\n",
    "    ## specify range and ticklabels for plot\n",
    "    lon_range = [-100, 0]\n",
    "    lat_range = [3, 70]\n",
    "    xticks = [-80, -60, -40, -20, 0]\n",
    "    yticks = [20, 40, 60]\n",
    "\n",
    "    ax, gl = plot_setup(ax, lon_range, lat_range, xticks, yticks, scale)\n",
    "\n",
    "    return ax, gl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c35469d-c92b-46ab-bc02-4f7a8ad9bc4b",
   "metadata": {},
   "source": [
    "Next, plot a sample of the temperature dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e7f373-6f9d-4f23-ae87-88175e5d02c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a figure object (can contain multiple \"Axes\" object)\n",
    "fig = plt.figure(figsize=(6, 3))\n",
    "\n",
    "## add Axes object (blank canvas for our plot)\n",
    "ax = fig.add_subplot(projection=ccrs.PlateCarree())\n",
    "ax, gl = plot_setup_north_atl(ax)\n",
    "\n",
    "## Let's plot T2m data for Jan 1, 1980\n",
    "t2m_plot = ax.contourf(\n",
    "    T2m_1980.longitude,\n",
    "    T2m_1980.latitude,\n",
    "    T2m_1980[\"t2m\"].isel(time=0),\n",
    "    levels=np.arange(260, 304, 4),  # contour levels to plot\n",
    "    cmap=\"cmo.thermal\",  # colormap (see https://matplotlib.org/cmocean/)\n",
    "    extend=\"both\",  # includes values outside of contour bounds,\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "\n",
    "## add a colorbar\n",
    "cb = fig.colorbar(t2m_plot, orientation=\"vertical\", label=r\"$K$\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa5574f-8dd0-4ed8-a113-5be480042cae",
   "metadata": {},
   "source": [
    "### Plotting in the Pacific"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac29d45-7b81-4f94-8d70-3200a9402e95",
   "metadata": {},
   "source": [
    "#### Plotting functions\n",
    "Let's start from scratch for this example: define a function to set up a plot with the given projection and lon/lat range (```plot_setup_simple```). Then define a wrapper function which sets up a plot with the given projection *in the North Pacific*.\n",
    "Note we have to specify the projection keyword (e.g., ccrs.PlateCarree or ccrs.Orthographic) when creating an Axes object with the ```fig.add_subplot``` function. When plotting data on regular lon/lat grids, we also have to pass ```ccrs.PlateCarree``` as an argument to ```ax.set_extent``` and to the contour plotting function, ```ax.contourf```. Note the map projection type passted to ```fig.add_subplot``` may change (shown below) but we always pass ```ccrs.PlateCarree``` to the ```ax.set_extent``` and ```ax.contourf``` functions (I don't know why this is the case, but it seems to work :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926c2767-3985-4668-8c41-a2612a69b5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_setup_simple(fig, projection, lon_range, lat_range):\n",
    "    \"\"\"Add a subplot to the figure with the given map projection\n",
    "    and lon/lat range. Returns an Axes object.\"\"\"\n",
    "\n",
    "    ## Create subplot with given projection\n",
    "    ax = fig.add_subplot(projection=projection)\n",
    "\n",
    "    ## Subset to given region\n",
    "    extent = [*lon_range, *lat_range]\n",
    "    ax.set_extent(extent, crs=ccrs.PlateCarree())\n",
    "\n",
    "    ## draw coastlines\n",
    "    ax.coastlines()\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_setup_pacific(fig, projection):\n",
    "    \"\"\"Plot Pacific region\"\"\"\n",
    "    return plot_setup_simple(fig, projection, lon_range=[120, 240], lat_range=[30, 70])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde6d4ea-d094-4b1d-ae81-b32360b5db17",
   "metadata": {},
   "source": [
    "#### Make plots for two projection types, PlateCarree and Orthographic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40954d5-ce2f-4bb2-b2a5-833f5809cab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define some map projections\n",
    "## for a full list, see https://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html\n",
    "proj_PC = ccrs.PlateCarree(central_longitude=180)\n",
    "proj_ortho = ccrs.Orthographic(central_longitude=180, central_latitude=50)\n",
    "\n",
    "## Plot data with each projection\n",
    "for proj in [proj_PC, proj_ortho]:\n",
    "\n",
    "    ## make blank figure\n",
    "    fig = plt.figure(figsize=(6, 3))\n",
    "\n",
    "    ## plot pacific background\n",
    "    ax = plot_setup_pacific(fig, proj)\n",
    "\n",
    "    ## plot data\n",
    "    ax.contourf(\n",
    "        T2m_1980.longitude,\n",
    "        T2m_1980.latitude,\n",
    "        T2m_1980[\"t2m\"].isel(time=0),\n",
    "        transform=ccrs.PlateCarree(),\n",
    "    )\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8ac4fc-130f-485a-be0a-661296bf82ef",
   "metadata": {},
   "source": [
    "### Highlighting specific contours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b874de9-e4d1-4e2d-8da8-2467dd11aa58",
   "metadata": {},
   "source": [
    "#### Plot the data (and highlight the $280 K$ contour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5da71c8-2fa8-4d64-a963-70cc8a88f9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make blank figure\n",
    "fig = plt.figure(figsize=(6, 2.5))\n",
    "\n",
    "## plot pacific background\n",
    "ax = plot_setup_pacific(\n",
    "    fig, projection=ccrs.Orthographic(central_longitude=180, central_latitude=50)\n",
    ")\n",
    "\n",
    "## plot the data\n",
    "# plot_data = ax.contourf(t2m.longitude, t2m.latitude, t2m, transform=ccrs.PlateCarree())\n",
    "plot_data = ax.contourf(\n",
    "    T2m_1980.longitude,\n",
    "    T2m_1980.latitude,\n",
    "    T2m_1980[\"t2m\"].isel(time=0),\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "\n",
    "## Add a colorbar\n",
    "cb = fig.colorbar(plot_data)\n",
    "\n",
    "##### Highlight a specified contour value #####\n",
    "\n",
    "## specify which value to highlight\n",
    "contour_value = 280\n",
    "\n",
    "## Create list of contour levels to pass to the plotting function.\n",
    "## We'll pad the contour value we want to plot with -/+ a big number:\n",
    "## we have to add these \"pad\" values because the plotting function\n",
    "## (ax.contour) will throw an error if we only pass only one value.\n",
    "## The pad value is chosen to be outside of the range of the data values\n",
    "## so isn't plotted.\n",
    "pad_value = 1e10\n",
    "levels = [-pad_value, contour_value, pad_value]\n",
    "\n",
    "## call the plotting function\n",
    "ax.contour(\n",
    "    T2m_1980.longitude,\n",
    "    T2m_1980.latitude,\n",
    "    T2m_1980[\"t2m\"].isel(time=0),\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    levels=levels,\n",
    "    colors=\"white\",\n",
    "    linestyles=\"dashed\",\n",
    ")\n",
    "\n",
    "################################################\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2974b60-3371-4b09-bfc8-470ecbc200bf",
   "metadata": {},
   "source": [
    "(spatial-averaging)=\n",
    "## Spatial averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0969f0e-25d2-49b5-8b0e-c28440285b34",
   "metadata": {},
   "source": [
    "Next, write a function to spatially average the data. This is slightly more involved than just averaging over all elements in the array: we need to compute a weighted average, with the weights given by the cosine of the latitude . The reason is that we're averaging on the surface of a sphere, and need to account for the fact that grid cells get smaller as you go closer to the poles (see [below](coslat) for a more detailed explanation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a9d528-0940-419d-9b58-a1890d6fa2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_avg(data):\n",
    "    \"\"\"function to compute spatial average of data on grid with constant\n",
    "    longitude/latitude spacing.\"\"\"\n",
    "\n",
    "    ## first, compute cosine of latitude (after converting degrees to radians)\n",
    "    latitude_radians = np.deg2rad(data.latitude)\n",
    "    cos_lat = np.cos(latitude_radians)\n",
    "\n",
    "    ## get weighted average using xarray\n",
    "    avg = data.weighted(weights=cos_lat).mean([\"longitude\", \"latitude\"])\n",
    "\n",
    "    return avg\n",
    "\n",
    "\n",
    "## \"naive\" unweighted average over longitude and latitudes\n",
    "avg_unweighted = T2m_trimmed[\"t2m\"].mean([\"latitude\", \"longitude\"])\n",
    "\n",
    "## (correct) weighted average\n",
    "avg_weighted = spatial_avg(T2m_trimmed[\"t2m\"])\n",
    "\n",
    "## compare results:\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "ax.plot(avg_unweighted.time, avg_unweighted, label=\"unweighted\")\n",
    "ax.plot(avg_weighted.time, avg_weighted, label=\"weighted\")\n",
    "\n",
    "## label plot\n",
    "ax.legend(prop={\"size\": 10})\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.set_ylabel(r\"$K$\")\n",
    "ax.set_xticks(ax.get_xticks()[::3])\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fcb783-7fd2-4f97-b7a8-e5395c2b081a",
   "metadata": {},
   "source": [
    "(coslat)=\n",
    "### Explanation of cos(latitude) weighting\n",
    "Not every element in our array represents an equal surface area of the earth: on a \"regular\" longitude-latitude grid (where the longitude and latitude spacing is constant) the area of gridcells decreases as you move away from the equator to the poles. Denoting longitude and latitude as $\\theta$ and $\\phi$, and longitude and latitude spacing as $\\delta\\theta$ and $\\delta\\phi$, the area of each gridcell is given by $\\delta A ~= R^2\\cos(\\phi)\\delta\\phi\\delta\\theta$, where $R$ is the radius of the earth. The weighted average of a variable $f$ on the sphere is then given by:\n",
    "\\begin{align}\n",
    "    \\overline{f} &= \\frac{\\sum f~\\delta A}{\\sum \\delta A} = \\frac{\\sum f~R^2\\cos\\left(\\phi\\right)~\\delta\\phi~\\delta\\theta}{\\sum R^2\\cos\\left(\\phi\\right)~\\delta\\phi~\\delta\\theta} = \\frac{R^2 ~\\delta\\phi~\\delta\\theta \\sum f~\\cos\\left(\\phi\\right)}{R^2~\\delta\\phi~\\delta\\theta \\sum \\cos(\\phi)} = \\frac{\\sum f\\cos(\\phi)}{\\sum\\cos(\\phi)},\n",
    "\\end{align}\n",
    "where we use the fact that $R^2$, $\\delta\\theta$, and $\\delta\\phi$ are constant (and can be pulled out of the summation). Therefore, to compute $\\overline{f}$, we need to compute a *weighted* average, where the weights are the cosine of the latitude."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f0a3b3-48d1-4668-9d75-77c9298f69bd",
   "metadata": {},
   "source": [
    "(seasonal-cycle)=\n",
    "## Seasonal cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f438eafd-efe6-42f1-be22-97370cacda08",
   "metadata": {},
   "source": [
    "Use ```groupby``` to group data by month (and apply functions to each month separately). Below, we'll compute the mean temperature for each season and subtract it from the data to obtain anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11f6e1f-95be-47f6-a025-49573f103a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_cyc = avg_weighted.groupby(\"time.month\").mean()\n",
    "anomalies = avg_weighted.groupby(\"time.month\") - seasonal_cyc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42586515-a795-4bef-a462-e847d2357754",
   "metadata": {},
   "source": [
    "Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71289dc3-df44-46f2-9af2-32832e3491c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot seasonal cycle\n",
    "fig, ax = plt.subplots(figsize=(3, 2))\n",
    "ax.plot(seasonal_cyc.month, seasonal_cyc)\n",
    "ax.set_xticks([1, 6, 11], labels=[\"Jan\", \"Jun\", \"Nov\"])\n",
    "ax.set_yticks(ticks=[285, 290, 295])\n",
    "ax.set_ylabel(r\"$K$\")\n",
    "ax.set_xlabel(\"Month\")\n",
    "ax.set_title(\"Mean seasonal cycle\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "## Plot anomalies\n",
    "fig, ax = plt.subplots(figsize=(3, 2))\n",
    "\n",
    "## plot raw data\n",
    "p = ax.plot(avg_weighted.time, avg_weighted, label=\"w/ seasonal cycle\", alpha=0.5)\n",
    "ax.set_ylabel(r\"$T$ before ($K$)\", color=p[0].get_color())\n",
    "ax.set_yticks(ticks=[285, 290, 295], labels=[285, 290, 295], color=p[0].get_color())\n",
    "\n",
    "## plot after removing mean seasonal cycle\n",
    "ax_anom = ax.twinx()\n",
    "ax_anom.plot(anomalies.time, anomalies, label=\"w/o seasonal cycle\", c=\"k\")\n",
    "ax_anom.set_ylabel(r\"$T$ after ($K$)\")\n",
    "\n",
    "## Label plot\n",
    "ax.set_xticks(ax.get_xticks()[::3])\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
    "ax.set_title(\"Before/after removing seasonal cycle\")\n",
    "ax.set_xlabel(\"Year\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cbd802-9b68-4468-a9bf-267f3c060435",
   "metadata": {},
   "source": [
    "Note we can compute the seasonal cycle at every gridpoint separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc1aff0-73d7-4696-ad45-1180793f3b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute seasonal cycle, and plot at diff. b/n july and jan\n",
    "seasonal_cyc_spatial = T2m_trimmed[\"t2m\"].groupby(\"time.month\").mean()\n",
    "jul_jan_diff = seasonal_cyc_spatial.sel(month=7) - seasonal_cyc_spatial.sel(month=1)\n",
    "\n",
    "## Create a figure object (can contain multiple \"Axes\" object)\n",
    "fig = plt.figure(figsize=(6, 3))\n",
    "ax = fig.add_subplot(projection=ccrs.PlateCarree())\n",
    "ax, gl = plot_setup_north_atl(ax)\n",
    "\n",
    "## Plot data\n",
    "t2m_plot = ax.contourf(\n",
    "    jul_jan_diff.longitude,\n",
    "    jul_jan_diff.latitude,\n",
    "    jul_jan_diff,\n",
    "    levels=np.arange(-30, 34, 4),\n",
    "    cmap=\"cmo.balance\",\n",
    "    extend=\"both\",\n",
    ")\n",
    "\n",
    "## add a colorbar and label\n",
    "cb = fig.colorbar(\n",
    "    t2m_plot, orientation=\"vertical\", label=r\"$K$\", ticks=np.arange(-30, 45, 15)\n",
    ")\n",
    "ax.set_title(\"Jul – Jan difference\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd54c8e-fb41-40de-90ef-e1e5e1e9e321",
   "metadata": {},
   "source": [
    "Check that the order of averaging doesn't matter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74669be7-cbcc-4439-8ff9-dfba093e4b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  to spatial dataset\n",
    "print(np.allclose(spatial_avg(seasonal_cyc_spatial), seasonal_cyc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bca5be-925f-4e9e-869a-fa1527cc0f83",
   "metadata": {},
   "source": [
    "(interp)=\n",
    "## Interpolation and resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f372ea3-cc52-4623-8f48-7a0ab1add942",
   "metadata": {},
   "source": [
    "### Averaging in time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb4556c-c837-4d3e-abb3-97d94b8a759d",
   "metadata": {},
   "source": [
    "Below, let's downsample from monthly data to 3-month averages, grouped into the following months: Dec-Jan-Feb (DJF), Mar-Apr-May (MAM), Jun-Jul-Aug (JJA), and Sep-Oct-Nov (SON)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f575d1f8-a292-4b97-be3d-7a8769cefdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Resample to quarterly (3-month) averages, where\n",
    "## the first quarter starts in December (\"QS-DEC\"),\n",
    "## and each point is labeled by the first month in the quarter\n",
    "anomalies_seasonal = anomalies.resample({\"time\": \"QS-DEC\"}).mean()\n",
    "\n",
    "## To extract the Dec-Jan-Feb season:\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "\n",
    "## plot data\n",
    "ax.step(anomalies_seasonal.time, anomalies_seasonal, where=\"post\", label=\"seasonal\")\n",
    "ax.plot(anomalies.time, anomalies, c=\"k\", alpha=0.3, label=\"monthly\")\n",
    "\n",
    "## label plot\n",
    "ax.set_ylabel(r\"$T$ anomaly ($K$)\")\n",
    "ax.set_yticks([-0.5, 0.0, 0.5])\n",
    "ax.set_xticks(ax.get_xticks()[::3])\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9348649-3e4a-4432-a2de-80a40de96270",
   "metadata": {},
   "source": [
    "Next, downsample to annual data two different ways. Note that the resulting time axis differs for each method: one is labeled with a ```datetime``` object representing the first day in the year, while the other is labeled by an integer representing the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d51c957-8334-4bcb-8e4b-0d62f696a36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## annual mean, 2 different ways\n",
    "anomalies_annual0 = anomalies.resample({\"time\": \"YS-JAN\"}).mean()\n",
    "anomalies_annual1 = anomalies.groupby(\"time.year\").mean()\n",
    "print(np.allclose(anomalies_annual0, anomalies_annual1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b313eb-341e-4b17-a19c-929064522698",
   "metadata": {},
   "source": [
    "### Resampling in space\n",
    "```xarray```'s ```interp``` function can be used to resample in space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa822db2-a3c4-4bdc-907d-15b8e4695c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Downsample by averaging in space\n",
    "lat_coarse = T2m_trimmed.latitude[::4]\n",
    "lon_coarse = T2m_trimmed.longitude[::4]\n",
    "\n",
    "## Do the downsampling (linear interpolation is default)\n",
    "T2m_coarse = T2m_trimmed.interp({\"longitude\": lon_coarse, \"latitude\": lat_coarse})\n",
    "\n",
    "print(f\"Original shape:     {T2m_trimmed['t2m'].shape}\")\n",
    "print(f\"After downsampling: {T2m_coarse['t2m'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cda6e1-f5ae-4a59-9250-04191d568e22",
   "metadata": {},
   "source": [
    "(detrending)=\n",
    "## Detrending"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4bfa15-f805-4369-b9c2-3e77ffb88604",
   "metadata": {},
   "source": [
    "To illustrate detrending, let's load in a longer timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1b2159-2026-4b7b-8450-97c9e1325425",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define a preprocessing function\n",
    "def preprocess(data):\n",
    "    \"\"\"pre-process data before loading it:\n",
    "    1. Downsample in space\n",
    "    2. only get DJF months\n",
    "    \"\"\"\n",
    "    ## 1. Downsample in space\n",
    "    data_ = data.interp({\"longitude\": lon_coarse, \"latitude\": lat_coarse}).compute()\n",
    "\n",
    "    ## 2. Find indices of winter season\n",
    "    month = data_.time.dt.month\n",
    "    is_winter = (month == 12) | (month <= 2)\n",
    "\n",
    "    ## select winter season\n",
    "    data_ = data_.sel(time=is_winter)\n",
    "\n",
    "    return data_\n",
    "\n",
    "\n",
    "def djf_avg(data):\n",
    "    \"\"\"function to get Dec-Jan-Feb average\"\"\"\n",
    "\n",
    "    ## first, resample from monthly to seasonal\n",
    "    data_ = data.resample({\"time\": \"QS-DEC\"}).mean()\n",
    "\n",
    "    ## next, select DJF season\n",
    "    is_winter = data_.time.dt.month == 12\n",
    "    data_ = data_.sel(time=is_winter)\n",
    "\n",
    "    ## for convenience, replace \"time\" index with \"year\":\n",
    "    ## label with year for Jan, (so Dec-'78,Jan-'79,Feb-'79 -> 1979)\n",
    "    year = data_.time.dt.year.values + 1\n",
    "    data_[\"time\"] = year\n",
    "    data_ = data_.rename({\"time\": \"year\"})\n",
    "\n",
    "    return data_\n",
    "\n",
    "\n",
    "## load prepped data\n",
    "T2m_long = xr.open_mfdataset(file_list, preprocess=preprocess)\n",
    "\n",
    "## Get DJF average\n",
    "T2m_djf = djf_avg(T2m_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcf39e6-c4af-4acb-9dc0-c6becf67e433",
   "metadata": {},
   "source": [
    "Next, write a function to compute a trend along a given dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7103e9c-c2d4-48c4-a033-d2735edfe177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trend(data, dim=\"year\"):\n",
    "    \"\"\"Get linear trend for an xr.dataarray along specified dimension\"\"\"\n",
    "\n",
    "    ## Get coefficients for best fit\n",
    "    polyfit_coefs = data.polyfit(dim=dim, deg=1)[\"polyfit_coefficients\"]\n",
    "\n",
    "    ## Get best fit line (linear trend in this case)\n",
    "    trend = xr.polyval(data[dim], polyfit_coefs)\n",
    "\n",
    "    return trend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132f8344-78ad-4d84-9cba-2f6a6d5a96d4",
   "metadata": {},
   "source": [
    "Compute the trend and remove it from data to obtain a \"detrended\" version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2654e2fc-2b5f-4291-ba6a-2964484de349",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute the trend\n",
    "T2m_trend = get_trend(T2m_djf[\"t2m\"])\n",
    "\n",
    "## Get detrended version\n",
    "T2m_detrended = T2m_djf[\"t2m\"] - T2m_trend\n",
    "\n",
    "## compute spatial averages\n",
    "T2m_trend_avg = spatial_avg(T2m_trend)\n",
    "T2m_detrended_avg = spatial_avg(T2m_detrended)\n",
    "T2m_djf_avg = spatial_avg(T2m_djf[\"t2m\"])\n",
    "\n",
    "\n",
    "## plot result\n",
    "fig, ax = plt.subplots(figsize=(3, 2))\n",
    "ax.plot(T2m_djf_avg.year, T2m_djf_avg, label=\"DJF\")\n",
    "ax.plot(T2m_trend_avg.year, T2m_trend_avg, label=\"DJF trend\", c=\"k\", alpha=0.3)\n",
    "ax.plot(\n",
    "    T2m_detrended_avg.year,\n",
    "    T2m_detrended_avg + T2m_trend_avg.mean(),\n",
    "    label=\"DJF detrended\",\n",
    ")\n",
    "ax.set_yticks([285, 286])\n",
    "ax.set_xticks([1980, 2000, 2020])\n",
    "ax.legend(prop={\"size\": 8})\n",
    "ax.set_title(r\"North Atlantic $T_{2m}$\")\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_ylabel(r\"$T_{2m}$ ($K$)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c8672a-8e23-4ac6-9b00-3c9eaae0b862",
   "metadata": {},
   "source": [
    "(correlation)=\n",
    "## Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392a9afb-d99d-46d2-9b7c-ca48bf3368a9",
   "metadata": {},
   "source": [
    "Load in sea level pressure from ERA5 and detrend it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae05d665-16fd-4302-a685-bd42f3823f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get list of SLP files\n",
    "slp_file_list = list(slp_path.glob(\"*.nc\"))\n",
    "\n",
    "## Open SLP over N. Atlantic\n",
    "slp = xr.open_mfdataset(slp_file_list, preprocess=preprocess)[\"msl\"]\n",
    "\n",
    "## convert from Pa to hPa (1 hPa = 100 Pa)\n",
    "slp *= 1 / 100\n",
    "\n",
    "## Get DJF average\n",
    "slp_djf = djf_avg(slp)\n",
    "\n",
    "## detrend\n",
    "slp_detrended = slp_djf - get_trend(slp_djf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c2e68d-9f05-4c8e-a31c-e609b0e88743",
   "metadata": {},
   "source": [
    "### Compute point-wise correlation between SLP and $T_{2m}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb3067b-e982-4637-9404-c98f0ca14fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cb_range(amp, delta):\n",
    "    \"\"\"Make colorbar_range for cmo.balance\n",
    "    Args:\n",
    "        - 'amp': amplitude of maximum value for colorbar\n",
    "        - 'delta': increment for colorbar\n",
    "    \"\"\"\n",
    "    return np.concatenate(\n",
    "        [np.arange(-amp, 0, delta), np.arange(delta, amp + delta, delta)]\n",
    "    )\n",
    "\n",
    "\n",
    "def make_correlation_plot(correlation):\n",
    "\n",
    "    ## Plot results\n",
    "    fig = plt.figure(figsize=(6, 3))\n",
    "    ax = fig.add_subplot(projection=ccrs.PlateCarree())\n",
    "    ax, gl = plot_setup_north_atl(ax)\n",
    "\n",
    "    ## Plot data\n",
    "    corr_plot = ax.contourf(\n",
    "        correlation.longitude,\n",
    "        correlation.latitude,\n",
    "        correlation,\n",
    "        levels=make_cb_range(1, 0.1),\n",
    "        cmap=\"cmo.balance\",\n",
    "        extend=\"both\",\n",
    "    )\n",
    "\n",
    "    ## add a colorbar and label\n",
    "    cb = fig.colorbar(corr_plot, orientation=\"vertical\", ticks=[-1, 0, 1])\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "## compute correlation\n",
    "slp_T2m_corr = xr.corr(slp_detrended, T2m_detrended, dim=\"year\")\n",
    "\n",
    "## plot results\n",
    "fig, ax = make_correlation_plot(slp_T2m_corr)\n",
    "ax.set_title(r\"Correlation b/n $T_{2m}$ and SLP during winter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3002a22e-029d-4bfe-bbae-92f2c969771a",
   "metadata": {},
   "source": [
    "### Correlation between a single point the rest of the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32449107-df25-4c8b-ba6f-a4217bef0c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get SLP near Woods Hole\n",
    "T2m_woodshole = T2m_detrended.interp(latitude=41.5, longitude=288.5)\n",
    "\n",
    "## get correlation between Woods Hole T2m and North Atlantic SLP\n",
    "T2mWH_slp_corr = xr.corr(T2m_woodshole, slp_detrended, dim=\"year\")\n",
    "\n",
    "fig, ax = make_correlation_plot(T2mWH_slp_corr)\n",
    "ax.scatter(288.5, 41.5, marker=\"*\", c=\"k\", s=100)\n",
    "ax.set_title(r\"Correlation b/n Woods Hole SLP and $T_{2m}$ during winter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c3929d-2f31-40a9-a0da-68849dc680ac",
   "metadata": {},
   "source": [
    "(regridding)=\n",
    "## Regridding data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d60caf-b46a-4afd-9254-209398f7b9e4",
   "metadata": {},
   "source": [
    "Next, we're going to load data on a non-regular grid (tripolar, in this case). Specifically, we'll look at sea surface temperature (SST) from the MIROC6 model's historical simulation. We'll show how to plot the data on it's native grid and how to regrid it to a regular lon/lat grid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a2d667-3d4b-44e5-9541-7f24910a0d8e",
   "metadata": {},
   "source": [
    "Start by importing ```xesmf``` package for regridding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1314820f-258a-40f6-8432-4ec04c3cfbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xesmf as xe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8797d82-01a9-4a0c-a526-e3e9001892d2",
   "metadata": {},
   "source": [
    "First, load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a763ee-5ce6-4276-83fc-a3905098cea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify filename\n",
    "sst_fname = \"tos_Omon_MIROC6_historical_r1i1p1f1_gn_195001-201412.nc\"\n",
    "sst_path_to_file = pathlib.Path(sst_path, sst_fname)\n",
    "\n",
    "## open the data and trim in time\n",
    "sst_miroc6 = xr.open_dataset(sst_path_to_file)\n",
    "sst_miroc6 = sst_miroc6.isel(time=slice(-36, None)).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9cc258-1157-4d56-ae17-840fb0519b27",
   "metadata": {},
   "source": [
    "Next, regrid to a \"regular\" lon/lat grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2767c06b-4d2b-42a7-b049-29b5aba7bac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## should we use custom grid?\n",
    "use_custom_grid = True\n",
    "\n",
    "if use_custom_grid:\n",
    "    # create regular lon/lat grid\n",
    "    grid = xr.DataArray(\n",
    "        data=None,\n",
    "        coords={\"longitude\": np.arange(0, 360), \"latitude\": np.arange(-90, 91)},\n",
    "        dims=[\"longitude\", \"latitude\"],\n",
    "    )\n",
    "\n",
    "else:\n",
    "    # use ERA5 grid\n",
    "    grid = T2m_detrended.isel(year=0)\n",
    "\n",
    "## do the regridding\n",
    "regridder = xe.Regridder(ds_in=sst_miroc6, ds_out=grid, method=\"bilinear\")\n",
    "sst_miroc6_regridded = regridder(sst_miroc6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f47992-aee5-453e-8f2f-d226debdf2fa",
   "metadata": {},
   "source": [
    "Plot comparison of data on native and regular grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e58094-1c06-461b-af7b-fad1b972f210",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up the plot\n",
    "fig = plt.figure(figsize=(10, 2.5))\n",
    "\n",
    "## canvas for plot on native grid\n",
    "ax = fig.add_subplot(1, 2, 1, projection=ccrs.PlateCarree())\n",
    "ax, gl = plot_setup_north_atl(ax)\n",
    "\n",
    "## canvas for plot with regridded data\n",
    "ax_regridded = fig.add_subplot(1, 2, 2, projection=ccrs.PlateCarree())\n",
    "ax_regridded, gl_regridded = plot_setup_north_atl(ax_regridded)\n",
    "\n",
    "## Plot data on native grid\n",
    "ax.set_title(\"Native grid\")\n",
    "sst_plot = ax.pcolormesh(\n",
    "    sst_miroc6.longitude,\n",
    "    sst_miroc6.latitude,\n",
    "    sst_miroc6[\"tos\"].mean(\"time\"),\n",
    "    cmap=\"cmo.thermal\",\n",
    "    vmin=-2,\n",
    "    vmax=32,\n",
    ")\n",
    "cb = fig.colorbar(sst_plot)\n",
    "\n",
    "## Plot regridded data\n",
    "ax_regridded.set_title(\"Regridded\")\n",
    "xx, yy = np.meshgrid(sst_miroc6_regridded.longitude, sst_miroc6_regridded.latitude)\n",
    "sst_plot_regridded = ax_regridded.pcolormesh(\n",
    "    xx,\n",
    "    yy,\n",
    "    sst_miroc6_regridded[\"tos\"].mean(\"time\"),\n",
    "    cmap=\"cmo.thermal\",\n",
    "    vmin=-2,\n",
    "    vmax=32,\n",
    ")\n",
    "cb = fig.colorbar(sst_plot_regridded, ticks=[0, 10, 20, 30])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
