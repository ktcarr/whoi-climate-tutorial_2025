{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0294a2d1-ac11-44c6-8d4c-f09066b4ce27",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Example\n",
    "In this example, we'll use a single ensemble member from CESM1-LE to diagnose the forced response to external forcing near Woods Hole."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ea7642-50d7-4e56-b847-f9d0af63f9b5",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daaf53e-f603-40ac-b7a6-968a9eef13dc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import cmocean\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.ticker as mticker\n",
    "import copy\n",
    "import pandas as pd\n",
    "import time\n",
    "import intake\n",
    "import xesmf as xe\n",
    "\n",
    "## (optional) remove gridlines from plots\n",
    "sns.set(rc={\"axes.facecolor\": \"white\", \"axes.grid\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de6686d-1f50-4cd2-99e3-ec18c930e6c0",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ad8ace-6902-4bb7-8b3d-ea4c19d33506",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def trim(data, lon_range, lat_range):\n",
    "    \"\"\"select part of data in given longitude/latitude range\"\"\"\n",
    "\n",
    "    ## helper function to check if 'x' is in 'x_range'\n",
    "    isin_range = lambda x, x_range: (x_range[0] <= x) & (x <= x_range[1])\n",
    "\n",
    "    ## get mask for data in given lon/lat range\n",
    "    in_lon_range = isin_range(data[\"lon\"], lon_range)\n",
    "    in_lat_range = isin_range(data[\"lat\"], lat_range)\n",
    "    in_lonlat_range = in_lon_range & in_lat_range\n",
    "\n",
    "    ## load to memory\n",
    "    in_lonlat_range.load()\n",
    "\n",
    "    if \"nlon\" in data.dims:\n",
    "\n",
    "        ## Retain all points with at least one valid grid cell\n",
    "        x_idx = in_lonlat_range.any(\"nlat\")\n",
    "        y_idx = in_lonlat_range.any(\"nlon\")\n",
    "\n",
    "        return data.isel(nlon=x_idx, nlat=y_idx)\n",
    "\n",
    "    else:\n",
    "\n",
    "        return data.isel(lon=in_lon_range, lat=in_lat_range)\n",
    "\n",
    "\n",
    "def sort_longitude(data):\n",
    "    \"\"\"shuffles data so that longitude is monotonically increasing\"\"\"\n",
    "\n",
    "    ## Transpose data so that longitude is last dimension\n",
    "    ## (we'll do all the sorting along this dimension)\n",
    "    data = data.transpose(..., \"nlon\")\n",
    "\n",
    "    ## Get indices needed to sort longitude to be monotonic increasing\n",
    "    lon_sort_idx = np.argsort(data[\"lon\"].values, axis=-1)\n",
    "\n",
    "    ## sort the lon/lat coordindates\n",
    "    sort = lambda X, idx: np.take_along_axis(X.values, indices=idx, axis=-1)\n",
    "    data[\"lon\"].values = sort(data[\"lon\"], idx=lon_sort_idx)\n",
    "    data[\"lat\"].values = sort(data[\"lat\"], idx=lon_sort_idx)\n",
    "\n",
    "    #### sort the data\n",
    "\n",
    "    # first, check to see if data has more than two dimensions\n",
    "    if data.ndim > 2:\n",
    "        extra_dims = [i for i in range(data.ndim - 2)]\n",
    "        lon_sort_idx = np.expand_dims(lon_sort_idx, axis=extra_dims)\n",
    "\n",
    "    ## now, do the actual sorting\n",
    "    data.values = sort(data, idx=lon_sort_idx)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def swap_longitude_range(data):\n",
    "    \"\"\"swap longitude range of xr.DataArray from [0,360) to (-180, 180].\"\"\"\n",
    "\n",
    "    ## make copy of longitude coordinate to be modified\n",
    "    lon_new = copy.deepcopy(data.lon.values)\n",
    "\n",
    "    ## relabel values greater than 180\n",
    "    exceeds_180 = lon_new > 180\n",
    "    lon_new[exceeds_180] = -360 + lon_new[exceeds_180]\n",
    "\n",
    "    ## Update the coordinate on the xarray object\n",
    "    if \"lon\" in data.dims:\n",
    "        data = data.assign_coords({\"lon\": lon_new})\n",
    "\n",
    "    else:\n",
    "        data[\"lon\"].values = lon_new\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def plot_setup(fig, projection, lon_range, lat_range, xticks=None, yticks=None):\n",
    "    \"\"\"Add a subplot to the figure with the given map projection\n",
    "    and lon/lat range. Returns an Axes object.\"\"\"\n",
    "\n",
    "    ## increase resolution for projection\n",
    "    ## (otherwise lines plotted on surface won't follow curved trajectories)\n",
    "    projection.threshold /= 1000\n",
    "\n",
    "    ## Create subplot with given projection\n",
    "    ax = fig.add_subplot(projection=projection)\n",
    "\n",
    "    ## Subset to given region\n",
    "    extent = [*lon_range, *lat_range]\n",
    "    ax.set_extent(extent, crs=ccrs.PlateCarree())\n",
    "\n",
    "    ## draw coastlines\n",
    "    ax.coastlines(linewidths=0.5)\n",
    "\n",
    "    ## add tick labels\n",
    "    if xticks is not None:\n",
    "\n",
    "        ## add lon/lat labels\n",
    "        gl = ax.gridlines(\n",
    "            draw_labels=True,\n",
    "            linestyle=\"-\",\n",
    "            alpha=0.1,\n",
    "            linewidth=0.5,\n",
    "            color=\"k\",\n",
    "            zorder=1.05,\n",
    "        )\n",
    "\n",
    "        ## specify which axes to label\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "\n",
    "        ## specify ticks\n",
    "        gl.ylocator = mticker.FixedLocator(yticks)\n",
    "        gl.xlocator = mticker.FixedLocator(xticks)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_box_outline(ax, lon_range, lat_range, c=\"k\"):\n",
    "    \"\"\"\n",
    "    Plot box outlining the specifed lon/lat range on given\n",
    "    ax object.\n",
    "    \"\"\"\n",
    "\n",
    "    ## get width and height\n",
    "    height = lat_range[1] - lat_range[0]\n",
    "    width = lon_range[1] - lon_range[0]\n",
    "\n",
    "    ## add rectangle to plot\n",
    "    ax.add_patch(\n",
    "        mpatches.Rectangle(\n",
    "            xy=[lon_range[0], lat_range[0]],\n",
    "            height=height,\n",
    "            width=width,\n",
    "            transform=ccrs.PlateCarree(),\n",
    "            facecolor=\"none\",\n",
    "            edgecolor=c,\n",
    "            linewidth=1,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_setup_atlantic(fig):\n",
    "    \"\"\"Plot Atlantic region\"\"\"\n",
    "\n",
    "    ## adjust figure size\n",
    "    fig.set_size_inches(7.5, 3.75)\n",
    "\n",
    "    ## specify map projection\n",
    "    proj = ccrs.Orthographic(central_longitude=-50, central_latitude=40)\n",
    "\n",
    "    ## get ax object\n",
    "    ax = plot_setup(\n",
    "        fig,\n",
    "        proj,\n",
    "        lon_range=[-90, -10],\n",
    "        lat_range=[20, 60],\n",
    "        xticks=[-80, -50, -20],\n",
    "        yticks=[25, 45],\n",
    "    )\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def make_cb_range(amp, delta):\n",
    "    \"\"\"Make colorbar_range for cmo.balance\n",
    "    Args:\n",
    "        - 'amp': amplitude of maximum value for colorbar\n",
    "        - 'delta': increment for colorbar\n",
    "    \"\"\"\n",
    "    return np.concatenate(\n",
    "        [np.arange(-amp, 0, delta), np.arange(delta, amp + delta, delta)]\n",
    "    )\n",
    "\n",
    "\n",
    "def get_empirical_pdf(x, bin_edges=None):\n",
    "    \"\"\"\n",
    "    Estimate the \"empirical\" probability distribution function for the data x.\n",
    "    In this case the result is a normalized histogram,\n",
    "    Normalized means that integrating over the histogram yields 1.\n",
    "    Returns the PDF (normalized histogram) and edges of the histogram bins\n",
    "    \"\"\"\n",
    "\n",
    "    ## compute histogram\n",
    "    if bin_edges is None:\n",
    "        hist, bin_edges = np.histogram(x)\n",
    "\n",
    "    else:\n",
    "        hist, _ = np.histogram(x, bins=bin_edges)\n",
    "\n",
    "    ## normalize to a probability distribution (PDF)\n",
    "    bin_width = bin_edges[1:] - bin_edges[:-1]\n",
    "    pdf = hist / (hist * bin_width).sum()\n",
    "\n",
    "    return pdf, bin_edges\n",
    "\n",
    "\n",
    "def load_simulation(\n",
    "    server_fp, varname, member_id, simulation_type, preprocess_func=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Load dataset for single simulation, for single variable.\n",
    "    Arguments:\n",
    "        - varname: name of variable to load, one of {\"SST\",\"PSL\"}\n",
    "        - member_id: ID of ensemble member to load, an integer in the range [1,10]\n",
    "        - simulation_type: one of {\"hist\", \"rcp85\"}\n",
    "    Returns:\n",
    "        - xarray dataarray with given data\n",
    "    \"\"\"\n",
    "\n",
    "    ## Filepath to the CESM LENS dataset\n",
    "    lens_fp = pathlib.Path(\"cmip6/data/cmip6/CMIP/NCAR/LENS\")\n",
    "\n",
    "    #### 1. get filepath to data\n",
    "    data_fp = server_fp / lens_fp / pathlib.Path(varname)\n",
    "\n",
    "    #### 2. get naming pattern for files to open\n",
    "    if simulation_type == \"hist\":\n",
    "        file_pattern = f\"*20TRC*.{member_id:03d}.*.nc\"\n",
    "\n",
    "    elif simulation_type == \"rcp85\":\n",
    "        file_pattern = f\"*RCP85*.{member_id:03d}.*.nc\"\n",
    "\n",
    "    else:\n",
    "        print(\"Not a valid simulation type\")\n",
    "\n",
    "    #### 3. open the relevant datasets, applying preprocessing function\n",
    "\n",
    "    ## filepath to data\n",
    "    fp = list(data_fp.glob(file_pattern))[0]\n",
    "\n",
    "    ## load data\n",
    "    data = xr.open_dataset(fp, chunks=None, decode_timedelta=True)\n",
    "\n",
    "    ## apply (optional) preprocessing\n",
    "    if preprocess_func is not None:\n",
    "        data = preprocess_func(data)\n",
    "\n",
    "    return data[varname].squeeze(drop=True)\n",
    "\n",
    "\n",
    "def get_trend(data, dim=\"time\", deg=1):\n",
    "    \"\"\"\n",
    "    Get trend for an xr.dataarray along specified dimension,\n",
    "    by fitting polynomial of degree 'deg'.\n",
    "    \"\"\"\n",
    "\n",
    "    ## Get coefficients for best fit\n",
    "    polyfit_coefs = data.polyfit(dim=dim, deg=deg)[\"polyfit_coefficients\"]\n",
    "\n",
    "    ## Get best fit line (linear trend in this case)\n",
    "    trend = xr.polyval(data[dim], polyfit_coefs)\n",
    "\n",
    "    return trend\n",
    "\n",
    "\n",
    "def detrend(data, dim=\"time\", deg=1):\n",
    "    \"\"\"\n",
    "    Remove trend of degree 'deg' from data, along dimension 'dim'.\n",
    "    \"\"\"\n",
    "\n",
    "    return data - get_trend(data, dim=dim, deg=deg)\n",
    "\n",
    "\n",
    "def spatial_avg(data):\n",
    "    \"\"\"function to compute spatial average of data on grid with constant\n",
    "    longitude/latitude spacing.\"\"\"\n",
    "\n",
    "    ## first, compute cosine of latitude (after converting degrees to radians)\n",
    "    latitude_radians = np.deg2rad(data.lat)\n",
    "    cos_lat = np.cos(latitude_radians)\n",
    "\n",
    "    ## get weighted average using xarray\n",
    "    avg = data.weighted(weights=cos_lat).mean([\"lon\", \"lat\"])\n",
    "\n",
    "    return avg\n",
    "\n",
    "\n",
    "def load_cesm_from_cloud(\n",
    "    lon_range, lat_range, varname=\"TREFHT\", load_ssp370=False, member_id=1\n",
    "):\n",
    "    \"\"\"Load CESM data from cloud. Args:\n",
    "    - lon_range, lat_range: each is a two-element array\n",
    "    - varname: variable to load (\"TREFHT\" is 2m-temperature)\n",
    "    - load_ssp370: bool; if True, load historical AND ssp370 simulations\n",
    "    - member_id: index of ensemble member to load\n",
    "    \"\"\"\n",
    "\n",
    "    ## get catalog of available data\n",
    "    catalog = intake.open_esm_datastore(\n",
    "        \"https://raw.githubusercontent.com/NCAR/cesm2-le-aws/main/intake-catalogs/aws-cesm2-le.json\"\n",
    "    )\n",
    "\n",
    "    ## subset for temperature data\n",
    "    ## to look at available data, use: catalog.df\n",
    "    catalog_subset = catalog.search(variable=varname, frequency=\"monthly\")\n",
    "\n",
    "    ## kwargs for opening data\n",
    "    kwargs = dict(\n",
    "        aggregate=True,\n",
    "        xarray_open_kwargs=dict(engine=\"zarr\", decode_timedelta=True),\n",
    "        zarr_kwargs={\"consolidated\": True},\n",
    "        storage_options={\"anon\": True},\n",
    "    )\n",
    "\n",
    "    ## open data (but don't load to memory)\n",
    "    dsets = catalog_subset.to_dataset_dict(**kwargs)\n",
    "    data = dsets[\"atm.historical.monthly.cmip6\"]\n",
    "\n",
    "    ## optionally load ssp data as well\n",
    "    if load_ssp370:\n",
    "        data = xr.concat([data, dsets[\"atm.ssp370.monthly.cmip6\"]], dim=\"time\")\n",
    "\n",
    "    ## trim data (select ensemble members and lon/lat space)\n",
    "    lonlat_idx = dict(lon=slice(*lon_range), lat=slice(*lat_range))\n",
    "    data = data.sel(lonlat_idx).isel(member_id=member_id)\n",
    "\n",
    "    ## convert kelvin to celsius\n",
    "    data = data[varname] - 273.15\n",
    "\n",
    "    ## swap longitude range\n",
    "    data = swap_longitude_range(data)\n",
    "\n",
    "    ## load to memory\n",
    "    data = data.compute()\n",
    "\n",
    "    ## regrid with land-sea mask\n",
    "    ## load land-sea mask (used for interpolation)\n",
    "    lsm = load_lsm_from_cloud(lon_range=lon_range, lat_range=lat_range)\n",
    "    regridder = xe.Regridder(data, lsm, \"bilinear\", ignore_degenerate=False)\n",
    "    data = regridder(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_cesm_from_server(lon_range, lat_range, server_fp, varname, member_id=10):\n",
    "    \"\"\"Load specified CESM1-LE ensemble member from CMIP server\"\"\"\n",
    "\n",
    "    ## shared arguments for loading data\n",
    "    load_kwargs = dict(server_fp=server_fp, varname=varname, member_id=member_id)\n",
    "\n",
    "    ## Load data\n",
    "    data_hist = load_simulation(simulation_type=\"hist\", **load_kwargs).compute()\n",
    "    data_rcp = load_simulation(simulation_type=\"rcp85\", **load_kwargs).compute()\n",
    "\n",
    "    ## concatenate in time\n",
    "    data = xr.concat([data_hist, data_rcp], dim=\"time\")\n",
    "\n",
    "    ## rename coordinates for convenience\n",
    "    data = data.rename({\"TLONG\": \"lon\", \"TLAT\": \"lat\"})\n",
    "\n",
    "    ## subset data by longitude\n",
    "    data = trim(data, lon_range=[260, 360], lat_range=[0, 70])\n",
    "\n",
    "    ## swap longitude range from [0,360) to (-180, 180]\n",
    "    data = swap_longitude_range(data)\n",
    "\n",
    "    ## make sure longitude is in ascending order\n",
    "    data = sort_longitude(data)\n",
    "\n",
    "    ## interpolate onto land-sea mask with regular grid\n",
    "    lsm = load_lsm_from_server(server_fp, lon_range=lon_range, lat_range=lat_range)\n",
    "    regridder = xe.Regridder(data, lsm, \"bilinear\", ignore_degenerate=False)\n",
    "    data = regridder(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def prep_lsm(lsm, lon_range, lat_range):\n",
    "    \"\"\"Prepare land-sea mask by renaming coords,\n",
    "    downsampling to 1x1 grid, and selecting specified lon/lat range\"\"\"\n",
    "\n",
    "    ## rename coords\n",
    "    lsm = lsm.rename({\"latitude\": \"lat\", \"longitude\": \"lon\"})\n",
    "\n",
    "    ## get coords for interpolation (downscale to 1x1 grid)\n",
    "    lon = np.arange(lon_range[0], lon_range[1] + 1, 1)\n",
    "    lat = np.arange(lat_range[0], lat_range[1] + 1, 1)\n",
    "    new_coords = dict(lon=lon, lat=lat)\n",
    "\n",
    "    ## interpolate to grid\n",
    "    lsm = lsm.interp(new_coords)\n",
    "\n",
    "    ## add binary mask for regridding\n",
    "    lsm[\"mask\"] = (lsm < 0.5).astype(int)\n",
    "\n",
    "    return lsm.transpose(\"lat\", \"lon\")\n",
    "\n",
    "\n",
    "def load_lsm_from_cloud(lon_range, lat_range):\n",
    "    \"\"\"Load ERA5 land-sea-mask from Google server\"\"\"\n",
    "\n",
    "    ## use ERA5 land-sea mask\n",
    "    data = xr.open_zarr(\n",
    "        \"gs://weatherbench2/datasets/era5/1959-2023_01_10-wb13-6h-1440x721_with_derived_variables.zarr\",\n",
    "    )\n",
    "\n",
    "    ## load lsm into memory\n",
    "    lsm = data[\"land_sea_mask\"].compute()\n",
    "\n",
    "    return prep_lsm(lsm, lon_range=lon_range, lat_range=lat_range)\n",
    "\n",
    "\n",
    "def load_lsm_from_server(server_fp, lon_range=[0, 360], lat_range=[-90, 90]):\n",
    "    \"\"\"Load ERA5 land-sea-mask from CMIP6 server\"\"\"\n",
    "\n",
    "    ## get server path to ERA5 land sea mask\n",
    "    lsm_fp = server_fp / pathlib.Path(\n",
    "        \"cmip6/data/era5/reanalysis/single-levels/monthly-means/land_sea_mask/2020_land_sea_mask.nc\"\n",
    "    )\n",
    "\n",
    "    ## open lsm\n",
    "    lsm = xr.open_dataarray(lsm_fp).isel(time=0).drop_vars(\"time\")\n",
    "\n",
    "    return prep_lsm(lsm, lon_range=lon_range, lat_range=lat_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333948ce-71b3-45c2-a758-89326cac7d36",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65329af-344f-4b7e-92da-1d12401f1dd1",
   "metadata": {},
   "source": [
    "````{admonition} To-do\n",
    "Update the filepaths ```SERVER_FP``` and ```save_fp``` in the code cell below.\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7cee7e-3ddf-4903-a8d5-a4c64a87210d",
   "metadata": {},
   "source": [
    "````{warning} CMIP server errors\n",
    "The CMIP server seems unable to handle multiple users access the same file at once (e.g., during the actual tutorial session). If you get a mysterious error when trying to load data from the server (e.g., ```NetCDF: HDF error```), try loading the data from the cloud instead (i.e., set ```LOAD_FROM_CLOUD = True``` in the code cell below).\n",
    "\n",
    "In order to load data from Google Cloud storage, you need to have the following packages installed:\n",
    "```\n",
    "- gcsfs\n",
    "- s3fs\n",
    "- intake-esm\n",
    "```\n",
    "You can install them with ```mamba``` using:\n",
    "```\n",
    "mamba install -n my_new_env -c conda-forge gcsfs s3fs intake-esm\n",
    "```\n",
    "where ```my_new_env``` is the name of your virtual environment.\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd30b754-868e-45fe-a18e-c7ff93b59027",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## should we load from the cloud?\n",
    "LOAD_FROM_CLOUD = False\n",
    "\n",
    "## Path to file server\n",
    "SERVER_FP = pathlib.Path(\"/Volumes\")\n",
    "\n",
    "## specify lon/lat range\n",
    "LON_RANGE = [260, 359.9]\n",
    "LAT_RANGE = [0, 70]\n",
    "\n",
    "## arguments shared by each loading function (server and cloud)\n",
    "shared_args = dict(lon_range=LON_RANGE, lat_range=LAT_RANGE, member_id=10)\n",
    "\n",
    "## keep track of loading time\n",
    "t0 = time.time()\n",
    "\n",
    "if LOAD_FROM_CLOUD:\n",
    "    data = load_cesm_from_cloud(varname=\"TREFHT\", load_ssp370=True, **shared_args)\n",
    "\n",
    "else:\n",
    "    data = load_cesm_from_server(varname=\"SST\", server_fp=SERVER_FP, **shared_args)\n",
    "\n",
    "print(f\"Elapsed time: {time.time()-t0:.1f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce44867-060f-4911-aa54-2acb54e9efcc",
   "metadata": {},
   "source": [
    "### Trim in lon/lat space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cdfa35-fd05-4a25-85b1-4bfe39b8f7cb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "````{admonition} To-do\n",
    "If you'd like to look at a different region, change ```lon_range``` and ```lat_range``` in the preprocessing function below.\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80443352-e67f-4004-ae26-6a71bfc050c5",
   "metadata": {},
   "source": [
    "### Downsample from monthly to seasonal averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f126c76-73f5-472a-8464-9584420dd3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get seasonal averages (omit first/last timesteps)\n",
    "## (resample from monthly to quarterly starting with December, \"QS-DEC\")\n",
    "## averages will be: \"DJF\", \"MAM\", \"JJA\", \"SON\"\n",
    "data = data.resample({\"time\": \"QS-DEC\"}).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d314c3-21bb-442d-a21e-9c3975c19be9",
   "metadata": {},
   "source": [
    "### Plot a sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7004dbeb-28b0-430f-9f6f-fd5382cdb290",
   "metadata": {},
   "source": [
    "````{admonition} To-do\n",
    "If you're not looking at Woods Hole, you may need to adapt the plotting function below (```plot_setup_atlantic```).\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf7619b-ed04-4c0f-bcc2-66b659ff0a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "## blank canvas\n",
    "fig = plt.figure()\n",
    "\n",
    "## plot background\n",
    "fig, ax = plot_setup_atlantic(fig)\n",
    "\n",
    "## plot the data\n",
    "plot_data = ax.pcolormesh(\n",
    "    data.lon,\n",
    "    data.lat,\n",
    "    data.isel(time=0),\n",
    "    cmap=\"cmo.thermal\",\n",
    "    vmax=27,\n",
    "    vmin=-6,\n",
    "    # levels=np.arange(-6, 30, 3),\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    # extend=\"both\",\n",
    ")\n",
    "\n",
    "## make a colorbar\n",
    "cb = fig.colorbar(plot_data, ticks=[-3, 12, 27])\n",
    "\n",
    "## plot outline of region\n",
    "ax = plot_box_outline(ax, lon_range=[287.5, 293.5], lat_range=[39, 44])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d351eff-fdf0-42ac-ad9f-aaac49259080",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Woods Hole SST index over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2c49dc-0c82-49d3-9045-1f1cc630f150",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Compute index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99dcfda-c529-43b4-b109-bcd9586dca29",
   "metadata": {},
   "source": [
    "````{admonition} To-do\n",
    "If you'd like to look at a different index, modify the function below.\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b47df93-7ca4-4023-a3b6-adcf22e6017b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_T_wh(x):\n",
    "    \"\"\"Compute Woods Hole temperature index\"\"\"\n",
    "\n",
    "    ## get subset of data inside the box\n",
    "    lonlat_idx = dict(lon=slice(287.5, 293.5), lat=slice(39, 44))\n",
    "    data_subset = x.sel(lonlat_idx)\n",
    "\n",
    "    return spatial_avg(data_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96cc01a-d4ff-41c6-9eda-70ad209c782a",
   "metadata": {},
   "source": [
    "Do the computational, and get seasonal averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c8f793-f587-4f23-9e4c-4bf89120ea36",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## do the computation here\n",
    "idx = compute_T_wh(data)\n",
    "\n",
    "## compute SON average\n",
    "is_son = idx.time.dt.month == 9\n",
    "idx_son = idx.isel(time=is_son)\n",
    "idx_son[\"time\"] = idx_son.time.dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bea78c-1401-438a-853b-624f255ff55a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### SON trend and anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe495904-03de-40ee-b114-0f15ec32f974",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## compute trends (linear and quadratic)\n",
    "idx_son_trend1 = get_trend(idx_son, dim=\"time\", deg=1)\n",
    "idx_son_trend2 = get_trend(idx_son, dim=\"time\", deg=2)\n",
    "\n",
    "## estimate anomalies (using quadratic)\n",
    "idx_son_anom = idx_son - idx_son_trend2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fecc6d-f31c-4b39-8a7e-a2282a11f9bd",
   "metadata": {},
   "source": [
    "#### Plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf2317c-0b07-44f5-83c5-2a5b1d684c49",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def setup_trend_plot():\n",
    "    \"\"\"create fig and axs for plotting trends\"\"\"\n",
    "\n",
    "    ## blank canvas\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(7, 2.75), layout=\"constrained\")\n",
    "\n",
    "    #### label plots\n",
    "    for ax in axs:\n",
    "        ax.set_xticks([1920, 2006, 2080])\n",
    "        ax.set_xlabel(\"Year\")\n",
    "        ax.set_ylabel(r\"$^{\\circ}$C\")\n",
    "\n",
    "    axs[0].set_yticks([22, 24.5, 27])\n",
    "    axs[1].set_yticks([-1, 0, 1])\n",
    "    axs[0].set_title(\"Total\")\n",
    "    axs[1].set_title(\"Anomaly\")\n",
    "    axs[1].axhline(0, c=\"k\", zorder=0.5, lw=0.5)\n",
    "    axs[1].yaxis.tick_right()\n",
    "    axs[1].yaxis.set_label_position(\"right\")\n",
    "\n",
    "    for ax in axs:\n",
    "        ## plot boundary between HIST and RCP\n",
    "        ax.axvline(2006, ls=\"--\", lw=0.5, c=\"k\")\n",
    "\n",
    "    return fig, axs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d916049e-b4d0-4726-9b9c-5f3a8ec31c51",
   "metadata": {},
   "source": [
    "#### Make the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3b6e55-5b7d-4bcd-958b-52fd109ddeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = setup_trend_plot()\n",
    "\n",
    "## plot raw index\n",
    "axs[0].plot(idx_son.time, idx_son, c=\"gray\", label=\"Raw\")\n",
    "\n",
    "# get list for (i) trends and (ii) corresponding linestyles\n",
    "trends = [idx_son_trend1, idx_son_trend2]\n",
    "linestyles = [\"--\", \"-\"]\n",
    "\n",
    "# plot each trend with corresponding linestyle\n",
    "for i, (trend, ls) in enumerate(zip(trends, linestyles), start=1):\n",
    "\n",
    "    kwargs = dict(c=\"r\", ls=ls, label=f\"Trend (degree {i})\")\n",
    "    axs[0].plot(trend.time, trend, **kwargs)\n",
    "\n",
    "## on RHS sub-panel, plot anomalies\n",
    "axs[1].plot(idx_son_anom.time, idx_son_anom, c=\"gray\")\n",
    "\n",
    "## add legend\n",
    "axs[0].legend(prop=dict(size=8))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491f5527-9050-44af-a5ca-3e0582989e04",
   "metadata": {},
   "source": [
    "## Spatial pattern of warming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597b235f-2578-4539-92e8-911431891ca2",
   "metadata": {},
   "source": [
    "#### Function to compute climatology for given period and month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893c8897-35e2-410d-aed5-1f53e40d8786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clim(data, yr_range, QS_month=9):\n",
    "    \"\"\"function to get SON climatology for specified range\"\"\"\n",
    "\n",
    "    ## find samples in given quarter\n",
    "    in_quarter = data.time.dt.month == QS_month\n",
    "\n",
    "    ## subset for samples in quarter\n",
    "    data_subset = data.sel(time=in_quarter)\n",
    "\n",
    "    ## subset for samples in year range\n",
    "    data_subset = data_subset.sel(time=slice(*yr_range))\n",
    "\n",
    "    ## average in time\n",
    "    return data_subset.mean(\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd82602-dd7a-4e61-99eb-89f3e206634e",
   "metadata": {},
   "source": [
    "#### Do computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca99f74d-ae3a-4dcc-bdad-0c8c3cf73cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compare SON averages in two 30-yr periods\n",
    "yr_range0 = [\"1980\", \"2010\"]\n",
    "yr_range1 = [\"2050\", \"2080\"]\n",
    "\n",
    "## get SON climatology for each period\n",
    "clim0 = get_clim(data, yr_range=yr_range0, QS_month=9)\n",
    "clim1 = get_clim(data, yr_range=yr_range1, QS_month=9)\n",
    "\n",
    "## get difference\n",
    "delta_clim = clim1 - clim0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13accc7f-8917-4df6-b449-91cfce807c05",
   "metadata": {},
   "source": [
    "#### Plot difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8440392-8f5c-4bab-8bf2-f9da20c92d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set colorbar levels\n",
    "if LOAD_FROM_CLOUD:\n",
    "    plot_kwargs = dict(vmin=-3, vmax=3, cmap=\"cmo.balance\")\n",
    "    ticks = [-3, 0, 3]\n",
    "\n",
    "else:\n",
    "    plot_kwargs = dict(vmin=1, vmax=4, cmap=\"cmo.amp\")\n",
    "    ticks = [1, 4]\n",
    "\n",
    "## blank canvas\n",
    "fig = plt.figure()\n",
    "\n",
    "## plot background\n",
    "fig, ax = plot_setup_atlantic(fig)\n",
    "\n",
    "## plot the difference\n",
    "plot_data = ax.pcolormesh(\n",
    "    data.lon,\n",
    "    data.lat,\n",
    "    delta_clim,\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    **plot_kwargs,\n",
    ")\n",
    "\n",
    "## plot the background state\n",
    "ax.contour(\n",
    "    data.lon,\n",
    "    data.lat,\n",
    "    clim0,\n",
    "    colors=\"w\",\n",
    "    levels=np.arange(-2, 34, 4),\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    extend=\"both\",\n",
    "    linewidths=1,\n",
    "    alpha=0.7,\n",
    ")\n",
    "\n",
    "## make a colorbar\n",
    "cb = fig.colorbar(plot_data, ticks=ticks, label=r\"$^{\\circ}$C\")\n",
    "\n",
    "## plot outline of Woods Hole region\n",
    "ax = plot_box_outline(ax, lon_range=[287.5, 293.5], lat_range=[39, 44])\n",
    "\n",
    "## plot outline of warming hole region\n",
    "ax = plot_box_outline(ax, lon_range=[323, 343], lat_range=[45, 55])\n",
    "\n",
    "## label\n",
    "ax.set_title(r\"$\\Delta$(T) b/n 1980-2010 and 2050-2080\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91be0c50-11c0-4458-9338-d296a68487a1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Assess robustness in forced changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0622d813-854b-4069-a0b7-78e70aab65ed",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Compute warming hole index (as comparison point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a27dfc-92d3-4fe8-a3ff-9a5e9d0d0b33",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_warming_hole_idx(x):\n",
    "    \"\"\"Compute Woods Hole temperature index\"\"\"\n",
    "\n",
    "    ## get subset of data inside the box\n",
    "    lonlat_idx = dict(lon=slice(323, 343), lat=slice(45, 55))\n",
    "    data_subset = x.sel(lonlat_idx)\n",
    "\n",
    "    ## compute spatial average\n",
    "    return spatial_avg(data_subset)\n",
    "\n",
    "\n",
    "idx_warminghole = compute_warming_hole_idx(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3341e8f-013f-4022-9e2e-3a30efe64068",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Function to compute PDF for specified (i) year range and (ii) season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f688906-af51-4fef-8442-0a9cab609eac",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def get_pdf_helper(data, yr_range, bin_edges, QS_month=9):\n",
    "    \"\"\"function to get SON climatology for specified range\"\"\"\n",
    "\n",
    "    if QS_month is not None:\n",
    "\n",
    "        ## find samples in given quarter\n",
    "        in_quarter = data.time.dt.month == QS_month\n",
    "\n",
    "        ## subset for samples in quarter\n",
    "        data_subset = data.sel(time=in_quarter)\n",
    "\n",
    "    else:\n",
    "        data_subset = data\n",
    "\n",
    "    ## subset for samples in year range\n",
    "    data_subset = data_subset.sel(time=slice(*yr_range))\n",
    "\n",
    "    ## compute PDF\n",
    "    pdf, _ = get_empirical_pdf(data_subset, bin_edges)\n",
    "\n",
    "    ## average in time\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2225a52a-36b9-4005-8770-30a2afc397ea",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Compute PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eadf9ee-8c54-4c11-b701-837e546669e1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## specify edges for PDFs\n",
    "if LOAD_FROM_CLOUD:\n",
    "    edges_woodshole = np.arange(17, 23.3, 0.4)\n",
    "    edges_warminghole = np.arange(10, 16.2, 0.4)\n",
    "\n",
    "else:\n",
    "    edges_woodshole = np.arange(21.6, 28, 0.4)\n",
    "    edges_warminghole = np.arange(13, 19.2, 0.4)\n",
    "\n",
    "## for Woods Hole idx\n",
    "pdf_woodshole0 = get_pdf_helper(idx, yr_range0, bin_edges=edges_woodshole)\n",
    "pdf_woodshole1 = get_pdf_helper(idx, yr_range1, bin_edges=edges_woodshole)\n",
    "\n",
    "## for warming hole index\n",
    "pdf_warminghole0 = get_pdf_helper(\n",
    "    idx_warminghole, yr_range0, bin_edges=edges_warminghole\n",
    ")\n",
    "pdf_warminghole1 = get_pdf_helper(\n",
    "    idx_warminghole, yr_range1, bin_edges=edges_warminghole\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c49cd94-2d7c-4948-9e91-3bde9ab6cdc1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Plot PDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9b6b94-1cb3-4ad2-9c12-072c8bbe4cff",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Function to setup plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e40eb8-f12c-4981-90c5-790322ce3615",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_setup_pdfs():\n",
    "    \"\"\"Plot background for PDFs\"\"\"\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(6, 2.5), layout=\"constrained\")\n",
    "\n",
    "    ## format/label axes\n",
    "    axs[1].set_yticks([])\n",
    "    axs[0].set_title(\"Woods Hole\")\n",
    "    axs[1].set_title(\"'Warming hole'\")\n",
    "    axs[0].set_ylabel(\"Prob. density\")\n",
    "    axs[0].set_yticks([0, 0.5, 1])\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_xlabel(r\"$^{\\circ}$C\")\n",
    "\n",
    "    return fig, axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13264d3-1d05-4dc6-bd48-773a2b756287",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up plot\n",
    "fig, axs = plot_setup_pdfs()\n",
    "\n",
    "## plot woods hole index\n",
    "axs[0].stairs(pdf_woodshole0, edges_woodshole, label=\"1980-2010\")\n",
    "axs[0].stairs(pdf_woodshole1, edges_woodshole, ls=\"--\", label=\"2050-2080\")\n",
    "\n",
    "## plot warming hole index\n",
    "axs[1].stairs(pdf_warminghole0, edges_warminghole)\n",
    "axs[1].stairs(pdf_warminghole1, edges_warminghole, ls=\"--\")\n",
    "\n",
    "## format/label axes\n",
    "axs[1].set_ylim(axs[0].get_ylim())\n",
    "axs[0].legend(prop=dict(size=8))\n",
    "axs[0].set_xticks([edges_woodshole.min(), edges_woodshole.max()])\n",
    "axs[1].set_xticks([edges_warminghole.min(), edges_warminghole.max()])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c527ea-e3f5-4bd0-9a87-e2dbd6751b34",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Look at changes in internal variability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd81a24-8cce-42fe-a093-73dbe849744e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Detrend both indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a551a4-e2d8-477d-a608-76d22e51bdb3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detrend_bymonth(x):\n",
    "    \"\"\"detrend given index with 2nd degree polynomial\"\"\"\n",
    "\n",
    "    ## function to quadratic detrend\n",
    "    detrend_quadratic = lambda x: detrend(x, dim=\"time\", deg=2)\n",
    "\n",
    "    ## apply quadratic detrending to each month separately\n",
    "    return x.groupby(\"time.month\").map(detrend_quadratic)\n",
    "\n",
    "\n",
    "## apply detrending\n",
    "idx_anom = detrend_bymonth(idx)\n",
    "idx_warminghole_anom = detrend_bymonth(idx_warminghole)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b24540e-5c34-4742-9d31-9f27b18456bd",
   "metadata": {},
   "source": [
    "### Compute PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21e8e4e-1c9d-4643-9f53-fbbded892946",
   "metadata": {},
   "outputs": [],
   "source": [
    "## shared arguments for PDFs\n",
    "edges = 0.125 + np.arange(-1.5, 1.5, 0.25)\n",
    "kwargs = dict(bin_edges=edges, QS_month=None)\n",
    "\n",
    "# ## for Woods Hole idx\n",
    "pdf_woodshole0 = get_pdf_helper(idx_anom, yr_range0, **kwargs)\n",
    "pdf_woodshole1 = get_pdf_helper(idx_anom, yr_range1, **kwargs)\n",
    "\n",
    "## for warming hole index\n",
    "pdf_warminghole0 = get_pdf_helper(idx_warminghole_anom, yr_range0, **kwargs)\n",
    "pdf_warminghole1 = get_pdf_helper(idx_warminghole_anom, yr_range1, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d8547d-881a-46f8-bb9b-3af6dfe577f3",
   "metadata": {},
   "source": [
    "### Plot PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffea271d-c737-4d6b-b802-1f7ed63bd3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up plot\n",
    "fig, axs = plot_setup_pdfs()\n",
    "\n",
    "## plot woods hole index\n",
    "axs[0].stairs(pdf_woodshole0, edges, label=\"1980-2010\")\n",
    "axs[0].stairs(pdf_woodshole1, edges, ls=\"--\", label=\"2050-2080\")\n",
    "\n",
    "## plot warming hole index\n",
    "axs[1].stairs(pdf_warminghole0, edges)\n",
    "axs[1].stairs(pdf_warminghole1, edges, ls=\"--\")\n",
    "\n",
    "## format/label axes\n",
    "axs[1].set_ylim(axs[0].get_ylim())\n",
    "axs[0].legend(prop=dict(size=8))\n",
    "\n",
    "for ax in axs:\n",
    "    ax.axvline(0, c=\"k\", lw=0.5)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
