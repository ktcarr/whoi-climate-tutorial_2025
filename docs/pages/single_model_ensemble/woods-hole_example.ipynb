{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0294a2d1-ac11-44c6-8d4c-f09066b4ce27",
   "metadata": {},
   "source": [
    "# Example\n",
    "In this example, we'll use CESM1-LE to diagnose the forced response to external forcing near Woods Hole.  \n",
    "{download}`Download notebook<./woods-hole_example.ipynb>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ea7642-50d7-4e56-b847-f9d0af63f9b5",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daaf53e-f603-40ac-b7a6-968a9eef13dc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import cmocean\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.ticker as mticker\n",
    "import scipy.signal\n",
    "import copy\n",
    "import pandas as pd\n",
    "import time\n",
    "import intake\n",
    "\n",
    "# this package shows our data loading progress\n",
    "# Install, import, and then change the data loading line in the load_ensemble_helper func if you want to use\n",
    "# import tqdm\n",
    "\n",
    "## (optional) remove gridlines from plots\n",
    "sns.set(rc={\"axes.facecolor\": \"white\", \"axes.grid\": False})\n",
    "\n",
    "## should we save figs?\n",
    "SAVE_FIGS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de6686d-1f50-4cd2-99e3-ec18c930e6c0",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ad8ace-6902-4bb7-8b3d-ea4c19d33506",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def trim(data, lon_range, lat_range):\n",
    "    \"\"\"select part of data in given longitude/latitude range\"\"\"\n",
    "\n",
    "    ## check if data is on the \"T\"-grid\n",
    "    on_Tgrid = \"TLONG\" in data.coords\n",
    "\n",
    "    ## handle trimming for T-grid\n",
    "    if on_Tgrid:\n",
    "\n",
    "        ## helper function to check if 'x' is in 'x_range'\n",
    "        isin_range = lambda x, x_range: (x_range[0] <= x) & (x <= x_range[1])\n",
    "\n",
    "        ## get mask for data in given lon/lat range\n",
    "        in_lon_range = isin_range(data[\"TLONG\"], lon_range)\n",
    "        in_lat_range = isin_range(data[\"TLAT\"], lat_range)\n",
    "        in_lonlat_range = in_lon_range & in_lat_range\n",
    "\n",
    "        ## load to memory\n",
    "        in_lonlat_range.load()\n",
    "\n",
    "        ## Retain all points with at least one valid grid cell\n",
    "        x_idx = in_lonlat_range.any(\"nlat\")\n",
    "        y_idx = in_lonlat_range.any(\"nlon\")\n",
    "\n",
    "        ## select given points\n",
    "        return data.isel(nlon=x_idx, nlat=y_idx)\n",
    "\n",
    "    else:\n",
    "        return data.sel(lon=slice(*lon_range), lat=slice(*lat_range))\n",
    "\n",
    "\n",
    "def plot_setup(fig, projection, lon_range, lat_range, xticks=None, yticks=None):\n",
    "    \"\"\"Add a subplot to the figure with the given map projection\n",
    "    and lon/lat range. Returns an Axes object.\"\"\"\n",
    "\n",
    "    ## increase resolution for projection\n",
    "    ## (otherwise lines plotted on surface won't follow curved trajectories)\n",
    "    projection.threshold /= 1000\n",
    "\n",
    "    ## Create subplot with given projection\n",
    "    ax = fig.add_subplot(projection=projection)\n",
    "\n",
    "    ## Subset to given region\n",
    "    extent = [*lon_range, *lat_range]\n",
    "    ax.set_extent(extent, crs=ccrs.PlateCarree())\n",
    "\n",
    "    ## draw coastlines\n",
    "    ax.coastlines(linewidths=0.5)\n",
    "\n",
    "    ## add tick labels\n",
    "    if xticks is not None:\n",
    "\n",
    "        ## add lon/lat labels\n",
    "        gl = ax.gridlines(\n",
    "            draw_labels=True,\n",
    "            linestyle=\"-\",\n",
    "            alpha=0.1,\n",
    "            linewidth=0.5,\n",
    "            color=\"k\",\n",
    "            zorder=1.05,\n",
    "        )\n",
    "\n",
    "        ## specify which axes to label\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "\n",
    "        ## specify ticks\n",
    "        gl.ylocator = mticker.FixedLocator(yticks)\n",
    "        gl.xlocator = mticker.FixedLocator(xticks)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_box_outline(ax, lon_range, lat_range, c=\"k\"):\n",
    "    \"\"\"\n",
    "    Plot box outlining the specifed lon/lat range on given\n",
    "    ax object.\n",
    "    \"\"\"\n",
    "\n",
    "    ## get width and height\n",
    "    height = lat_range[1] - lat_range[0]\n",
    "    width = lon_range[1] - lon_range[0]\n",
    "\n",
    "    ## add rectangle to plot\n",
    "    ax.add_patch(\n",
    "        mpatches.Rectangle(\n",
    "            xy=[lon_range[0], lat_range[0]],\n",
    "            height=height,\n",
    "            width=width,\n",
    "            transform=ccrs.PlateCarree(),\n",
    "            facecolor=\"none\",\n",
    "            edgecolor=c,\n",
    "            linewidth=1,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_setup_woodshole(fig):\n",
    "    \"\"\"Plot zoomed-in view of Woods Hole\"\"\"\n",
    "\n",
    "    ## adjust figure size\n",
    "    fig.set_size_inches(5, 3)\n",
    "\n",
    "    ## set map projection to orthographic\n",
    "    proj = ccrs.Orthographic(central_longitude=-67.5, central_latitude=40)\n",
    "\n",
    "    ## Get ax object based on generic plotting function\n",
    "    ax = plot_setup(\n",
    "        fig,\n",
    "        proj,\n",
    "        lon_range=[-80, -60],\n",
    "        lat_range=[35, 45],\n",
    "        xticks=[-80, -70, -60],\n",
    "        yticks=[35, 40, 45],\n",
    "    )\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def make_cb_range(amp, delta):\n",
    "    \"\"\"Make colorbar_range for cmo.balance\n",
    "    Args:\n",
    "        - 'amp': amplitude of maximum value for colorbar\n",
    "        - 'delta': increment for colorbar\n",
    "    \"\"\"\n",
    "    return np.concatenate(\n",
    "        [np.arange(-amp, 0, delta), np.arange(delta, amp + delta, delta)]\n",
    "    )\n",
    "\n",
    "\n",
    "def get_empirical_pdf(x, bin_edges=None):\n",
    "    \"\"\"\n",
    "    Estimate the \"empirical\" probability distribution function for the data x.\n",
    "    In this case the result is a normalized histogram,\n",
    "    Normalized means that integrating over the histogram yields 1.\n",
    "    Returns the PDF (normalized histogram) and edges of the histogram bins\n",
    "    \"\"\"\n",
    "\n",
    "    ## compute histogram\n",
    "    if bin_edges is None:\n",
    "        hist, bin_edges = np.histogram(x)\n",
    "\n",
    "    else:\n",
    "        hist, _ = np.histogram(x, bins=bin_edges)\n",
    "\n",
    "    ## normalize to a probability distribution (PDF)\n",
    "    bin_width = bin_edges[1:] - bin_edges[:-1]\n",
    "    pdf = hist / (hist * bin_width).sum()\n",
    "\n",
    "    return pdf, bin_edges\n",
    "\n",
    "\n",
    "def get_autocorr(x, lags, month=None):\n",
    "    \"\"\"Get autocorrelation for data for multiple lags\"\"\"\n",
    "\n",
    "    ## put autocorrelation for each lag in array\n",
    "    autocorr = [get_autocorr_helper(x, lag, month) for lag in lags]\n",
    "\n",
    "    ## convert to xr.DataArray\n",
    "    autocorr = xr.concat(autocorr, dim=pd.Index(lags, name=\"lag\"))\n",
    "    # return xr.DataArray(autocorr, coords={\"lag\": lags})\n",
    "    return autocorr\n",
    "\n",
    "\n",
    "def get_autocorr_helper(x, lag, month=None):\n",
    "    \"\"\"Get autocorrelation of data for single lag\"\"\"\n",
    "\n",
    "    ## return 1 for a lag of 0\n",
    "    if lag == 0:\n",
    "        return xr.ones_like(x.isel(time=0))\n",
    "\n",
    "    ## get lagged version of x\n",
    "    elif lag > 0:\n",
    "        x_lagged = x.isel(time=slice(lag, None))\n",
    "        x_ = x.isel(time=slice(None, -lag))\n",
    "\n",
    "    else:\n",
    "        x_lagged = x.isel(time=slice(None, lag))\n",
    "        x_ = x.isel(time=slice(-lag, None))\n",
    "\n",
    "    ## re-label time axis so arrays match\n",
    "    x_lagged[\"time\"] = x_.time\n",
    "\n",
    "    ## subset for data from given month\n",
    "    if month is not None:\n",
    "        is_month = x_.time.dt.month == month\n",
    "        x_ = x_.isel(time=is_month)\n",
    "        x_lagged = x_lagged.isel(time=is_month)\n",
    "\n",
    "    return xr.corr(x_, x_lagged, dim=\"time\")\n",
    "\n",
    "\n",
    "def load_simulation(varname, member_id, simulation_type, preprocess_func=None):\n",
    "    \"\"\"\n",
    "    Load dataset for single simulation, for single variable.\n",
    "    Arguments:\n",
    "        - varname: name of variable to load, one of {\"SST\",\"PSL\"}\n",
    "        - member_id: ID of ensemble member to load, an integer in the range [1,10]\n",
    "        - simulation_type: one of {\"hist\", \"rcp85\"}\n",
    "        - preprocess func: optional preprocessing function to apply to the simulation\n",
    "    Returns:\n",
    "        - xarray dataarray with given data\n",
    "    \"\"\"\n",
    "\n",
    "    ## Filepath to the CESM LENS dataset\n",
    "    lens_fp = pathlib.Path(\"cmip6/data/cmip6/CMIP/NCAR/LENS\")\n",
    "\n",
    "    #### 1. get filepath to data\n",
    "    data_fp = SERVER_FP / lens_fp / pathlib.Path(varname)\n",
    "\n",
    "    #### 2. get naming pattern for files to open\n",
    "    if simulation_type == \"hist\":\n",
    "        file_pattern = f\"*20TRC*.{member_id:03d}.*.nc\"\n",
    "\n",
    "    elif simulation_type == \"rcp85\":\n",
    "        file_pattern = f\"*RCP85*.{member_id:03d}.*.nc\"\n",
    "\n",
    "    else:\n",
    "        print(\"Not a valid simulation type\")\n",
    "\n",
    "    #### 3. open the relevant datasets, applying preprocessing function\n",
    "    fp = list(data_fp.glob(file_pattern))[0]\n",
    "    data = preprocess_func(xr.open_dataset(fp, decode_timedelta=True))\n",
    "\n",
    "    return data[varname].squeeze(drop=True).compute()\n",
    "\n",
    "\n",
    "def load_ensemble_helper(varname, simulation_type, preprocess_func=None, n_members=35):\n",
    "    \"\"\"\n",
    "    Load all ensemble members for given simulation type and variable.\n",
    "    Arguments:\n",
    "        - varname: name of variable to load, one of {\"SST\",\"PSL\"}\n",
    "        - simulation_type: one of {\"hist\", \"rcp85\"}\n",
    "        - preprocess func: optional preprocessing function to apply to the simulation\n",
    "    Returns:\n",
    "        - xarray dataarray with given data and 'ensemble' dimension\n",
    "    \"\"\"\n",
    "\n",
    "    ## put arguments in dictionary\n",
    "    kwargs = dict(\n",
    "        varname=varname,\n",
    "        simulation_type=simulation_type,\n",
    "        preprocess_func=preprocess_func,\n",
    "    )\n",
    "\n",
    "    ## get array of ensemble IDs\n",
    "    member_ids = np.arange(1, n_members + 1)\n",
    "\n",
    "    ## put results in list\n",
    "\n",
    "    # USE tqdm TO SHOW PROGRESS IF YOU WOULD LIKE (NEED TO INSTALL)\n",
    "    # data = [load_simulation(member_id=i, **kwargs) for i in tqdm.tqdm(member_ids)]\n",
    "    # otherwise:\n",
    "    data = [load_simulation(member_id=i, **kwargs) for i in member_ids]\n",
    "\n",
    "    ## concatenate data along the \"ensemble\" dimension\n",
    "    ensemble_dim = pd.Index(member_ids, name=\"member\")\n",
    "    data = xr.concat(data, dim=ensemble_dim)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_ensemble(\n",
    "    varname, simulation_type, preprocess_func=None, save_fp=None, n_members=35\n",
    "):\n",
    "    \"\"\"\n",
    "    Load all ensemble members for given simulation type and variable.\n",
    "    (Checks if data exists locally first).\n",
    "    Arguments:\n",
    "        - varname: name of variable to load, one of {\"SST\",\"PSL\"}\n",
    "        - simulation_type: one of {\"hist\", \"rcp85\"}\n",
    "        - preprocess func: optional preprocessing function to apply to the simulation\n",
    "        - save_fp: pathlib.Path object (save the result here if specified)\n",
    "    Returns:\n",
    "        - xarray dataarray with given data and 'ensemble' dimension\n",
    "    \"\"\"\n",
    "\n",
    "    ## put arguments in dictionary\n",
    "    kwargs = dict(\n",
    "        varname=varname,\n",
    "        simulation_type=simulation_type,\n",
    "        preprocess_func=preprocess_func,\n",
    "        n_members=n_members,\n",
    "    )\n",
    "\n",
    "    ## load pre-computed data if it exists\n",
    "    if save_fp is not None:\n",
    "\n",
    "        ## path to file\n",
    "        save_fp = save_fp / f\"{varname}_{simulation_type}.nc\"\n",
    "\n",
    "        ## check if file exists:\n",
    "        if save_fp.is_file():\n",
    "            data = xr.open_dataarray(save_fp)\n",
    "\n",
    "        else:\n",
    "\n",
    "            ## load the data and save to file for next time\n",
    "            data = load_ensemble_helper(**kwargs)\n",
    "\n",
    "            print(\"saving to file\")\n",
    "            data.to_netcdf(save_fp)\n",
    "\n",
    "    else:\n",
    "\n",
    "        ## don't load/save the data\n",
    "        data = load_ensemble_helper(**kwargs)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def plot_quantiles(ax, x, label=None, month=None, time_dim=\"time\", **kwargs):\n",
    "    \"\"\"plot .1, .5, and .9 quantiles on given ax object\"\"\"\n",
    "\n",
    "    ## filter for month if specified\n",
    "    if month is not None:\n",
    "        x = x.sel(time=(x.time.dt.month == month))\n",
    "\n",
    "    ## compute quantiles\n",
    "    x_quantiles = x.quantile([0.1, 0.5, 0.9], dim=\"member\")\n",
    "\n",
    "    ## plot median\n",
    "    ax.plot(\n",
    "        x_quantiles[time_dim],\n",
    "        x_quantiles.sel(quantile=0.5),\n",
    "        lw=2,\n",
    "        label=label,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    ## plot upper/lower bounds\n",
    "    for q in [0.1, 0.9]:\n",
    "        ax.plot(\n",
    "            x_quantiles[time_dim],\n",
    "            x_quantiles.sel(quantile=q),\n",
    "            lw=1,\n",
    "            alpha=0.5,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def rolling_fn_helper(x, fn, window_size=15):\n",
    "    \"\"\"Function to get rolling standard deviation ('sigma').\n",
    "    'window_size' is number of timesteps to include in each averaging window\"\"\"\n",
    "\n",
    "    ## get rolling object\n",
    "    rolling_obj = x.rolling({\"time\": window_size}, center=True)\n",
    "\n",
    "    ## apply function\n",
    "    fn_eval = fn(rolling_obj)\n",
    "\n",
    "    ## get half window size\n",
    "    n = int((window_size - 1) / 2)\n",
    "\n",
    "    ## trim to remove NaNs\n",
    "    return fn_eval.isel(time=slice(n, -n))\n",
    "\n",
    "\n",
    "def rolling_fn_bymonth(x, fn, window_size=15):\n",
    "    \"\"\"Apply rolling function to each month separately\"\"\"\n",
    "\n",
    "    ## get rolling function to pass to apply to each month\n",
    "    rolling_fn_ = lambda y: rolling_fn_helper(y, fn, window_size=window_size)\n",
    "\n",
    "    ## evaluate\n",
    "    fn_eval = x.groupby(\"time.month\").map(rolling_fn_)\n",
    "\n",
    "    ## reindex so time is ascending\n",
    "    fn_eval = fn_eval.reindex({\"time\": np.sort(fn_eval.time)})\n",
    "\n",
    "    return fn_eval\n",
    "\n",
    "\n",
    "def rolling_fn(x, fn, window_size=15, by_month=True):\n",
    "    \"\"\"apply rolling function; handle by_month cases (True or False)\"\"\"\n",
    "\n",
    "    ## keyword args\n",
    "    kwargs = dict(x=x, fn=fn, window_size=window_size)\n",
    "\n",
    "    ## handle cases\n",
    "    if by_month:\n",
    "        return rolling_fn_bymonth(**kwargs)\n",
    "\n",
    "    else:\n",
    "        return rolling_fn_helper(**kwargs)\n",
    "\n",
    "\n",
    "def get_rolling_stddev(x, window_size=31, by_month=True):\n",
    "    \"\"\"Function to get rolling standard deviation ('sigma').\"\"\"\n",
    "\n",
    "    ## get sigma function\n",
    "    fn = lambda y: y.std()\n",
    "\n",
    "    return rolling_fn(x, fn=fn, window_size=window_size, by_month=by_month)\n",
    "\n",
    "\n",
    "def get_rolling_mean(x, window_size=31, by_month=True):\n",
    "    \"\"\"Function to get rolling standard deviation ('sigma').\"\"\"\n",
    "\n",
    "    ## get sigma function\n",
    "    fn = lambda y: y.mean()\n",
    "\n",
    "    return rolling_fn(x, fn=fn, window_size=window_size, by_month=by_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333948ce-71b3-45c2-a758-89326cac7d36",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0836eb39-d811-4fd9-a462-da36e2319e32",
   "metadata": {},
   "source": [
    "#### Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed8c4db-51c4-4210-9adf-27530c92fdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_server(lens_fp, simulation_type, preprocess_func, n_members=2, varname=\"SST\"):\n",
    "    \"\"\"\n",
    "    Load ensemble data for CESM-LE from server. \n",
    "    Args:\n",
    "        - lens_fp: filepath to LENS data on CMIP server\n",
    "        - simulation type: either \"hist\" or \"rcp85\"\n",
    "        - n_members: number of ensemble members to load\n",
    "        - varname: one of \"SST\" or \"PSL\"\n",
    "    \"\"\"\n",
    "\n",
    "    ## parse \n",
    "\n",
    "    ## get filename pattern\n",
    "    if simulation_type == \"historical\":\n",
    "        pattern = f\"*20TRC*.nc\"\n",
    "\n",
    "    elif simulation_type == \"future\":\n",
    "        pattern = f\"*RCP85*.nc\"\n",
    "\n",
    "    else:\n",
    "        print(\"not a valid simulation type\")\n",
    "        return\n",
    "\n",
    "    ## get (sorted) list of files\n",
    "    files = pathlib.Path(lens_fp, varname).glob(pattern)\n",
    "    files = sorted(list(files))\n",
    "\n",
    "    ## get subset of files to load\n",
    "    files = files[:n_members]\n",
    "\n",
    "    ## open the data (but don't load to memory)\n",
    "    data = xr.open_mfdataset(\n",
    "        files, \n",
    "        concat_dim=\"member\",\n",
    "        decode_timedelta=True,\n",
    "        combine=\"nested\",\n",
    "        chunks=dict({\"time\":1872}),\n",
    "        parallel=True,\n",
    "    )\n",
    "\n",
    "    ## preprocess (still don't load to memory)\n",
    "    data_prepped = preprocess_func(data[varname])\n",
    "\n",
    "    return data_prepped\n",
    "\n",
    "def load_from_cloud(\n",
    "    simulation_type, preprocess_func, varname=\"TREFHT\", n_members=2,\n",
    "):\n",
    "    \"\"\"Load CESM data from cloud. Args:\n",
    "    - simulation type: either \"historical\" or \"future\"\n",
    "    - preprocess_func: preprocessing function\n",
    "    - varname: variable to load (\"TREFHT\" is 2m-temperature)\n",
    "    - n_members: number of ensemble members to load\n",
    "    \"\"\"\n",
    "\n",
    "    ## get catalog of available data\n",
    "    catalog = intake.open_esm_datastore(\n",
    "        \"https://raw.githubusercontent.com/NCAR/cesm2-le-aws/main/intake-catalogs/aws-cesm2-le.json\"\n",
    "    )\n",
    "\n",
    "    ## subset for temperature data\n",
    "    ## to look at available data, use: catalog.df\n",
    "    catalog_subset = catalog.search(variable=varname, frequency=\"monthly\")\n",
    "\n",
    "    ## kwargs for opening data\n",
    "    kwargs = dict(\n",
    "        aggregate=True,\n",
    "        xarray_open_kwargs=dict(\n",
    "            engine=\"zarr\", \n",
    "            decode_timedelta=True,\n",
    "        ),\n",
    "        zarr_kwargs={\"consolidated\": True},\n",
    "        storage_options={\"anon\": True},\n",
    "    )\n",
    "\n",
    "    ## open data (but don't load to memory)\n",
    "    dsets = catalog_subset.to_dataset_dict(**kwargs)\n",
    "\n",
    "    ## load future or historical\n",
    "    if simulation_type == \"historical\":\n",
    "        data = dsets[\"atm.historical.monthly.cmip6\"]\n",
    "    \n",
    "    elif simulation_type == \"future\":\n",
    "        data = dsets[\"atm.ssp370.monthly.cmip6\"]\n",
    "\n",
    "    else:\n",
    "        print(\"Not a valid simulation type\")\n",
    "\n",
    "    ## subset for ensemble members\n",
    "    data = data.isel(member_id=slice(None,n_members))\n",
    "\n",
    "    ## do preprocessing\n",
    "    data_prepped = preprocess_func(data[varname])\n",
    "\n",
    "    return data_prepped\n",
    "\n",
    "def preprocess(data):\n",
    "    \"\"\"\n",
    "    Preprocessing steps:\n",
    "        1. trim to period 1921 - 2080\n",
    "        2. trim in lon/lat space\n",
    "        3. drop vertical coord\n",
    "    \"\"\"\n",
    "\n",
    "    ## trim in time\n",
    "    data = data.sel(time=slice(\"1921\",\"2080\"))\n",
    "\n",
    "    ## trim in space\n",
    "    data = trim(data, lon_range=[280, 300], lat_range=[35, 45])\n",
    "\n",
    "    ## drop vertical coord\n",
    "    if \"z_t\" in data.dims:\n",
    "        data = data.drop_vars(\"z_t\").squeeze()\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_lsm(lon_range, lat_range):\n",
    "    \"\"\"Load ERA5 land-sea-mask from CMIP6 server\"\"\"\n",
    "\n",
    "    ## open ERSST data\n",
    "    sst = xr.open_dataset(\n",
    "        r\"http://psl.noaa.gov/thredds/dodsC/Datasets/noaa.ersst.v5/sst.mnmean.nc\"\n",
    "    )\n",
    "    sst = sst[\"sst\"].isel(time=0).drop_vars(\"time\")\n",
    "\n",
    "    ## convert to lsm (fill ones over ocean)\n",
    "    lsm = sst.where(np.isnan(sst), other=1.0)\n",
    "\n",
    "    ## sel lon/lat range\n",
    "    lsm = lsm.sel(lon=slice(*lon_range), lat=slice(*lat_range[::-1]))\n",
    "  \n",
    "    # ## add binary mask for regridding\n",
    "    lsm[\"mask\"] = np.isnan(lsm)\n",
    "\n",
    "    return lsm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672dd796-55ea-4cee-8c9c-f20d7fc14aae",
   "metadata": {},
   "source": [
    "#### Initialize dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc859601-b81a-4adc-b8e4-e7eaacd44abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import LocalCluster, Client\n",
    "\n",
    "cluster = LocalCluster(n_workers=4)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ae6cb9-369f-45c1-9b00-34d2ea90a6a3",
   "metadata": {},
   "source": [
    "### open data, preprocess, then load to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9712af-3cad-462c-b525-62f925234e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specify args\n",
    "LENS_FP = pathlib.Path(\"/Volumes/cmip6/data/cmip6/CMIP/NCAR/LENS\")\n",
    "VARNAME = \"SST\"\n",
    "N_MEMBERS = 3\n",
    "LOAD_FROM_CLOUD = True\n",
    "\n",
    "if LOAD_FROM_CLOUD:\n",
    "\n",
    "    ## specify server kwargs\n",
    "    cloud_kwargs = dict(\n",
    "        preprocess_func = preprocess,\n",
    "        varname=\"TREFHT\", \n",
    "        n_members=N_MEMBERS\n",
    "    )\n",
    "    \n",
    "    ## open the data (but don't load to memory\n",
    "    data_hist = load_from_cloud(simulation_type=\"historical\", **cloud_kwargs)\n",
    "    data_fut = load_from_cloud(simulation_type=\"future\", **cloud_kwargs)\n",
    "\n",
    "else:\n",
    "\n",
    "    ## specify server kwargs\n",
    "    server_kwargs = dict(\n",
    "        preprocess_func = preprocess, \n",
    "        lens_fp = LENS_FP, \n",
    "        varname=VARNAME, \n",
    "        n_members=N_MEMBERS\n",
    "    )\n",
    "    \n",
    "    ## open the data (but don't load to memory\n",
    "    data_hist = load_from_server(simulation_type=\"historical\", **server_kwargs)\n",
    "    data_rcp = load_from_server(simulation_type=\"future\", **server_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5d13b5-d41d-4c90-a565-faf51133fe50",
   "metadata": {},
   "source": [
    "Now, load to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da97410-c53d-4da4-bf6f-3ad274955e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading historical data\")\n",
    "t0 = time.time()\n",
    "data_hist.load();\n",
    "t1 = time.time()\n",
    "print(f\"Elapsed time: {(t1-t0)/60:.1f} minutes\\n\")\n",
    "\n",
    "print(\"Loading future data\")\n",
    "t0 = time.time()\n",
    "data_fut.load();\n",
    "t1 = time.time()\n",
    "print(f\"Elapsed time: {(t1-t0)/60:.1f} minutes\\n\")\n",
    "\n",
    "# Concatenate in time\n",
    "data = xr.concat([data_hist, data_fut], dim=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5371bf86-1a6d-454d-aa1a-8a323a7414e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e39c0a-ccb3-476f-9d93-a13338805a88",
   "metadata": {},
   "source": [
    "### Set filepaths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65329af-344f-4b7e-92da-1d12401f1dd1",
   "metadata": {},
   "source": [
    "````{admonition} To-do\n",
    "Update the filepaths ```SERVER_FP``` and ```save_fp``` in the code cell below.  \n",
    "\n",
    "Preprocessing all 35 ensemble members takes a \"long time\" ($\\sim$ 30 minutes on a laptop), so we'll save the preprocessed data to a file (to be loaded if the script is run a second time).\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eb8c3a-dd13-4c17-be12-a52d2e458682",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Path to file server\n",
    "# SERVER_FP = pathlib.Path(\"/vortexfs1/share\")\n",
    "SERVER_FP = pathlib.Path(\"/Volumes\")\n",
    "\n",
    "## Specify folder location for saving trimmed data (\"./\" means current directory)\n",
    "save_fp = pathlib.Path(\"./data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05342387-4441-4a19-a756-4da7a743da66",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Pre-processing functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08eaab26-56c0-49ba-ae6d-9c2d4403eebb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "````{admonition} To-do\n",
    "If you'd like to look at a different region, change ```lon_range``` and ```lat_range``` in the preprocessing function below.\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11d8b35-7e62-4f5e-834e-617adeb6c086",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    \"\"\"\n",
    "    Preprocessing steps:\n",
    "        1. trim to period 1920 - 2081\n",
    "        2. trim in lon/lat space\n",
    "        3. convert time dimension from cftime to datetime\n",
    "    \"\"\"\n",
    "\n",
    "    ## trim in time\n",
    "    data_ = data.sel(time=slice(\"1920-02\", \"2081-01\"))\n",
    "\n",
    "    ## trim in space\n",
    "    data_ = trim(data_, lon_range=[280, 300], lat_range=[35, 45])\n",
    "\n",
    "    ## update time dimension\n",
    "    start_year = data_.time.isel(time=0).dt.year.item()\n",
    "    start_month = data_.time.isel(time=0).dt.month.item()\n",
    "    start_date = f\"{start_year}-{start_month}-01\"\n",
    "    data_[\"time\"] = pd.date_range(start=start_date, periods=len(data_.time), freq=\"MS\")\n",
    "\n",
    "    return data_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2174c18-f322-4761-8852-56831c0ad804",
   "metadata": {},
   "source": [
    "### Do the loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b550f15-982b-4d48-b33d-b5fc0f0246dd",
   "metadata": {},
   "source": [
    "````{note} \n",
    "Preprocessing the data in the code cell below is slow ($\\sim 30$ minutes on a laptop). To speed up the process, here are a few options:\n",
    "1. Download [pre-processed data from Google Drive](https://drive.google.com/drive/folders/1sBa-Z1-b6iKaBHo_UDCdSL5d4zz9GVJE?usp=sharing). Unzip the file and save it to the same directory as this notebook.\n",
    "2. Load less ensemble members (e.g., reduce ```n_members``` from 18 to 9 in the code cell below).\n",
    "3. Run this notebook in the cloud (using Google Colab) and using CESM2 data on the cloud. For instructions on how to do this, see [this page](../resources/cesm_cloud.ipynb).\n",
    "````\n",
    "The loading function (```load_ensemble```) will save the pre-processed data to a file (and load it, if it already exists), so the cell below will run much faster the second time around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146b4707-46e8-40a6-8ac2-76355769fd2a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## shared arguments for loading data\n",
    "load_kwargs = dict(\n",
    "    varname=\"SST\", preprocess_func=preprocess, save_fp=save_fp, n_members=18\n",
    ")\n",
    "\n",
    "## Load data\n",
    "data_hist = load_ensemble(simulation_type=\"hist\", **load_kwargs)\n",
    "data_rcp = load_ensemble(simulation_type=\"rcp85\", **load_kwargs)\n",
    "\n",
    "## concatenate in time\n",
    "data = xr.concat([data_hist, data_rcp], dim=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc9d2a9-2204-4b37-84a5-158cde02db68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d314c3-21bb-442d-a21e-9c3975c19be9",
   "metadata": {},
   "source": [
    "## Plot a sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7004dbeb-28b0-430f-9f6f-fd5382cdb290",
   "metadata": {},
   "source": [
    "````{admonition} To-do\n",
    "If you're not looking at Woods Hole, you may need to adapt the plotting function below (```plot_setup_woodshole```).\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf7619b-ed04-4c0f-bcc2-66b659ff0a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "## blank canvas\n",
    "fig = plt.figure()\n",
    "\n",
    "## plot background\n",
    "fig, ax = plot_setup_woodshole(fig)\n",
    "\n",
    "\n",
    "## plot the data\n",
    "plot_data = ax.pcolormesh(\n",
    "    data.TLONG,\n",
    "    data.TLAT,\n",
    "    data.isel(member=0, time=0),\n",
    "    # cmap=\"cmo.thermal\",\n",
    "    cmap=\"plasma\",\n",
    "    vmax=20,\n",
    "    vmin=5,\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "\n",
    "## make a colorbar\n",
    "cb = fig.colorbar(plot_data, fraction=0.015, pad=0.05, ticks=[5, 12.5, 20])\n",
    "\n",
    "## plot outline of region\n",
    "ax = plot_box_outline(ax, lon_range=[287.5, 293.5], lat_range=[39, 44])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d351eff-fdf0-42ac-ad9f-aaac49259080",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2c49dc-0c82-49d3-9045-1f1cc630f150",
   "metadata": {},
   "source": [
    "### Compute index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99dcfda-c529-43b4-b109-bcd9586dca29",
   "metadata": {},
   "source": [
    "````{admonition} To-do\n",
    "If you'd like to look at a different index, modify the function below.\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bb35d3-deaa-477b-8d6d-92a4ad2bba22",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_T_wh(x):\n",
    "    \"\"\"Compute Woods Hole temperature index\"\"\"\n",
    "\n",
    "    ## get subset of data inside the box\n",
    "    data_subset = trim(x, lon_range=[287.5, 293.5], lat_range=[39, 44])\n",
    "\n",
    "    ## compute spatial average\n",
    "    return data_subset.mean([\"nlon\", \"nlat\"])\n",
    "\n",
    "\n",
    "## do the computation here\n",
    "idx = compute_T_wh(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bea78c-1401-438a-853b-624f255ff55a",
   "metadata": {},
   "source": [
    "## Separate forced response from internal variability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650bce34-a919-4095-a9c2-7a263493e7d3",
   "metadata": {},
   "source": [
    "Estimate forced response and internval variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b91a62-1f48-42b1-9de6-7281c6c8e285",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define forced response as ensemble mean\n",
    "idx_forced = idx.mean(\"member\")\n",
    "\n",
    "## internal variability is the residual\n",
    "idx_iv = idx - idx_forced\n",
    "\n",
    "## compute annual means\n",
    "get_ann_mean = lambda x: x.groupby(\"time.year\").mean().sel(year=slice(None, 2080))\n",
    "idx_forced_ann = get_ann_mean(idx_forced)\n",
    "idx_iv_ann = get_ann_mean(idx_iv)\n",
    "idx_ann = get_ann_mean(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c2ed4c-4540-4fdf-be56-5d6b331e2718",
   "metadata": {},
   "source": [
    "Lets plot the annual mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba63602-95a7-4b87-af52-59682de06a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up plot\n",
    "fig, axs = plt.subplots(1, 2, figsize=(7, 2.75), layout=\"constrained\")\n",
    "\n",
    "## plot ensemble median and 10%/90% percentiles\n",
    "plot_quantiles(axs[0], idx_ann, c=\"k\", time_dim=\"year\", label=\"Ensemble median\")\n",
    "\n",
    "## plot forced response (ensemble mean)\n",
    "axs[0].plot(idx_forced_ann.year, idx_forced_ann, c=\"r\", lw=2, label=\"Ensemble mean\")\n",
    "\n",
    "## plot internval variability\n",
    "kwargs = dict(lw=0.5, alpha=0.5, c=\"gray\")\n",
    "for m in idx_iv_ann.member[:10]:\n",
    "    axs[1].plot(idx_iv_ann.year, idx_iv_ann.sel(member=m), **kwargs)\n",
    "\n",
    "\n",
    "## label plots\n",
    "for ax in axs:\n",
    "    ax.set_xticks([1920, 2000, 2080])\n",
    "    ax.set_xlabel(\"Year\")\n",
    "    ax.set_ylabel(r\"$^{\\circ}$C\")\n",
    "\n",
    "axs[0].set_yticks([18, 20, 22])\n",
    "axs[1].set_yticks([-1, 0, 1])\n",
    "axs[0].set_title(\"Forced response\")\n",
    "axs[1].set_title(\"Internal variability (10/35 members)\")\n",
    "axs[1].axhline(0, ls=\"--\", c=\"k\", zorder=0.5)\n",
    "axs[1].yaxis.tick_right()\n",
    "axs[1].yaxis.set_label_position(\"right\")\n",
    "axs[0].legend(prop=dict(size=8))\n",
    "\n",
    "## save fig\n",
    "if SAVE_FIGS:\n",
    "    fig.savefig(\"figs/forced-response.svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2445d40-5dc2-41ea-be4f-a1ed8d4cfb08",
   "metadata": {},
   "source": [
    "## Compare warming rates in Mar and Sep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e903f9bd-1bd1-4e85-a501-8ccde94b7dcb",
   "metadata": {},
   "source": [
    "Compute rolling mean temperature for March and September"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91868ff9-783a-4454-b400-63b8b512bdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to select month\n",
    "sel_month = lambda x, month: x.sel(time=(x.time.dt.month == month))\n",
    "\n",
    "## function to normalize by first 10 timesteps\n",
    "normalize = lambda x: x - x.isel(time=slice(None, 10)).mean([\"member\", \"time\"])\n",
    "\n",
    "## get smoothed version of index\n",
    "idx_smooth = get_rolling_mean(idx, by_month=True, window_size=9)\n",
    "\n",
    "## compute values for Mar/\n",
    "idx_mar_norm = normalize(sel_month(idx_smooth, 3))\n",
    "idx_sep_norm = normalize(sel_month(idx_smooth, 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d9f207-2985-4048-b371-a13a4852175e",
   "metadata": {},
   "source": [
    "Plot forced response for Mar/Sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c445fa55-ceb7-41ec-b21b-158fefd53945",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get colors for plot\n",
    "colors = sns.color_palette()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3.5, 2.75), layout=\"constrained\")\n",
    "\n",
    "## plot data\n",
    "plot_quantiles(ax, idx_mar_norm, c=colors[0], label=\"Mar\")\n",
    "plot_quantiles(ax, idx_sep_norm, c=colors[1], label=\"Sep\")\n",
    "\n",
    "## label\n",
    "ax.legend(prop=dict(size=8))\n",
    "ax.set_ylabel(r\"$\\Delta T$ ($^{\\circ}$C)\")\n",
    "ax.set_xticks([\"1920\", \"2000\", \"2080\"])\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
    "\n",
    "## save to file\n",
    "if SAVE_FIGS:\n",
    "    fig.savefig(\"figs/forced-response_by-seasonal.svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b09e6ad-b368-4369-8cb0-838ac205b19d",
   "metadata": {},
   "source": [
    "Compute temperature change over two pairs of periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f699497-e5e6-4716-a8b8-16d65e4b2a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta_T_pdf(T, t0, t1, bin_edges):\n",
    "    \"\"\"function to compute PDFs of temperature difference between two periods\"\"\"\n",
    "\n",
    "    ## get delta T\n",
    "    delta_T = T.sel(time=t1).squeeze() - T.sel(time=t0).squeeze()\n",
    "\n",
    "    ## create PDF\n",
    "    pdf, _ = get_empirical_pdf(delta_T, bin_edges)\n",
    "\n",
    "    return pdf\n",
    "\n",
    "\n",
    "## specify params for PDF\n",
    "kwargs0 = dict(t0=\"1924\", t1=\"2000\", bin_edges=np.arange(-0.3, 1.9, 0.15))\n",
    "kwargs1 = dict(t0=\"2000\", t1=\"2076\", bin_edges=np.arange(2, 4.5, 0.2))\n",
    "\n",
    "## compute PDFs for each period\n",
    "pdf_mar_0 = get_delta_T_pdf(idx_mar_norm, **kwargs0)\n",
    "pdf_sep_0 = get_delta_T_pdf(idx_sep_norm, **kwargs0)\n",
    "pdf_mar_1 = get_delta_T_pdf(idx_mar_norm, **kwargs1)\n",
    "pdf_sep_1 = get_delta_T_pdf(idx_sep_norm, **kwargs1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811623fb-7bfd-4d41-8bbc-0ff82ed330f0",
   "metadata": {},
   "source": [
    "Plot result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9371f7-d29b-47b7-b1de-b6207bfbfb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up plot\n",
    "fig, axs = plt.subplots(1, 2, figsize=(5, 2.75), layout=\"constrained\")\n",
    "\n",
    "## plot style for march\n",
    "mar_kwargs = dict(fill=True, alpha=0.3, label=\"Mar\")\n",
    "sep_kwargs = dict(lw=1.5, label=\"Sep\")\n",
    "\n",
    "## plot temperature change for first period\n",
    "axs[0].stairs(pdf_mar_0, edges=kwargs0[\"bin_edges\"], **mar_kwargs)\n",
    "axs[0].stairs(pdf_sep_0, edges=kwargs0[\"bin_edges\"], **sep_kwargs)\n",
    "\n",
    "## plot for second period\n",
    "axs[1].stairs(pdf_mar_1, edges=kwargs1[\"bin_edges\"], **mar_kwargs)\n",
    "axs[1].stairs(pdf_sep_1, edges=kwargs1[\"bin_edges\"], **sep_kwargs)\n",
    "\n",
    "## set axis limits\n",
    "axs[0].set_xlim([-0.75, 2.25])\n",
    "axs[1].set_xlim([1.5, 4.5])\n",
    "for ax in axs:\n",
    "    ax.set_ylim([0, 3])\n",
    "\n",
    "## label\n",
    "axs[0].legend(prop=dict(size=8))\n",
    "axs[0].set_title(f\"{kwargs0['t0']}-{kwargs0['t1']}\")\n",
    "axs[1].set_title(f\"{kwargs1['t0']}-{kwargs1['t1']}\")\n",
    "axs[0].set_xticks([-0.5, 0.5, 1.5])\n",
    "axs[1].set_xticks([2, 3, 4])\n",
    "axs[0].set_yticks([0, 1.5, 3])\n",
    "axs[1].set_yticks([])\n",
    "axs[0].set_ylabel(\"Prob. density\")\n",
    "for ax in axs:\n",
    "    ax.set_xlabel(r\"$\\Delta T$ ($^{\\circ}$C)\")\n",
    "\n",
    "## save to file\n",
    "if SAVE_FIGS:\n",
    "    fig.savefig(\"figs/histograms.svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f62f27-5356-440d-8241-044e82dd47a8",
   "metadata": {},
   "source": [
    "## Look at change in standard deviation (spatial pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca482d3-b0e2-4173-83d5-5ef5d87d4b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get internval variability signal\n",
    "data_iv = data - data.mean(\"member\")\n",
    "\n",
    "## compute standard dev over first/last 30 years of simulation\n",
    "std_init = data_iv.isel(time=slice(None, 360)).std([\"time\", \"member\"], skipna=False)\n",
    "std_end = data_iv.isel(time=slice(-360, None)).std([\"time\", \"member\"], skipna=False)\n",
    "\n",
    "## get percentage change\n",
    "std_pct_change = 100 * (std_end - std_init) / std_init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6107117-45ca-4ac3-b583-45e88e7af2a8",
   "metadata": {},
   "source": [
    "### Plot initial standard deviation result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14e829b-1e2b-4258-87ba-c3126415c37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## blank canvas\n",
    "fig = plt.figure()\n",
    "\n",
    "## plot background\n",
    "fig, ax = plot_setup_woodshole(fig)\n",
    "\n",
    "\n",
    "## plot the data\n",
    "plot_data = ax.pcolormesh(\n",
    "    std_init.TLONG,\n",
    "    std_init.TLAT,\n",
    "    std_init,\n",
    "    cmap=\"cmo.amp\",\n",
    "    vmax=1,\n",
    "    vmin=0.3,\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "\n",
    "## make a colorbar\n",
    "cb = fig.colorbar(\n",
    "    plot_data,\n",
    "    fraction=0.015,\n",
    "    pad=0.05,\n",
    "    ticks=[0.3, 1],\n",
    "    label=r\"Std. dev. ($^{\\circ}$C)\",\n",
    ")\n",
    "\n",
    "## plot outline of region\n",
    "ax = plot_box_outline(ax, lon_range=[287.5, 293.5], lat_range=[39, 44])\n",
    "\n",
    "## Label\n",
    "ax.set_title(\"Standard dev. of SST (1920-1950)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c14e81-8d7f-42dc-901d-4875026ce46c",
   "metadata": {},
   "source": [
    "### Plot % change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5c4912-f937-4348-b509-c88a044766bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## blank canvas\n",
    "fig = plt.figure(layout=\"constrained\")\n",
    "\n",
    "## plot background\n",
    "fig, ax = plot_setup_woodshole(fig)\n",
    "\n",
    "\n",
    "## plot the data\n",
    "plot_data = ax.pcolormesh(\n",
    "    std_init.TLONG,\n",
    "    std_init.TLAT,\n",
    "    std_pct_change,\n",
    "    cmap=\"cmo.balance\",\n",
    "    vmax=40,\n",
    "    vmin=-40,\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "\n",
    "## make a colorbar\n",
    "cb = fig.colorbar(\n",
    "    plot_data, fraction=0.015, pad=0.05, ticks=[-40, 0, 40], label=\"% change\"\n",
    ")\n",
    "\n",
    "## plot outline of region\n",
    "ax = plot_box_outline(ax, lon_range=[287.5, 293.5], lat_range=[39, 44])\n",
    "\n",
    "## label\n",
    "ax.set_title(\"Change in standard dev. of SST (1935-2065)\")\n",
    "\n",
    "## save to  file\n",
    "if SAVE_FIGS:\n",
    "    fig.savefig(\"figs/sigma-change.svg\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
