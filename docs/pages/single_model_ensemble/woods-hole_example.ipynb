{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0294a2d1-ac11-44c6-8d4c-f09066b4ce27",
   "metadata": {},
   "source": [
    "# Woods hole example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ea7642-50d7-4e56-b847-f9d0af63f9b5",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daaf53e-f603-40ac-b7a6-968a9eef13dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import cmocean\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.ticker as mticker\n",
    "import scipy.signal\n",
    "import copy\n",
    "import dask.distributed\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "## (optional) remove gridlines from plots\n",
    "sns.set(rc={\"axes.facecolor\": \"white\", \"axes.grid\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de6686d-1f50-4cd2-99e3-ec18c930e6c0",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ad8ace-6902-4bb7-8b3d-ea4c19d33506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_setup(fig, projection, lon_range, lat_range, xticks=None, yticks=None):\n",
    "    \"\"\"Add a subplot to the figure with the given map projection\n",
    "    and lon/lat range. Returns an Axes object.\"\"\"\n",
    "\n",
    "    ## increase resolution for projection\n",
    "    ## (otherwise lines plotted on surface won't follow curved trajectories)\n",
    "    projection.threshold /= 1000\n",
    "\n",
    "    ## Create subplot with given projection\n",
    "    ax = fig.add_subplot(projection=projection)\n",
    "\n",
    "    ## Subset to given region\n",
    "    extent = [*lon_range, *lat_range]\n",
    "    ax.set_extent(extent, crs=ccrs.PlateCarree())\n",
    "\n",
    "    ## draw coastlines\n",
    "    ax.coastlines(linewidths=0.5)\n",
    "\n",
    "    ## add tick labels\n",
    "    if xticks is not None:\n",
    "\n",
    "        ## add lon/lat labels\n",
    "        gl = ax.gridlines(\n",
    "            draw_labels=True,\n",
    "            linestyle=\"-\",\n",
    "            alpha=0.1,\n",
    "            linewidth=0.5,\n",
    "            color=\"k\",\n",
    "            zorder=1.05,\n",
    "        )\n",
    "\n",
    "        ## specify which axes to label\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "\n",
    "        ## specify ticks\n",
    "        gl.ylocator = mticker.FixedLocator(yticks)\n",
    "        gl.xlocator = mticker.FixedLocator(xticks)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_box_outline(ax, lon_range, lat_range, c=\"k\"):\n",
    "    \"\"\"\n",
    "    Plot box outlining the specifed lon/lat range on given\n",
    "    ax object.\n",
    "    \"\"\"\n",
    "\n",
    "    ## get width and height\n",
    "    height = lat_range[1] - lat_range[0]\n",
    "    width = lon_range[1] - lon_range[0]\n",
    "\n",
    "    ## add rectangle to plot\n",
    "    ax.add_patch(\n",
    "        mpatches.Rectangle(\n",
    "            xy=[lon_range[0], lat_range[0]],\n",
    "            height=height,\n",
    "            width=width,\n",
    "            transform=ccrs.PlateCarree(),\n",
    "            facecolor=\"none\",\n",
    "            edgecolor=c,\n",
    "            linewidth=1,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_correlation(plot_setup_fn, corr, x, y):\n",
    "    \"\"\"\n",
    "    Make spatial plot of correlation, using the specified\n",
    "    plot setup function and pre-computed correlation.\n",
    "    Args:\n",
    "        - plot_setup_fn: function that returns a fig, ax object\n",
    "        - corr: xarray with spatial correlation\n",
    "        - x, y: lon/lat points for plotting\n",
    "    \"\"\"\n",
    "\n",
    "    ## blank canvas to plot on\n",
    "    fig = plt.figure()\n",
    "\n",
    "    ## draw background map of Atlantic\n",
    "    fig, ax = plot_setup_fn(fig)\n",
    "\n",
    "    ## plot the data\n",
    "    plot_data = ax.contourf(\n",
    "        x,\n",
    "        y,\n",
    "        corr,\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        levels=make_cb_range(1, 0.1),\n",
    "        extend=\"both\",\n",
    "        cmap=\"cmo.balance\",\n",
    "    )\n",
    "\n",
    "    ## create colorbath\n",
    "    colorbar = fig.colorbar(plot_data, label=\"Corr.\", ticks=[-1, -0.5, 0, 0.5, 1])\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def plot_setup_atlantic(fig):\n",
    "    \"\"\"Plot Atlantic region\"\"\"\n",
    "\n",
    "    ## adjust figure size\n",
    "    fig.set_size_inches(5, 3)\n",
    "\n",
    "    ## specify map projection\n",
    "    # proj = ccrs.Orthographic(central_longitude=-50, central_latitude=40)\n",
    "    proj = ccrs.Orthographic(central_longitude=-50, central_latitude=40)\n",
    "\n",
    "    ## get ax object\n",
    "    ax = plot_setup(\n",
    "        fig,\n",
    "        proj,\n",
    "        lon_range=[-100, 0],\n",
    "        lat_range=[10, 70],\n",
    "        xticks=[-90, -45, 0],\n",
    "        yticks=[0, 35],\n",
    "    )\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def plot_setup_woodshole(fig):\n",
    "    \"\"\"Plot zoomed-in view of Woods Hole\"\"\"\n",
    "\n",
    "    ## adjust figure size\n",
    "    fig.set_size_inches(5, 3)\n",
    "\n",
    "    ## set map projection to orthographic\n",
    "    proj = ccrs.Orthographic(central_longitude=-67.5, central_latitude=40)\n",
    "\n",
    "    ## Get ax object based on generic plotting function\n",
    "    ax = plot_setup(\n",
    "        fig,\n",
    "        proj,\n",
    "        lon_range=[-80, -60],\n",
    "        lat_range=[35, 45],\n",
    "        xticks=[-80, -70, -60],\n",
    "        yticks=[35, 40, 45],\n",
    "    )\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def make_cb_range(amp, delta):\n",
    "    \"\"\"Make colorbar_range for cmo.balance\n",
    "    Args:\n",
    "        - 'amp': amplitude of maximum value for colorbar\n",
    "        - 'delta': increment for colorbar\n",
    "    \"\"\"\n",
    "    return np.concatenate(\n",
    "        [np.arange(-amp, 0, delta), np.arange(delta, amp + delta, delta)]\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_setup_timeseries():\n",
    "    \"\"\"\n",
    "    Create fig, ax objects and label time axis\n",
    "    \"\"\"\n",
    "\n",
    "    ## set up plot\n",
    "    fig, ax = plt.subplots(figsize=(4, 3))\n",
    "\n",
    "    ## restrict to last 50 years and label axes\n",
    "    ax.set_xlim([datetime.date(1970, 1, 1), None])\n",
    "\n",
    "    ax.set_xticks(\n",
    "        [\n",
    "            datetime.date(1979, 1, 1),\n",
    "            datetime.date(2000, 6, 30),\n",
    "            datetime.date(2021, 12, 31),\n",
    "        ]\n",
    "    )\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def plot_seasonal_cycle(mean, std):\n",
    "    \"\"\"\n",
    "    Plot the seasonal cycle (monthly mean ± 1 standard dev.)\n",
    "    \"\"\"\n",
    "\n",
    "    ## plot\n",
    "    fig, ax = plt.subplots(figsize=(4, 3))\n",
    "\n",
    "    ## mean\n",
    "    ax.plot(np.arange(1, 13), mean, c=\"k\", label=r\"$\\mu$\")\n",
    "\n",
    "    ## mean ± std\n",
    "    ax.plot(np.arange(1, 13), mean + std, c=\"k\", lw=0.5, label=r\"$\\mu \\pm \\sigma$\")\n",
    "    ax.plot(np.arange(1, 13), mean - std, c=\"k\", lw=0.5)\n",
    "\n",
    "    ## label\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def spatial_avg(data):\n",
    "    \"\"\"function to compute spatial average of data on grid with constant\n",
    "    longitude/latitude spacing.\"\"\"\n",
    "\n",
    "    ## first, compute cosine of latitude (after converting degrees to radians)\n",
    "    latitude_radians = np.deg2rad(data.latitude)\n",
    "    cos_lat = np.cos(latitude_radians)\n",
    "\n",
    "    ## get weighted average using xarray\n",
    "    avg = data.weighted(weights=cos_lat).mean([\"longitude\", \"latitude\"])\n",
    "\n",
    "    return avg\n",
    "\n",
    "\n",
    "def get_trend_coefs(data, dim=\"time\", deg=1):\n",
    "    \"\"\"get coefficients for trend\"\"\"\n",
    "    return data.polyfit(dim=dim, deg=deg)[\"polyfit_coefficients\"]\n",
    "\n",
    "\n",
    "def get_trend(data, dim=\"time\", deg=1):\n",
    "    \"\"\"\n",
    "    Get trend for an xr.dataarray along specified dimension,\n",
    "    by fitting polynomial of degree 'deg'.\n",
    "    \"\"\"\n",
    "\n",
    "    ## Get coefficients for best fit\n",
    "    polyfit_coefs = get_trend_coefs(data=data, dim=dim, deg=deg)\n",
    "\n",
    "    ## Get best fit line (linear trend in this case)\n",
    "    trend = xr.polyval(data[dim], polyfit_coefs)\n",
    "\n",
    "    return trend\n",
    "\n",
    "\n",
    "def detrend(data, dim=\"time\", deg=1):\n",
    "    \"\"\"\n",
    "    Remove trend of degree 'deg' from data, along dimension 'dim'.\n",
    "    \"\"\"\n",
    "\n",
    "    return data - get_trend(data, dim=dim, deg=deg)\n",
    "\n",
    "\n",
    "def get_empirical_pdf(x, bin_edges=None):\n",
    "    \"\"\"\n",
    "    Estimate the \"empirical\" probability distribution function for the data x.\n",
    "    In this case the result is a normalized histogram,\n",
    "    Normalized means that integrating over the histogram yields 1.\n",
    "    Returns the PDF (normalized histogram) and edges of the histogram bins\n",
    "    \"\"\"\n",
    "\n",
    "    ## compute histogram\n",
    "    if bin_edges is None:\n",
    "        hist, bin_edges = np.histogram(x)\n",
    "\n",
    "    else:\n",
    "        hist, _ = np.histogram(x, bins=bin_edges)\n",
    "\n",
    "    ## normalize to a probability distribution (PDF)\n",
    "    bin_width = bin_edges[1:] - bin_edges[:-1]\n",
    "    pdf = hist / (hist * bin_width).sum()\n",
    "\n",
    "    return pdf, bin_edges\n",
    "\n",
    "\n",
    "def get_gaussian_best_fit(x):\n",
    "    \"\"\"Get gaussian best fit to data, and evaluate\n",
    "    probabilities over the range of the data.\"\"\"\n",
    "\n",
    "    ## get normal distribution best fit\n",
    "    gaussian = scipy.stats.norm(loc=x.mean(), scale=x.std())\n",
    "\n",
    "    ## evaluate over range of data\n",
    "    amp = np.max(np.abs(x.values))\n",
    "    x_eval = np.linspace(-amp, amp)\n",
    "    pdf_eval = gaussian.pdf(x_eval)\n",
    "\n",
    "    return pdf_eval, x_eval\n",
    "\n",
    "\n",
    "def swap_longitude_range(data):\n",
    "    \"\"\"swap longitude range of xr.DataArray from [0,360) to (-180, 180]\"\"\"\n",
    "\n",
    "    ## copy of longitude coordinate to be modified\n",
    "    new_longitude = copy.deepcopy(data.longitude.values)\n",
    "\n",
    "    ## find index where longitude first exceeds 180.\n",
    "    ## (note: np.argmax returns first instance of \"True\" in boolean array)\n",
    "    swap_idx = np.argmax(new_longitude > 180)\n",
    "\n",
    "    ## relabel values >180\n",
    "    new_longitude[swap_idx:] = -360 + new_longitude[swap_idx:]\n",
    "\n",
    "    ## add this coordinate back to the array\n",
    "    data[\"longitude\"] = new_longitude\n",
    "\n",
    "    ## \"roll\" the data to be centered at zero\n",
    "    data = data.roll({\"longitude\": -swap_idx}, roll_coords=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_autocorr_helper(x, lag, month=None):\n",
    "    \"\"\"Get autocorrelation of data for single lag\"\"\"\n",
    "\n",
    "    ## return 1 for a lag of 0\n",
    "    if lag == 0:\n",
    "        return 1.0\n",
    "\n",
    "    ## get lagged version of x\n",
    "    elif lag > 0:\n",
    "        x_lagged = x.isel(time=slice(lag, None))\n",
    "        x_ = x.isel(time=slice(None, -lag))\n",
    "\n",
    "    else:\n",
    "        x_lagged = x.isel(time=slice(None, lag))\n",
    "        x_ = x.isel(time=slice(-lag, None))\n",
    "\n",
    "    ## re-label time axis so arrays match\n",
    "    x_lagged[\"time\"] = x_.time\n",
    "\n",
    "    ## subset for data from given month\n",
    "    if month is not None:\n",
    "        is_month = x_.time.dt.month == month\n",
    "        x_ = x_.isel(time=is_month)\n",
    "        x_lagged = x_lagged.isel(time=is_month)\n",
    "\n",
    "    return get_corr_coef(x_, x_lagged).item()\n",
    "\n",
    "\n",
    "def get_autocorr(x, lags, month=None):\n",
    "    \"\"\"Get autocorrelation for data for multiple lags\"\"\"\n",
    "\n",
    "    ## put autocorrelation for each lag in array\n",
    "    autocorr = [get_autocorr_helper(x, lag, month) for lag in lags]\n",
    "\n",
    "    ## convert to xr.DataArray\n",
    "    return xr.DataArray(autocorr, coords={\"lag\": lags})\n",
    "\n",
    "\n",
    "def get_autocorr_by_month(x, lags):\n",
    "    \"\"\"Get autocorrelation for each month, and stack in array\"\"\"\n",
    "\n",
    "    ## compute autocorrelation for each month\n",
    "    autocorr = [get_autocorr(x, lags, month=m) for m in np.arange(1, 13)]\n",
    "\n",
    "    ## convert to xarray\n",
    "    return xr.concat(autocorr, dim=pd.Index(np.arange(1, 13), name=\"month\"))\n",
    "\n",
    "\n",
    "def load_simulation(varname, member_id, simulation_type, preprocess_func=None):\n",
    "    \"\"\"\n",
    "    Load dataset for single simulation, for single variable.\n",
    "    Arguments:\n",
    "        - varname: name of variable to load, one of {\"SST\",\"PSL\"}\n",
    "        - member_id: ID of ensemble member to load, an integer in the range [1,10]\n",
    "        - simulation_type: one of {\"hist\", \"rcp85\"}\n",
    "        - preprocess func: optional preprocessing function to apply to the simulation\n",
    "    Returns:\n",
    "        - xarray dataarray with given data\n",
    "    \"\"\"\n",
    "\n",
    "    ## Filepath to the CESM LENS dataset\n",
    "    lens_fp = pathlib.Path(\"cmip6/data/cmip6/CMIP/NCAR/LENS\")\n",
    "\n",
    "    #### 1. get filepath to data\n",
    "    data_fp = SERVER_FP / lens_fp / pathlib.Path(varname)\n",
    "\n",
    "    #### 2. get naming pattern for files to open\n",
    "    if simulation_type == \"hist\":\n",
    "        file_pattern = f\"*20TRC*.{member_id:03d}.*.nc\"\n",
    "\n",
    "    elif simulation_type == \"rcp85\":\n",
    "        file_pattern = f\"*RCP85*.{member_id:03d}.*.nc\"\n",
    "\n",
    "    else:\n",
    "        print(\"Not a valid simulation type\")\n",
    "\n",
    "    #### 3. open the relevant datasets, applying preprocessing function\n",
    "    fp = list(data_fp.glob(file_pattern))[0]\n",
    "    data = preprocess_func(xr.open_dataset(fp))\n",
    "\n",
    "    return data[varname].squeeze(drop=True).compute()\n",
    "\n",
    "\n",
    "def trim(data, lon_range=[280, 300], lat_range=[35, 45]):\n",
    "    \"\"\"select part of data in given longitude/latitude range\"\"\"\n",
    "\n",
    "    ## check if data is on the \"T\"-grid\n",
    "    on_Tgrid = \"TLONG\" in data.coords\n",
    "\n",
    "    ## handle trimming for T-grid\n",
    "    if on_Tgrid:\n",
    "\n",
    "        ## helper function to check if 'x' is in 'x_range'\n",
    "        isin_range = lambda x, x_range: (x_range[0] <= x) & (x <= x_range[1])\n",
    "\n",
    "        ## get mask for data in given lon/lat range\n",
    "        in_lon_range = isin_range(data[\"TLONG\"], lon_range)\n",
    "        in_lat_range = isin_range(data[\"TLAT\"], lat_range)\n",
    "        in_lonlat_range = in_lon_range & in_lat_range\n",
    "\n",
    "        ## load to memory\n",
    "        in_lonlat_range.load()\n",
    "\n",
    "        ## Retain all points with at least one valid grid cell\n",
    "        x_idx = in_lonlat_range.any(\"nlat\")\n",
    "        y_idx = in_lonlat_range.any(\"nlon\")\n",
    "\n",
    "        ## select given points\n",
    "        return data.isel(nlon=x_idx, nlat=y_idx)\n",
    "\n",
    "    else:\n",
    "        return data.sel(lon=slice(*lon_range), lat=slice(*lat_range))\n",
    "\n",
    "\n",
    "def load_ensemble_helper(varname, simulation_type, preprocess_func=None):\n",
    "    \"\"\"\n",
    "    Load all ensemble members for given simulation type and variable.\n",
    "    Arguments:\n",
    "        - varname: name of variable to load, one of {\"SST\",\"PSL\"}\n",
    "        - simulation_type: one of {\"hist\", \"rcp85\"}\n",
    "        - preprocess func: optional preprocessing function to apply to the simulation\n",
    "    Returns:\n",
    "        - xarray dataarray with given data and 'ensemble' dimension\n",
    "    \"\"\"\n",
    "\n",
    "    ## put arguments in dictionary\n",
    "    kwargs = dict(\n",
    "        varname=varname,\n",
    "        simulation_type=simulation_type,\n",
    "        preprocess_func=preprocess_func,\n",
    "    )\n",
    "\n",
    "    ## put results in list\n",
    "    data = [load_simulation(member_id=i, **kwargs) for i in tqdm.tqdm(np.arange(1, 36))]\n",
    "\n",
    "    ## concatenate data along the \"ensemble\" dimension\n",
    "    ensemble_dim = pd.Index(np.arange(1, 36), name=\"member\")\n",
    "    data = xr.concat(data, dim=ensemble_dim)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_ensemble(varname, simulation_type, preprocess_func=None, save_fp=None):\n",
    "    \"\"\"\n",
    "    Load all ensemble members for given simulation type and variable.\n",
    "    (Checks if data exists locally first).\n",
    "    Arguments:\n",
    "        - varname: name of variable to load, one of {\"SST\",\"PSL\"}\n",
    "        - simulation_type: one of {\"hist\", \"rcp85\"}\n",
    "        - preprocess func: optional preprocessing function to apply to the simulation\n",
    "        - save_fp: pathlib.Path object (save the result here if specified)\n",
    "    Returns:\n",
    "        - xarray dataarray with given data and 'ensemble' dimension\n",
    "    \"\"\"\n",
    "\n",
    "    ## put arguments in dictionary\n",
    "    kwargs = dict(\n",
    "        varname=varname,\n",
    "        simulation_type=simulation_type,\n",
    "        preprocess_func=preprocess_func,\n",
    "    )\n",
    "\n",
    "    ## load pre-computed data if it exists\n",
    "    if save_fp is not None:\n",
    "\n",
    "        ## path to file\n",
    "        save_fp = save_fp / f\"{varname}_{simulation_type}.nc\"\n",
    "\n",
    "        ## check if file exists:\n",
    "        if save_fp.is_file():\n",
    "            data = xr.open_dataarray(save_fp)\n",
    "\n",
    "        else:\n",
    "\n",
    "            ## load the data and save to file for next time\n",
    "            data = load_ensemble_helper(**kwargs)\n",
    "\n",
    "            print(\"saving to file\")\n",
    "            data.to_netcdf(save_fp)\n",
    "\n",
    "    else:\n",
    "\n",
    "        ## don't load/save the data\n",
    "        data = load_ensemble_helper(**kwargs)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def preprocess(data):\n",
    "    \"\"\"\n",
    "    Preprocessing steps:\n",
    "        1. remove data before Feb 1920\n",
    "        2. trim in lon/lat space\n",
    "        3. convert time dimension from cftime to datetime\n",
    "    \"\"\"\n",
    "\n",
    "    ## trim in time\n",
    "    data_ = data.sel(time=slice(\"1920-02\", None))\n",
    "\n",
    "    ## trim in space\n",
    "    data_ = trim(data_)\n",
    "\n",
    "    ## update time dimension\n",
    "    start_year = data_.time.isel(time=0).dt.year.item()\n",
    "    start_month = data_.time.isel(time=0).dt.month.item()\n",
    "    start_date = f\"{start_year}-{start_month}-01\"\n",
    "    data_[\"time\"] = pd.date_range(start=start_date, periods=len(data_.time), freq=\"MS\")\n",
    "\n",
    "    return data_\n",
    "\n",
    "\n",
    "def rolling_fn_helper(x, fn, window_size=15):\n",
    "    \"\"\"Function to get rolling standard deviation ('sigma').\n",
    "    'window_size' is number of timesteps to include in each averaging window\"\"\"\n",
    "\n",
    "    ## get rolling object\n",
    "    rolling_obj = x.rolling({\"time\": window_size}, center=True)\n",
    "\n",
    "    ## apply function\n",
    "    fn_eval = fn(rolling_obj)\n",
    "\n",
    "    ## get half window size\n",
    "    n = int((window_size - 1) / 2)\n",
    "\n",
    "    ## trim to remove NaNs\n",
    "    return fn_eval.isel(time=slice(n, -n))\n",
    "\n",
    "\n",
    "def rolling_fn_bymonth(x, fn, window_size=15):\n",
    "    \"\"\"Apply rolling function to each month separately\"\"\"\n",
    "\n",
    "    ## get rolling function to pass to apply to each month\n",
    "    rolling_fn_ = lambda y: rolling_fn_helper(y, fn, window_size=window_size)\n",
    "\n",
    "    ## evaluate\n",
    "    fn_eval = x.groupby(\"time.month\").map(rolling_fn_)\n",
    "\n",
    "    ## reindex so time is ascending\n",
    "    fn_eval = fn_eval.reindex({\"time\": np.sort(fn_eval.time)})\n",
    "\n",
    "    return fn_eval\n",
    "\n",
    "\n",
    "def rolling_fn(x, fn, window_size=15, by_month=True):\n",
    "    \"\"\"apply rolling function; handle by_month cases (True or False)\"\"\"\n",
    "\n",
    "    ## keyword args\n",
    "    kwargs = dict(x=x, fn=fn, window_size=window_size)\n",
    "\n",
    "    ## handle cases\n",
    "    if by_month:\n",
    "        return rolling_fn_bymonth(**kwargs)\n",
    "\n",
    "    else:\n",
    "        return rolling_fn_helper(**kwargs)\n",
    "\n",
    "\n",
    "def get_rolling_stddev(x, window_size=31, by_month=True):\n",
    "    \"\"\"Function to get rolling standard deviation ('sigma').\"\"\"\n",
    "\n",
    "    ## get sigma function\n",
    "    fn = lambda y: y.std()\n",
    "\n",
    "    return rolling_fn(x, fn=fn, window_size=window_size, by_month=by_month)\n",
    "\n",
    "\n",
    "def get_rolling_mean(x, window_size=31, by_month=True):\n",
    "    \"\"\"Function to get rolling standard deviation ('sigma').\"\"\"\n",
    "\n",
    "    ## get sigma function\n",
    "    fn = lambda y: y.mean()\n",
    "\n",
    "    return rolling_fn(x, fn=fn, window_size=window_size, by_month=by_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333948ce-71b3-45c2-a758-89326cac7d36",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e39c0a-ccb3-476f-9d93-a13338805a88",
   "metadata": {},
   "source": [
    "### Set filepaths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65329af-344f-4b7e-92da-1d12401f1dd1",
   "metadata": {},
   "source": [
    "````{admonition} To-do\n",
    "Update the filepaths ```SERVER_FP``` and ```save_fp``` in the code cell below.\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eb8c3a-dd13-4c17-be12-a52d2e458682",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Path to file server\n",
    "SERVER_FP = pathlib.Path(\"/vortexfs1/share\")\n",
    "\n",
    "## Specify folder location for saving trimmed data (\"./\" means current directory)\n",
    "save_fp = pathlib.Path(\"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2174c18-f322-4761-8852-56831c0ad804",
   "metadata": {},
   "source": [
    "### Do the loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146b4707-46e8-40a6-8ac2-76355769fd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data\n",
    "data_hist = load_ensemble(\"SST\", \"hist\", preprocess_func=preprocess, save_fp=save_fp)\n",
    "data_rcp = load_ensemble(\"SST\", \"rcp85\", preprocess_func=preprocess, save_fp=save_fp)\n",
    "\n",
    "## concatenate in time\n",
    "data = xr.concat([data_hist, data_rcp], dim=\"time\")\n",
    "\n",
    "## trim in time\n",
    "data = data.sel(time=slice(None, \"2081-01\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d314c3-21bb-442d-a21e-9c3975c19be9",
   "metadata": {},
   "source": [
    "## Plot a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf7619b-ed04-4c0f-bcc2-66b659ff0a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "## blank canvas\n",
    "fig = plt.figure()\n",
    "\n",
    "## make background of trop. Pacific\n",
    "fig, ax = plot_setup_woodshole(fig)\n",
    "\n",
    "## plot the data\n",
    "plot_data = ax.pcolormesh(\n",
    "    data_hist.TLONG,\n",
    "    data_hist.TLAT,\n",
    "    data_hist.isel(member=0, time=0),\n",
    "    cmap=\"cmo.thermal\",\n",
    "    # vmax=30,\n",
    "    # vmin=15,\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "\n",
    "## make a colorbar\n",
    "cb = fig.colorbar(plot_data, fraction=0.015, pad=0.05)\n",
    "\n",
    "## plot outline of Niño 3.4 region\n",
    "ax = plot_box_outline(ax, lon_range=[190, 240], lat_range=[-5, 5])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d351eff-fdf0-42ac-ad9f-aaac49259080",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2c49dc-0c82-49d3-9045-1f1cc630f150",
   "metadata": {},
   "source": [
    "### Compute index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99dcfda-c529-43b4-b109-bcd9586dca29",
   "metadata": {},
   "source": [
    "Function to compute Niño 3.4 index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bb35d3-deaa-477b-8d6d-92a4ad2bba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_T_wh(x):\n",
    "    \"\"\"Compute Woods Hole temperature index\"\"\"\n",
    "\n",
    "    ## get subset of data inside the box\n",
    "    data_subset = trim(x, lon_range=[287.5, 293.5], lat_range=[39, 44])\n",
    "\n",
    "    ## compute spatial average\n",
    "    return data_subset.mean([\"nlon\", \"nlat\"])\n",
    "\n",
    "\n",
    "## do the computation here\n",
    "idx = compute_T_wh(data)\n",
    "\n",
    "\n",
    "def plot_quantiles(ax, x, label=None, month=None, time_dim=\"time\", **kwargs):\n",
    "    \"\"\"plot .1, .5, and .9 quantiles on given ax object\"\"\"\n",
    "\n",
    "    ## filter for month if specified\n",
    "    if month is not None:\n",
    "        x = x.sel(time=(x.time.dt.month == month))\n",
    "\n",
    "    ## compute quantiles\n",
    "    x_quantiles = x.quantile([0.1, 0.5, 0.9], dim=\"member\")\n",
    "\n",
    "    ## plot median\n",
    "    ax.plot(\n",
    "        x_quantiles[time_dim],\n",
    "        x_quantiles.sel(quantile=0.5),\n",
    "        lw=2,\n",
    "        label=label,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    ## plot upper/lower bounds\n",
    "    for q in [0.1, 0.9]:\n",
    "        ax.plot(\n",
    "            x_quantiles[time_dim],\n",
    "            x_quantiles.sel(quantile=q),\n",
    "            lw=1,\n",
    "            alpha=0.5,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def rolling_fn_helper(x, fn, window_size=15):\n",
    "    \"\"\"Function to get rolling standard deviation ('sigma').\n",
    "    'window_size' is number of timesteps to include in each averaging window\"\"\"\n",
    "\n",
    "    ## get rolling object\n",
    "    rolling_obj = x.rolling({\"time\": window_size}, center=True)\n",
    "\n",
    "    ## apply function\n",
    "    fn_eval = fn(rolling_obj)\n",
    "\n",
    "    ## get half window size\n",
    "    n = int((window_size - 1) / 2)\n",
    "\n",
    "    ## trim to remove NaNs\n",
    "    return fn_eval.isel(time=slice(n, -n))\n",
    "\n",
    "\n",
    "def rolling_fn_bymonth(x, fn, window_size=15):\n",
    "    \"\"\"Apply rolling function to each month separately\"\"\"\n",
    "\n",
    "    ## get rolling function to pass to apply to each month\n",
    "    rolling_fn_ = lambda y: rolling_fn_helper(y, fn, window_size=window_size)\n",
    "\n",
    "    ## evaluate\n",
    "    fn_eval = x.groupby(\"time.month\").map(rolling_fn_)\n",
    "\n",
    "    ## reindex so time is ascending\n",
    "    fn_eval = fn_eval.reindex({\"time\": np.sort(fn_eval.time)})\n",
    "\n",
    "    return fn_eval\n",
    "\n",
    "\n",
    "def rolling_fn(x, fn, window_size=15, by_month=True):\n",
    "    \"\"\"apply rolling function; handle by_month cases (True or False)\"\"\"\n",
    "\n",
    "    ## keyword args\n",
    "    kwargs = dict(x=x, fn=fn, window_size=window_size)\n",
    "\n",
    "    ## handle cases\n",
    "    if by_month:\n",
    "        return rolling_fn_bymonth(**kwargs)\n",
    "\n",
    "    else:\n",
    "        return rolling_fn_helper(**kwargs)\n",
    "\n",
    "\n",
    "def get_rolling_stddev(x, window_size=31, by_month=True):\n",
    "    \"\"\"Function to get rolling standard deviation ('sigma').\"\"\"\n",
    "\n",
    "    ## get sigma function\n",
    "    fn = lambda y: y.std()\n",
    "\n",
    "    return rolling_fn(x, fn=fn, window_size=window_size, by_month=by_month)\n",
    "\n",
    "\n",
    "def get_rolling_mean(x, window_size=31, by_month=True):\n",
    "    \"\"\"Function to get rolling standard deviation ('sigma').\"\"\"\n",
    "\n",
    "    ## get sigma function\n",
    "    fn = lambda y: y.mean()\n",
    "\n",
    "    return rolling_fn(x, fn=fn, window_size=window_size, by_month=by_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bea78c-1401-438a-853b-624f255ff55a",
   "metadata": {},
   "source": [
    "## Separate forced response from internal variability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650bce34-a919-4095-a9c2-7a263493e7d3",
   "metadata": {},
   "source": [
    "Estimate forced response and internval variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b91a62-1f48-42b1-9de6-7281c6c8e285",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define forced response as ensemble mean\n",
    "idx_forced = idx.mean(\"member\")\n",
    "\n",
    "## internal variability is the residual\n",
    "idx_iv = idx - idx_forced\n",
    "\n",
    "## compute annual means\n",
    "get_ann_mean = lambda x: x.groupby(\"time.year\").mean().sel(year=slice(None, 2080))\n",
    "idx_forced_ann = get_ann_mean(idx_forced)\n",
    "idx_iv_ann = get_ann_mean(idx_iv)\n",
    "idx_ann = get_ann_mean(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c2ed4c-4540-4fdf-be56-5d6b331e2718",
   "metadata": {},
   "source": [
    "Lets plot the annual mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba63602-95a7-4b87-af52-59682de06a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up plot\n",
    "fig, axs = plt.subplots(1, 2, figsize=(7, 2.75), layout=\"constrained\")\n",
    "\n",
    "## plot ensemble median and 10%/90% percentiles\n",
    "plot_quantiles(axs[0], idx_ann, c=\"k\", time_dim=\"year\", label=\"Ensemble median\")\n",
    "\n",
    "## plot forced response (ensemble mean)\n",
    "axs[0].plot(idx_forced_ann.year, idx_forced_ann, c=\"r\", lw=2, label=\"Ensemble mean\")\n",
    "\n",
    "## plot internval variability\n",
    "kwargs = dict(lw=0.5, alpha=0.5, c=\"gray\")\n",
    "for m in idx_iv_ann.member[:10]:\n",
    "    axs[1].plot(idx_iv_ann.year, idx_iv_ann.sel(member=m), **kwargs)\n",
    "\n",
    "\n",
    "## label plots\n",
    "for ax in axs:\n",
    "    ax.set_xticks([1920, 2000, 2080])\n",
    "    ax.set_xlabel(\"Year\")\n",
    "    ax.set_ylabel(r\"$^{\\circ}$C\")\n",
    "\n",
    "axs[0].set_yticks([18, 20, 22])\n",
    "axs[1].set_yticks([-1, 0, 1])\n",
    "axs[0].set_title(\"Forced response\")\n",
    "axs[1].set_title(\"Internal variability (10/35 members)\")\n",
    "axs[1].axhline(0, ls=\"--\", c=\"k\", zorder=0.5)\n",
    "axs[1].yaxis.tick_right()\n",
    "axs[1].yaxis.set_label_position(\"right\")\n",
    "axs[0].legend(prop=dict(size=8))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5381785-665c-4476-9b89-885cae6aa10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up plot\n",
    "fig, ax = plt.subplots(figsize=(3.5, 2.75), layout=\"constrained\")\n",
    "\n",
    "## plot data\n",
    "plot_quantiles(ax, annual_mean, c=\"k\", time_dim=\"year\")\n",
    "\n",
    "## label plot\n",
    "ax.set_xticks([1920, 2000, 2080])\n",
    "ax.set_yticks([18, 20, 22])\n",
    "ax.set_ylabel(r\"$^{\\circ}$C\")\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_title(\"Annual mean temperature\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beacb9ad-823b-43da-9bb5-4a746b9db2d0",
   "metadata": {},
   "source": [
    "## Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3bcaf8-b162-4228-9cc7-8a6efdc1cd23",
   "metadata": {},
   "source": [
    "### Estimate forced signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b33e6e-3d8f-418b-9f5b-9603cbd69d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "## defined forced signal as ensemble mean, smoothed by 3-yr rolling average\n",
    "idx_rolling = get_rolling_mean(idx, window_size=3, by_month=True)\n",
    "# idx_forced = idx_rolling.mean(\"member\")\n",
    "\n",
    "## set up plot\n",
    "fig, ax = plt.subplots(figsize=(3.5, 2.75), layout=\"constrained\")\n",
    "\n",
    "## plot data\n",
    "plot_quantiles(ax, idx_rolling, month=6, c=\"k\")\n",
    "\n",
    "## label plot\n",
    "ax.set_xticks([1920, 2000, 2080])\n",
    "ax.set_yticks([18, 20, 22])\n",
    "ax.set_ylabel(r\"$^{\\circ}$C\")\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_title(\"Annual mean temperature\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfd860b-7b04-4c4d-a059-629cc298a324",
   "metadata": {},
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2dfa49-a830-4078-abec-b56df99c5b9d",
   "metadata": {},
   "source": [
    "Standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6880875-7262-46f6-ba24-8551a53c763c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b550f2e-377f-4efd-8578-62c671b1ee54",
   "metadata": {},
   "source": [
    "#### Change in Mar/Sep average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b158492-2763-49af-8dce-8f618b79f760",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute rolling mean for each ensemble member\n",
    "rolling_mean = get_rolling_mean(idx, window_size=3, by_month=True)\n",
    "\n",
    "## compute quantiles\n",
    "rolling_mean_q = rolling_mean.quantile(q=[0.1, 0.5, 0.9], dim=\"member\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a0ae7f-4ebc-4761-9a2c-61849cba539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up plot\n",
    "fig, ax = plt.subplots(figsize=(3.5, 2.75), layout=\"constrained\")\n",
    "\n",
    "## plot median\n",
    "ax.plot(\n",
    "    rolling_mean_q.time,\n",
    "    rolling_mean_q.sel(quantile=0.5),\n",
    "    lw=2,\n",
    "    c=\"k\",\n",
    ")\n",
    "\n",
    "## plot upper/lower bounds\n",
    "kwargs = dict(lw=1, c=\"gray\")\n",
    "for q in [0.1, 0.9]:\n",
    "    ax.plot(\n",
    "        annual_mean_stats.year,\n",
    "        annual_mean_stats.sel(quantile=q),\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "## label plot\n",
    "ax.set_xticks([1920, 2000, 2080])\n",
    "ax.set_yticks([18, 20, 22])\n",
    "ax.set_ylabel(r\"$^{\\circ}$C\")\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_title(\"Annual mean temperature\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeaa91e-7e7c-4244-9584-642c516d2927",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rolling_mean.median(\"member\").isel(time=slice(None, None, 12)))\n",
    "# plt.plot(rolling_mean.median(\"member\").isel(time=slice(6,None,12)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d63a49-9e06-4b80-b02d-dad93ac91c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx.groupby(\"time.month\").map(get_sigma_rolling).median(\"member\").isel(\n",
    "    time=slice(None, None, 12)\n",
    ").time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76d187c-bce5-47a4-9b89-5c1a165db831",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "    idx.groupby(\"time.month\")\n",
    "    .map(get_sigma_rolling)\n",
    "    .median(\"member\")\n",
    "    .isel(time=slice(8, None, 12))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bdad60-f9a9-4788-8a1c-f739a26338cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_rolling = get_sigma_rolling(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ad2280-9261-4f53-b878-2a629748ed1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_rolling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788bd52d-62a3-4731-9fea-52f2062a6d6c",
   "metadata": {},
   "source": [
    "Seasonal stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4291c84a-3bd1-4846-91b1-4a7b7b238b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate [.1, .5, .9] quantiles\n",
    "mean_quantile = idx.quantile(q=[0.1, 0.5, 0.9], dim=\"member\")\n",
    "\n",
    "## function to subset for given month\n",
    "sel_month = lambda x, month: x.isel(time=x.time.dt.month == month)\n",
    "\n",
    "## get data for march and september\n",
    "mean_quantile_mar = sel_month(mean_quantile, 3)\n",
    "mean_quantile_sep = sel_month(mean_quantile, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14044613-d44c-42ed-a7f4-2c81046a5440",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4, 3), layout=\"constrained\")\n",
    "\n",
    "for q in [0.1, 0.5, 0.9]:\n",
    "    ax.plot(\n",
    "        mean_quantile_mar.time,\n",
    "        mean_quantile_mar.sel(quantile=q)\n",
    "        - mean_quantile_mar.sel(quantile=0.5).isel(time=5),\n",
    "        lw=1,\n",
    "        c=\"k\",\n",
    "    )\n",
    "\n",
    "for q in [0.1, 0.5, 0.9]:\n",
    "    ax.plot(\n",
    "        mean_quantile_sep.time,\n",
    "        mean_quantile_sep.sel(quantile=q)\n",
    "        - mean_quantile_sep.sel(quantile=0.5).isel(time=0),\n",
    "        lw=1,\n",
    "        c=\"orange\",\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42808055-67eb-4b9f-bf78-6d16a9cfc07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx.groupby(\"time.month\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8470d0-60c4-4745-acd1-cfe57000fde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(idx.isel(time=slice(0, None, 12)).mean(\"member\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5909d1b-c93f-4803-b535-37be9a6a2745",
   "metadata": {},
   "source": [
    "Compute the index and do some pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27617f22-1398-4760-93aa-1efd6f0844fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute nino 3.4 climatology\n",
    "nino34_raw = get_nino34_idx(data_hist)\n",
    "nino34_mean = nino34_raw.groupby(\"time.month\").mean([\"time\", \"member\"])\n",
    "nino34_std = nino34_raw.groupby(\"time.month\").std([\"time\", \"member\"])\n",
    "\n",
    "## Compute anomalies (spatial data and nino 3.4)\n",
    "data_anom = data_hist.groupby(\"time.month\") - spatial_mean\n",
    "nino34_anom = get_nino34_idx(data_anom)\n",
    "\n",
    "## compute detrended anomalies (spatial data and Niño 3.4)\n",
    "data_trend = get_trend(data_anom.mean(\"member\"))\n",
    "data_detrend = data_anom - data_trend\n",
    "nino34_detrend = get_nino34_idx(data_detrend)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407377f1-86ff-4eab-b4c6-556da029f54e",
   "metadata": {},
   "source": [
    "#### plot seasonal cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdbefcd-e513-43b4-b040-aa7046551563",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make the plot\n",
    "fig, ax = plot_seasonal_cycle(nino34_mean, nino34_std)\n",
    "\n",
    "## add some labels\n",
    "ax.set_xticks([1, 7, 12], labels=[\"Jan\", \"Jul\", \"Dec\"])\n",
    "ax.set_title(r\"Niño 3.4 climatology\")\n",
    "ax.set_ylabel(r\"$K$\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3512ed7f-b8ac-4e02-89bf-d731dc9a93e4",
   "metadata": {},
   "source": [
    "#### plot Niño 3.4 over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217c46ab-398a-4211-8c17-953d085701b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 3))\n",
    "\n",
    "## plot individual ensemble members\n",
    "for m in nino34_anom.member:\n",
    "    ax.plot(data_hist.time, nino34_anom.sel(member=m), alpha=0.5, c=\"gray\", lw=0.5)\n",
    "\n",
    "## plot ensemble mean\n",
    "ax.plot(\n",
    "    data_hist.time,\n",
    "    nino34_anom.mean(\"member\"),\n",
    "    c=\"r\",\n",
    "    lw=2,\n",
    "    zorder=2,\n",
    "    label=\"Ensemble mean\",\n",
    ")\n",
    "\n",
    "## label\n",
    "ax.set_ylabel(r\"Niño 3.4 ($^{\\circ}C$)\")\n",
    "ax.legend()\n",
    "ax.axhline(0, ls=\"--\", c=\"k\", lw=1)\n",
    "ax.set_xlim([datetime.datetime(1920, 1, 1), datetime.datetime(2006, 12, 31)])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075323ce-6a40-478d-ab61-946675f7e4d4",
   "metadata": {},
   "source": [
    "#### Estimate trend for historical simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfe221d-23de-43a3-84e0-c762456050ef",
   "metadata": {},
   "source": [
    "Function to estimate trend in units of [1/century]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af031689-a712-4309-9f5d-bd3138a9c5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trend_per_100yrs(x):\n",
    "    \"\"\"get trend of data in units of 100/yrs\"\"\"\n",
    "\n",
    "    ## Get timeseries of trend\n",
    "    x_trend_timeseries = get_trend(x)\n",
    "\n",
    "    ## get total trend change over time period\n",
    "    dx = x_trend_timeseries[-1] - x_trend_timeseries[0]\n",
    "\n",
    "    ## convert to units of 1/month by dividing by number of months\n",
    "    dt = len(x.time)\n",
    "    dx_dt = dx / dt\n",
    "\n",
    "    ## convert from 1/month to 1/(100 yrs)\n",
    "    months_per_100_yrs = 100 * 12\n",
    "    dx_dt *= months_per_100_yrs\n",
    "\n",
    "    return dx_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45241e29-a49d-4cfa-8624-d1a6fad66457",
   "metadata": {},
   "source": [
    "Compute trend in Niño 3.4 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2c01e5-fd33-4c2e-97f8-b3e37973c541",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute nino34_trend\n",
    "nino34_trend = get_trend_per_100yrs(nino34_anom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03111732-13ca-42d2-aa6d-6743cb9fea6f",
   "metadata": {},
   "source": [
    "Plot result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c169833-8d1c-4e80-a021-3cce42e75468",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(1, 3))\n",
    "ax.scatter(np.ones_like(nino34_trend), nino34_trend, c=\"k\", s=10)\n",
    "ax.axhline(nino34_trend.mean(), c=\"k\", ls=\"--\", label=\"Mean\")\n",
    "ax.axhline(0, c=\"gray\", alpha=0.5, lw=1)\n",
    "ax.set_yticks(\n",
    "    [\n",
    "        0,\n",
    "        0.3,\n",
    "        0.6,\n",
    "    ]\n",
    ")\n",
    "ax.set_xticks([])\n",
    "ax.set_ylim([-0.1, 0.8])\n",
    "ax.legend(prop={\"size\": 8})\n",
    "ax.set_title(\"Niño 3.4 trend by ensemble member\")\n",
    "ax.set_ylabel(r\"$^{\\circ}C$ / 100 yrs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672ad2e7-5034-4be9-8423-9f8f12c3ef93",
   "metadata": {},
   "source": [
    "Compute spatial trend (trend at each gridcell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf927d0b-4ef9-47d7-bb2e-f380ded4e6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute trend\n",
    "spatial_trend = get_trend_per_100yrs(data_anom).mean(\"member\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89a3260-6155-4154-a1f0-5b19a70e288c",
   "metadata": {},
   "source": [
    "Plot spatial trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae6514e-01b8-4d98-b479-56d852f87c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot\n",
    "fig = plt.figure(figsize=(10, 3))\n",
    "\n",
    "## make background of trop. Pacific\n",
    "fig, ax = plot_setup_pacific(fig)\n",
    "\n",
    "## plot the data\n",
    "plot_data = ax.pcolormesh(\n",
    "    data_hist.TLONG,\n",
    "    data_hist.TLAT,\n",
    "    spatial_trend,\n",
    "    cmap=\"cmo.balance\",\n",
    "    vmax=1,\n",
    "    vmin=-1,\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "\n",
    "## make a colorbar\n",
    "cb = fig.colorbar(\n",
    "    plot_data,\n",
    "    ticks=[-1, 0, 1],\n",
    "    label=r\"$^{\\circ}C$ / 100 yrs\",\n",
    "    fraction=0.015,\n",
    "    pad=0.05,\n",
    ")\n",
    "\n",
    "## plot outline of Niño 3.4 region\n",
    "ax = plot_box_outline(ax, lon_range=[190, 240], lat_range=[-5, 5])\n",
    "\n",
    "## label\n",
    "ax.set_title(\"Trend over historical simulation\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ba053e-33ff-40b0-8b21-dc10423893c6",
   "metadata": {},
   "source": [
    "### Spatial pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900b55b8-a9c3-4cc3-b821-faffde294648",
   "metadata": {},
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4554d41-391d-474b-8a25-fa9c50a79d75",
   "metadata": {},
   "source": [
    "Functions to compute regression and correlation coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a25ab0-2f9c-4931-ad73-fc1f8c247564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regression_coef(Y, X):\n",
    "    \"\"\"\n",
    "    Solves for 'M' in the regression equation Y = MX.\n",
    "    Compute covariance matrices over 'member' and 'time' dimensions.\n",
    "    Assumes data is already centered\n",
    "        Y.mean([\"time\",\"member\"]) == 0, and\n",
    "        X.mean([\"time\",\"member\"]) == 0\n",
    "    \"\"\"\n",
    "\n",
    "    ## compute covariance matrices\n",
    "    cov_xy = (X * Y).mean([\"member\", \"time\"])\n",
    "    cov_xx = (X * X).mean([\"member\", \"time\"])\n",
    "\n",
    "    ## least squares fit for 'M'\n",
    "    M = cov_xy / cov_xx\n",
    "\n",
    "    return M\n",
    "\n",
    "\n",
    "def get_corr_coef(Y, X):\n",
    "    \"\"\"\n",
    "    Finds correlation between X and Y.\n",
    "    Compute covariance matrices over 'member' and 'time' dimensions.\n",
    "    Assumes data is already centered\n",
    "        Y.mean([\"time\",\"member\"]) == 0, and\n",
    "        X.mean([\"time\",\"member\"]) == 0\n",
    "    \"\"\"\n",
    "\n",
    "    ## compute covariance matrices\n",
    "    cov_xy = (X * Y).mean([\"member\", \"time\"])\n",
    "    cov_xx = (X * X).mean([\"member\", \"time\"])\n",
    "    cov_yy = (Y * Y).mean([\"member\", \"time\"])\n",
    "\n",
    "    ## least squares fit for 'M'\n",
    "    r = cov_xy / np.sqrt(cov_xx * cov_yy)\n",
    "\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fc5c8a-a24e-462b-b1b6-728c6224d24b",
   "metadata": {},
   "source": [
    "Compute the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b168755f-d656-49ea-9bb4-414d8335b615",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute linear regression coefficient and correlation coefficient\n",
    "regression_coef = get_regression_coef(data_detrend, nino34_detrend)\n",
    "corr = get_corr_coef(data_detrend, nino34_detrend)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c441796-9b68-46fa-947b-c4b0f8b34717",
   "metadata": {},
   "source": [
    "Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aca28b-4438-44fe-9eab-0fb3c19d96f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot regression coefficient\n",
    "fig = plt.figure(figsize=(10, 3))\n",
    "\n",
    "## make background of trop. Pacific\n",
    "fig, ax = plot_setup_pacific(fig)\n",
    "\n",
    "## plot the data\n",
    "plot_data = ax.pcolormesh(\n",
    "    data_hist.TLONG,\n",
    "    data_hist.TLAT,\n",
    "    regression_coef,\n",
    "    cmap=\"cmo.balance\",\n",
    "    vmax=1.5,\n",
    "    vmin=-1.5,\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "\n",
    "## make a colorbar\n",
    "cb = fig.colorbar(\n",
    "    plot_data,\n",
    "    ticks=[-1.5, 0, 1.5],\n",
    "    label=r\"$^{\\circ}C$ / Niño$_{3.4}$\",\n",
    "    fraction=0.015,\n",
    "    pad=0.05,\n",
    ")\n",
    "\n",
    "## plot outline of Niño 3.4 region\n",
    "ax = plot_box_outline(ax, lon_range=[190, 240], lat_range=[-5, 5], c=\"w\")\n",
    "\n",
    "## label\n",
    "ax.set_title(r\"ENSO spatial pattern (historical)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d25b5cb-67d5-473e-9bbc-7e5831c417e1",
   "metadata": {},
   "source": [
    "#### Composite\n",
    "First, a function to compute composites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1324e4df-5288-43fa-a102-42c5da31e0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def composite(data, mask):\n",
    "    \"\"\"\n",
    "    Create composite (average) based on specified mask.\n",
    "    Args:\n",
    "        - data: dataarray to use for the composite\n",
    "        - mask: dataarray with dimensions [\"member\",\"time\"];\n",
    "            used to filter 'data' to create the composite\n",
    "    Returns:\n",
    "        - composite\n",
    "        - n_samples: number of samples in the composite\n",
    "    \"\"\"\n",
    "\n",
    "    ## average over masked entries\n",
    "    composite = data.where(mask).mean([\"member\", \"time\"], skipna=True)\n",
    "\n",
    "    ## get number of samples\n",
    "    n_samples = mask.sum()\n",
    "\n",
    "    return composite, n_samples\n",
    "\n",
    "\n",
    "## compute composites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0b3672-1488-4200-b8dc-9dea9bf951c9",
   "metadata": {},
   "source": [
    "Next, compute the composites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3e4d66-4ec3-4666-936a-c794d02cf1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get composite for warm and cold events\n",
    "comp_warm, n_warm = composite(data_detrend, mask=nino34_detrend > 1.5)\n",
    "comp_cold, n_cold = composite(data_detrend, mask=nino34_detrend < -1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c95445b-5248-4cf8-a323-f01b031e182a",
   "metadata": {},
   "source": [
    "Finally, plot the composites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc05b1c-ad46-4e4a-8b0a-8b6c67e17007",
   "metadata": {},
   "outputs": [],
   "source": [
    "## spatial pattern of composites\n",
    "for comp, count, label in zip(\n",
    "    [comp_warm, comp_cold], [n_warm, n_cold], [\"warm\", \"cold\"]\n",
    "):\n",
    "\n",
    "    ## plot regression coefficient\n",
    "    fig = plt.figure(figsize=(10, 3))\n",
    "\n",
    "    ## make background of trop. Pacific\n",
    "    fig, ax = plot_setup_pacific(fig)\n",
    "\n",
    "    ## plot the data\n",
    "    plot_data = ax.pcolormesh(\n",
    "        data_hist.TLONG,\n",
    "        data_hist.TLAT,\n",
    "        comp,\n",
    "        cmap=\"cmo.balance\",\n",
    "        vmax=3,\n",
    "        vmin=-3,\n",
    "        transform=ccrs.PlateCarree(),\n",
    "    )\n",
    "\n",
    "    ## make a colorbar\n",
    "    cb = fig.colorbar(\n",
    "        plot_data,\n",
    "        ticks=[-3, 0, 3],\n",
    "        label=r\"$^{\\circ}C$\",\n",
    "        fraction=0.015,\n",
    "        pad=0.05,\n",
    "    )\n",
    "\n",
    "    ## plot outline of Niño 3.4 region\n",
    "    ax = plot_box_outline(ax, lon_range=[190, 240], lat_range=[-5, 5], c=\"w\")\n",
    "\n",
    "    ## label\n",
    "    ax.set_title(f\"ENSO composite ({label}, n = {count.values.item()})\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "## Plot the asymmetry\n",
    "fig = plt.figure(figsize=(10, 3))\n",
    "\n",
    "## make background of trop. Pacific\n",
    "fig, ax = plot_setup_pacific(fig)\n",
    "\n",
    "## plot the data\n",
    "plot_data = ax.pcolormesh(\n",
    "    data_hist.TLONG,\n",
    "    data_hist.TLAT,\n",
    "    comp_warm + comp_cold,\n",
    "    cmap=\"cmo.balance\",\n",
    "    vmax=1.5,\n",
    "    vmin=-1.5,\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "\n",
    "## make a colorbar\n",
    "cb = fig.colorbar(\n",
    "    plot_data,\n",
    "    ticks=[-1.5, 0, 1.5],\n",
    "    label=r\"$^{\\circ}C$\",\n",
    "    fraction=0.015,\n",
    "    pad=0.05,\n",
    ")\n",
    "\n",
    "## plot outline of Niño 3.4 region\n",
    "ax = plot_box_outline(ax, lon_range=[190, 240], lat_range=[-5, 5], c=\"w\")\n",
    "\n",
    "## label\n",
    "ax.set_title(f\"Composite asymmetry (warm plus cold)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59bfdc8-de9f-45c8-a909-ebdbf61ed9d1",
   "metadata": {},
   "source": [
    "## Autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c792e3-93dd-427a-a5e7-2f50eb829592",
   "metadata": {},
   "source": [
    "Compute autocorrelation by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9196cef1-70a1-44e8-b4db-6c211645155a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute autocorrelation by month\n",
    "autocorr_by_month = get_autocorr_by_month(nino34_detrend, lags=np.arange(-24, 25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847c9c49-892e-491b-b7fc-0489a5b62f13",
   "metadata": {},
   "source": [
    "Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6898a55d-1503-425f-98fc-e564202ce542",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "## plot data\n",
    "lags = np.arange(0, 19)\n",
    "months = np.arange(1, 13)\n",
    "plot_data = ax.pcolormesh(\n",
    "    lags, months, autocorr_by_month.sel(lag=lags), cmap=\"cmo.balance\", vmin=-1, vmax=1\n",
    ")\n",
    "\n",
    "## colorbar\n",
    "cb = fig.colorbar(plot_data, label=\"corr. coef.\", ticks=[-1, 0, 1])\n",
    "\n",
    "## label\n",
    "ax.set_ylabel(\"Start month\")\n",
    "ax.set_xlabel(\"Lag (months)\")\n",
    "ax.set_xticks([0, 6, 12, 18])\n",
    "ax.set_yticks([2, 7, 12], labels=[\"Feb\", \"Jul\", \"Dec\"])\n",
    "ax.set_title(\"Niño 3.4 autocorrelation\")\n",
    "\n",
    "## swap direction of y-axis\n",
    "ax.set_ylim(ax.get_ylim()[::-1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cc1fa9-86ec-4e94-b38b-b3da01247ff0",
   "metadata": {},
   "source": [
    "## Future Projections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d569f6c-aef4-4ed2-89a0-816e2e5688e1",
   "metadata": {},
   "source": [
    "### Niño 3.4 Timeseries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2ca767-d860-433a-bf98-c13ac4ff65be",
   "metadata": {},
   "source": [
    "Compute Niño 3.4 in RCP 8.5 simulation and concatenate to Niño 3.4 from historical simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37332787-8ca7-457f-8f4a-16cf6969c0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute Niño 3.4 for RCP 8.5\n",
    "nino34_rcp_raw = get_nino34_idx(data_rcp)\n",
    "\n",
    "## concatenate with historical timeseries\n",
    "nino34_raw_long = xr.concat([nino34_raw, nino34_rcp_raw], dim=\"time\")\n",
    "\n",
    "## remove seasonal cycle\n",
    "deseason = lambda x: x.groupby(\"time.month\") - x.groupby(\"time.month\").mean(\n",
    "    [\"time\", \"member\"]\n",
    ")\n",
    "nino34_anom_long = deseason(nino34_raw_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf675e7-a0cb-4efe-9db8-60971b60d3d7",
   "metadata": {},
   "source": [
    "Plot concatenated timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077758a4-b60c-4466-ac86-4d181f7dd285",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot result\n",
    "fig, ax = plt.subplots(figsize=(7, 3))\n",
    "\n",
    "## plot individual ensemble members\n",
    "for m in nino34_anom_long.member:\n",
    "    ax.plot(\n",
    "        nino34_anom_long.time,\n",
    "        nino34_anom_long.sel(member=m),\n",
    "        alpha=0.5,\n",
    "        c=\"gray\",\n",
    "        lw=0.5,\n",
    "    )\n",
    "\n",
    "## plot ensemble mean\n",
    "ax.plot(\n",
    "    nino34_anom_long.time,\n",
    "    nino34_anom_long.mean(\"member\"),\n",
    "    c=\"r\",\n",
    "    lw=2,\n",
    "    zorder=2,\n",
    "    label=\"Ensemble mean\",\n",
    ")\n",
    "\n",
    "## label\n",
    "ax.set_ylabel(r\"Niño 3.4 ($^{\\circ}C$)\")\n",
    "ax.axhline(0, ls=\"--\", c=\"k\", lw=1)\n",
    "ax.axvline(datetime.datetime(2006, 1, 1), lw=0.5, c=\"k\")\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91350fea-c779-47b0-8fe0-1730c8fa9772",
   "metadata": {},
   "source": [
    "### Compare variance between 1920-1960 and 2160-2100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06895623-6861-4e84-9377-33aee3a6e080",
   "metadata": {},
   "source": [
    "Compute PDFs over early and late period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009a346d-4fd9-4a49-8b0a-0c8c1e788363",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Niño 3.4 over early and late periods\n",
    "nino34_anom_early = nino34_anom_long.sel(time=slice(\"1920\", \"1960\"))\n",
    "nino34_anom_late = nino34_anom_long.sel(time=slice(\"2060\", \"2100\"))\n",
    "\n",
    "## compute PDFs (normalized histograms)\n",
    "pdf_early, edges_early = get_empirical_pdf(nino34_anom_early)\n",
    "pdf_late, edges_late = get_empirical_pdf(nino34_anom_late)\n",
    "\n",
    "## compute PDFs on detrended data\n",
    "# helper function to detrend\n",
    "detrend_fn = lambda x: x - get_trend(x.mean(\"member\"))\n",
    "\n",
    "# specify bin edges for the histograms\n",
    "bin_edges = np.arange(-4 - 0.875, 4 + 1.25, 0.75)\n",
    "\n",
    "# compute the PDFs\n",
    "pdf_early_, edges_early_ = get_empirical_pdf(\n",
    "    detrend_fn(nino34_anom_early), bin_edges=bin_edges\n",
    ")\n",
    "pdf_late_, edges_late_ = get_empirical_pdf(\n",
    "    detrend_fn(nino34_anom_late), bin_edges=bin_edges\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fce35aa-6044-4622-baea-4b0073a705e6",
   "metadata": {},
   "source": [
    "Plot result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecf5283-dd5f-40f6-9366-2629436736b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Plot result\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 3))\n",
    "\n",
    "## plot histogram\n",
    "axs[0].stairs(values=pdf_early, edges=edges_early, label=\"1920-1960\")\n",
    "axs[0].stairs(values=pdf_late, edges=edges_late, label=\"2060-2100\")\n",
    "\n",
    "## label\n",
    "axs[0].set_xlabel(r\"$^{\\circ}C$ anomaly\")\n",
    "axs[0].set_ylabel(\"Probability\")\n",
    "\n",
    "axs[0].legend()\n",
    "axs[0].set_title(\"Niño 3.4 PDFs\")\n",
    "\n",
    "\n",
    "#### next, plot centered histograms\n",
    "axs[1].stairs(values=pdf_early_, edges=edges_early_, label=\"1920-1960\")\n",
    "axs[1].stairs(values=pdf_late_, edges=edges_late_, label=\"2060-2100\")\n",
    "\n",
    "## make sure y-axis is the same across plots and remove y-ticks from the RHS panel\n",
    "axs[0].set_ylim(axs[1].get_ylim())\n",
    "axs[1].set_yticks([])\n",
    "\n",
    "## label\n",
    "axs[1].set_xlabel(r\"$^{\\circ}C$ anomaly\")\n",
    "axs[1].set_title(\"Niño 3.4 PDFs (detrended data)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1834dae-73ae-4a3c-ba36-81c3581dab18",
   "metadata": {},
   "source": [
    "### Change in autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8c9ae5-e149-4b84-b881-cf143ff4d475",
   "metadata": {},
   "source": [
    "Estimate autocorrelation in early & late periods, and compute the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abc457e-3bec-49dd-b8ef-60aa02bdd63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify lags for autocorrelation\n",
    "lags = np.arange(1, 19)\n",
    "\n",
    "## compute autocorrelations and difference\n",
    "autocorr_early = get_autocorr_by_month(detrend_fn(nino34_anom_early), lags=lags)\n",
    "autocorr_late = get_autocorr_by_month(detrend_fn(nino34_anom_late), lags=lags)\n",
    "autocorr_diff = autocorr_late - autocorr_early"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c4da68-2023-422c-ad2c-895f1915dcda",
   "metadata": {},
   "source": [
    "Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b8146c-9bd7-4924-a1c2-a69fcafd5474",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot autocorelation for early time series\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "## plot data\n",
    "plot_data = ax.pcolormesh(\n",
    "    autocorr_early.lag,\n",
    "    autocorr_early.month,\n",
    "    autocorr_early,\n",
    "    cmap=\"cmo.balance\",\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    ")\n",
    "\n",
    "## colorbar\n",
    "cb = fig.colorbar(plot_data, label=\"corr. coef.\", ticks=[-1, 0, 1])\n",
    "\n",
    "## label\n",
    "ax.set_ylabel(\"Start month\")\n",
    "ax.set_xlabel(\"Lag (months)\")\n",
    "ax.set_xticks([0, 6, 12, 18])\n",
    "ax.set_yticks([2, 7, 12], labels=[\"Feb\", \"Jul\", \"Dec\"])\n",
    "ax.set_title(\"Niño 3.4 autocorrelation (1920-1940)\")\n",
    "\n",
    "## swap direction of y-axis\n",
    "ax.set_ylim(ax.get_ylim()[::-1])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "## plot difference (late minus early)\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "## plot data\n",
    "plot_data = ax.pcolormesh(\n",
    "    autocorr_diff.lag,\n",
    "    autocorr_diff.month,\n",
    "    autocorr_diff,\n",
    "    cmap=\"cmo.balance\",\n",
    "    vmin=-0.3,\n",
    "    vmax=0.3,\n",
    ")\n",
    "\n",
    "## colorbar\n",
    "cb = fig.colorbar(plot_data, label=\"corr. coef.\", ticks=[-1, 0, 1])\n",
    "\n",
    "## label\n",
    "ax.set_ylabel(\"Start month\")\n",
    "ax.set_xlabel(\"Lag (months)\")\n",
    "ax.set_xticks([0, 6, 12, 18])\n",
    "ax.set_yticks([2, 7, 12], labels=[\"Feb\", \"Jul\", \"Dec\"])\n",
    "ax.set_title(\"Change in autocorr. (2060-2100 minus 1920-1960)\")\n",
    "\n",
    "## swap direction of y-axis\n",
    "ax.set_ylim(ax.get_ylim()[::-1])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
