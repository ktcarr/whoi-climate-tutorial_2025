{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0294a2d1-ac11-44c6-8d4c-f09066b4ce27",
   "metadata": {},
   "source": [
    "# Woods hole example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ea7642-50d7-4e56-b847-f9d0af63f9b5",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daaf53e-f603-40ac-b7a6-968a9eef13dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import cmocean\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.ticker as mticker\n",
    "import scipy.signal\n",
    "import copy\n",
    "import dask.distributed\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "## (optional) remove gridlines from plots\n",
    "sns.set(rc={\"axes.facecolor\": \"white\", \"axes.grid\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de6686d-1f50-4cd2-99e3-ec18c930e6c0",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ad8ace-6902-4bb7-8b3d-ea4c19d33506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_setup(fig, projection, lon_range, lat_range, xticks=None, yticks=None):\n",
    "    \"\"\"Add a subplot to the figure with the given map projection\n",
    "    and lon/lat range. Returns an Axes object.\"\"\"\n",
    "\n",
    "    ## increase resolution for projection\n",
    "    ## (otherwise lines plotted on surface won't follow curved trajectories)\n",
    "    projection.threshold /= 1000\n",
    "\n",
    "    ## Create subplot with given projection\n",
    "    ax = fig.add_subplot(projection=projection)\n",
    "\n",
    "    ## Subset to given region\n",
    "    extent = [*lon_range, *lat_range]\n",
    "    ax.set_extent(extent, crs=ccrs.PlateCarree())\n",
    "\n",
    "    ## draw coastlines\n",
    "    ax.coastlines(linewidths=0.5)\n",
    "\n",
    "    ## add tick labels\n",
    "    if xticks is not None:\n",
    "\n",
    "        ## add lon/lat labels\n",
    "        gl = ax.gridlines(\n",
    "            draw_labels=True,\n",
    "            linestyle=\"-\",\n",
    "            alpha=0.1,\n",
    "            linewidth=0.5,\n",
    "            color=\"k\",\n",
    "            zorder=1.05,\n",
    "        )\n",
    "\n",
    "        ## specify which axes to label\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "\n",
    "        ## specify ticks\n",
    "        gl.ylocator = mticker.FixedLocator(yticks)\n",
    "        gl.xlocator = mticker.FixedLocator(xticks)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_box_outline(ax, lon_range, lat_range, c=\"k\"):\n",
    "    \"\"\"\n",
    "    Plot box outlining the specifed lon/lat range on given\n",
    "    ax object.\n",
    "    \"\"\"\n",
    "\n",
    "    ## get width and height\n",
    "    height = lat_range[1] - lat_range[0]\n",
    "    width = lon_range[1] - lon_range[0]\n",
    "\n",
    "    ## add rectangle to plot\n",
    "    ax.add_patch(\n",
    "        mpatches.Rectangle(\n",
    "            xy=[lon_range[0], lat_range[0]],\n",
    "            height=height,\n",
    "            width=width,\n",
    "            transform=ccrs.PlateCarree(),\n",
    "            facecolor=\"none\",\n",
    "            edgecolor=c,\n",
    "            linewidth=1,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_setup_woodshole(fig):\n",
    "    \"\"\"Plot zoomed-in view of Woods Hole\"\"\"\n",
    "\n",
    "    ## adjust figure size\n",
    "    fig.set_size_inches(5, 3)\n",
    "\n",
    "    ## set map projection to orthographic\n",
    "    proj = ccrs.Orthographic(central_longitude=-67.5, central_latitude=40)\n",
    "\n",
    "    ## Get ax object based on generic plotting function\n",
    "    ax = plot_setup(\n",
    "        fig,\n",
    "        proj,\n",
    "        lon_range=[-80, -60],\n",
    "        lat_range=[35, 45],\n",
    "        xticks=[-80, -70, -60],\n",
    "        yticks=[35, 40, 45],\n",
    "    )\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def make_cb_range(amp, delta):\n",
    "    \"\"\"Make colorbar_range for cmo.balance\n",
    "    Args:\n",
    "        - 'amp': amplitude of maximum value for colorbar\n",
    "        - 'delta': increment for colorbar\n",
    "    \"\"\"\n",
    "    return np.concatenate(\n",
    "        [np.arange(-amp, 0, delta), np.arange(delta, amp + delta, delta)]\n",
    "    )\n",
    "\n",
    "\n",
    "def get_empirical_pdf(x, bin_edges=None):\n",
    "    \"\"\"\n",
    "    Estimate the \"empirical\" probability distribution function for the data x.\n",
    "    In this case the result is a normalized histogram,\n",
    "    Normalized means that integrating over the histogram yields 1.\n",
    "    Returns the PDF (normalized histogram) and edges of the histogram bins\n",
    "    \"\"\"\n",
    "\n",
    "    ## compute histogram\n",
    "    if bin_edges is None:\n",
    "        hist, bin_edges = np.histogram(x)\n",
    "\n",
    "    else:\n",
    "        hist, _ = np.histogram(x, bins=bin_edges)\n",
    "\n",
    "    ## normalize to a probability distribution (PDF)\n",
    "    bin_width = bin_edges[1:] - bin_edges[:-1]\n",
    "    pdf = hist / (hist * bin_width).sum()\n",
    "\n",
    "    return pdf, bin_edges\n",
    "\n",
    "\n",
    "def get_autocorr(x, lags, month=None):\n",
    "    \"\"\"Get autocorrelation for data for multiple lags\"\"\"\n",
    "\n",
    "    ## put autocorrelation for each lag in array\n",
    "    autocorr = [get_autocorr_helper(x, lag, month) for lag in lags]\n",
    "\n",
    "    ## convert to xr.DataArray\n",
    "    autocorr = xr.concat(autocorr, dim=pd.Index(lags, name=\"lag\"))\n",
    "    # return xr.DataArray(autocorr, coords={\"lag\": lags})\n",
    "    return autocorr\n",
    "\n",
    "\n",
    "def get_autocorr_helper(x, lag, month=None):\n",
    "    \"\"\"Get autocorrelation of data for single lag\"\"\"\n",
    "\n",
    "    ## return 1 for a lag of 0\n",
    "    if lag == 0:\n",
    "        return xr.ones_like(x.isel(time=0))\n",
    "\n",
    "    ## get lagged version of x\n",
    "    elif lag > 0:\n",
    "        x_lagged = x.isel(time=slice(lag, None))\n",
    "        x_ = x.isel(time=slice(None, -lag))\n",
    "\n",
    "    else:\n",
    "        x_lagged = x.isel(time=slice(None, lag))\n",
    "        x_ = x.isel(time=slice(-lag, None))\n",
    "\n",
    "    ## re-label time axis so arrays match\n",
    "    x_lagged[\"time\"] = x_.time\n",
    "\n",
    "    ## subset for data from given month\n",
    "    if month is not None:\n",
    "        is_month = x_.time.dt.month == month\n",
    "        x_ = x_.isel(time=is_month)\n",
    "        x_lagged = x_lagged.isel(time=is_month)\n",
    "\n",
    "    return xr.corr(x_, x_lagged, dim=\"time\")\n",
    "\n",
    "\n",
    "def load_simulation(varname, member_id, simulation_type, preprocess_func=None):\n",
    "    \"\"\"\n",
    "    Load dataset for single simulation, for single variable.\n",
    "    Arguments:\n",
    "        - varname: name of variable to load, one of {\"SST\",\"PSL\"}\n",
    "        - member_id: ID of ensemble member to load, an integer in the range [1,10]\n",
    "        - simulation_type: one of {\"hist\", \"rcp85\"}\n",
    "        - preprocess func: optional preprocessing function to apply to the simulation\n",
    "    Returns:\n",
    "        - xarray dataarray with given data\n",
    "    \"\"\"\n",
    "\n",
    "    ## Filepath to the CESM LENS dataset\n",
    "    lens_fp = pathlib.Path(\"cmip6/data/cmip6/CMIP/NCAR/LENS\")\n",
    "\n",
    "    #### 1. get filepath to data\n",
    "    data_fp = SERVER_FP / lens_fp / pathlib.Path(varname)\n",
    "\n",
    "    #### 2. get naming pattern for files to open\n",
    "    if simulation_type == \"hist\":\n",
    "        file_pattern = f\"*20TRC*.{member_id:03d}.*.nc\"\n",
    "\n",
    "    elif simulation_type == \"rcp85\":\n",
    "        file_pattern = f\"*RCP85*.{member_id:03d}.*.nc\"\n",
    "\n",
    "    else:\n",
    "        print(\"Not a valid simulation type\")\n",
    "\n",
    "    #### 3. open the relevant datasets, applying preprocessing function\n",
    "    fp = list(data_fp.glob(file_pattern))[0]\n",
    "    data = preprocess_func(xr.open_dataset(fp, decode_timedelta=True))\n",
    "\n",
    "    return data[varname].squeeze(drop=True).compute()\n",
    "\n",
    "\n",
    "def trim(data, lon_range=[280, 300], lat_range=[35, 45]):\n",
    "    \"\"\"select part of data in given longitude/latitude range\"\"\"\n",
    "\n",
    "    ## check if data is on the \"T\"-grid\n",
    "    on_Tgrid = \"TLONG\" in data.coords\n",
    "\n",
    "    ## handle trimming for T-grid\n",
    "    if on_Tgrid:\n",
    "\n",
    "        ## helper function to check if 'x' is in 'x_range'\n",
    "        isin_range = lambda x, x_range: (x_range[0] <= x) & (x <= x_range[1])\n",
    "\n",
    "        ## get mask for data in given lon/lat range\n",
    "        in_lon_range = isin_range(data[\"TLONG\"], lon_range)\n",
    "        in_lat_range = isin_range(data[\"TLAT\"], lat_range)\n",
    "        in_lonlat_range = in_lon_range & in_lat_range\n",
    "\n",
    "        ## load to memory\n",
    "        in_lonlat_range.load()\n",
    "\n",
    "        ## Retain all points with at least one valid grid cell\n",
    "        x_idx = in_lonlat_range.any(\"nlat\")\n",
    "        y_idx = in_lonlat_range.any(\"nlon\")\n",
    "\n",
    "        ## select given points\n",
    "        return data.isel(nlon=x_idx, nlat=y_idx)\n",
    "\n",
    "    else:\n",
    "        return data.sel(lon=slice(*lon_range), lat=slice(*lat_range))\n",
    "\n",
    "\n",
    "def load_ensemble_helper(varname, simulation_type, preprocess_func=None):\n",
    "    \"\"\"\n",
    "    Load all ensemble members for given simulation type and variable.\n",
    "    Arguments:\n",
    "        - varname: name of variable to load, one of {\"SST\",\"PSL\"}\n",
    "        - simulation_type: one of {\"hist\", \"rcp85\"}\n",
    "        - preprocess func: optional preprocessing function to apply to the simulation\n",
    "    Returns:\n",
    "        - xarray dataarray with given data and 'ensemble' dimension\n",
    "    \"\"\"\n",
    "\n",
    "    ## put arguments in dictionary\n",
    "    kwargs = dict(\n",
    "        varname=varname,\n",
    "        simulation_type=simulation_type,\n",
    "        preprocess_func=preprocess_func,\n",
    "    )\n",
    "\n",
    "    ## put results in list\n",
    "    data = [load_simulation(member_id=i, **kwargs) for i in tqdm.tqdm(np.arange(1, 36))]\n",
    "\n",
    "    ## concatenate data along the \"ensemble\" dimension\n",
    "    ensemble_dim = pd.Index(np.arange(1, 36), name=\"member\")\n",
    "    data = xr.concat(data, dim=ensemble_dim)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_ensemble(varname, simulation_type, preprocess_func=None, save_fp=None):\n",
    "    \"\"\"\n",
    "    Load all ensemble members for given simulation type and variable.\n",
    "    (Checks if data exists locally first).\n",
    "    Arguments:\n",
    "        - varname: name of variable to load, one of {\"SST\",\"PSL\"}\n",
    "        - simulation_type: one of {\"hist\", \"rcp85\"}\n",
    "        - preprocess func: optional preprocessing function to apply to the simulation\n",
    "        - save_fp: pathlib.Path object (save the result here if specified)\n",
    "    Returns:\n",
    "        - xarray dataarray with given data and 'ensemble' dimension\n",
    "    \"\"\"\n",
    "\n",
    "    ## put arguments in dictionary\n",
    "    kwargs = dict(\n",
    "        varname=varname,\n",
    "        simulation_type=simulation_type,\n",
    "        preprocess_func=preprocess_func,\n",
    "    )\n",
    "\n",
    "    ## load pre-computed data if it exists\n",
    "    if save_fp is not None:\n",
    "\n",
    "        ## path to file\n",
    "        save_fp = save_fp / f\"{varname}_{simulation_type}.nc\"\n",
    "\n",
    "        ## check if file exists:\n",
    "        if save_fp.is_file():\n",
    "            data = xr.open_dataarray(save_fp)\n",
    "\n",
    "        else:\n",
    "\n",
    "            ## load the data and save to file for next time\n",
    "            data = load_ensemble_helper(**kwargs)\n",
    "\n",
    "            print(\"saving to file\")\n",
    "            data.to_netcdf(save_fp)\n",
    "\n",
    "    else:\n",
    "\n",
    "        ## don't load/save the data\n",
    "        data = load_ensemble_helper(**kwargs)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def preprocess(data):\n",
    "    \"\"\"\n",
    "    Preprocessing steps:\n",
    "        1. trim to period 1920 - 2081\n",
    "        2. trim in lon/lat space\n",
    "        3. convert time dimension from cftime to datetime\n",
    "    \"\"\"\n",
    "\n",
    "    ## trim in time\n",
    "    data_ = data.sel(time=slice(\"1920-02\", \"2081-01\"))\n",
    "\n",
    "    ## trim in space\n",
    "    data_ = trim(data_)\n",
    "\n",
    "    ## update time dimension\n",
    "    start_year = data_.time.isel(time=0).dt.year.item()\n",
    "    start_month = data_.time.isel(time=0).dt.month.item()\n",
    "    start_date = f\"{start_year}-{start_month}-01\"\n",
    "    data_[\"time\"] = pd.date_range(start=start_date, periods=len(data_.time), freq=\"MS\")\n",
    "\n",
    "    return data_\n",
    "\n",
    "\n",
    "def plot_quantiles(ax, x, label=None, month=None, time_dim=\"time\", **kwargs):\n",
    "    \"\"\"plot .1, .5, and .9 quantiles on given ax object\"\"\"\n",
    "\n",
    "    ## filter for month if specified\n",
    "    if month is not None:\n",
    "        x = x.sel(time=(x.time.dt.month == month))\n",
    "\n",
    "    ## compute quantiles\n",
    "    x_quantiles = x.quantile([0.1, 0.5, 0.9], dim=\"member\")\n",
    "\n",
    "    ## plot median\n",
    "    ax.plot(\n",
    "        x_quantiles[time_dim],\n",
    "        x_quantiles.sel(quantile=0.5),\n",
    "        lw=2,\n",
    "        label=label,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    ## plot upper/lower bounds\n",
    "    for q in [0.1, 0.9]:\n",
    "        ax.plot(\n",
    "            x_quantiles[time_dim],\n",
    "            x_quantiles.sel(quantile=q),\n",
    "            lw=1,\n",
    "            alpha=0.5,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def rolling_fn_helper(x, fn, window_size=15):\n",
    "    \"\"\"Function to get rolling standard deviation ('sigma').\n",
    "    'window_size' is number of timesteps to include in each averaging window\"\"\"\n",
    "\n",
    "    ## get rolling object\n",
    "    rolling_obj = x.rolling({\"time\": window_size}, center=True)\n",
    "\n",
    "    ## apply function\n",
    "    fn_eval = fn(rolling_obj)\n",
    "\n",
    "    ## get half window size\n",
    "    n = int((window_size - 1) / 2)\n",
    "\n",
    "    ## trim to remove NaNs\n",
    "    return fn_eval.isel(time=slice(n, -n))\n",
    "\n",
    "\n",
    "def rolling_fn_bymonth(x, fn, window_size=15):\n",
    "    \"\"\"Apply rolling function to each month separately\"\"\"\n",
    "\n",
    "    ## get rolling function to pass to apply to each month\n",
    "    rolling_fn_ = lambda y: rolling_fn_helper(y, fn, window_size=window_size)\n",
    "\n",
    "    ## evaluate\n",
    "    fn_eval = x.groupby(\"time.month\").map(rolling_fn_)\n",
    "\n",
    "    ## reindex so time is ascending\n",
    "    fn_eval = fn_eval.reindex({\"time\": np.sort(fn_eval.time)})\n",
    "\n",
    "    return fn_eval\n",
    "\n",
    "\n",
    "def rolling_fn(x, fn, window_size=15, by_month=True):\n",
    "    \"\"\"apply rolling function; handle by_month cases (True or False)\"\"\"\n",
    "\n",
    "    ## keyword args\n",
    "    kwargs = dict(x=x, fn=fn, window_size=window_size)\n",
    "\n",
    "    ## handle cases\n",
    "    if by_month:\n",
    "        return rolling_fn_bymonth(**kwargs)\n",
    "\n",
    "    else:\n",
    "        return rolling_fn_helper(**kwargs)\n",
    "\n",
    "\n",
    "def get_rolling_stddev(x, window_size=31, by_month=True):\n",
    "    \"\"\"Function to get rolling standard deviation ('sigma').\"\"\"\n",
    "\n",
    "    ## get sigma function\n",
    "    fn = lambda y: y.std()\n",
    "\n",
    "    return rolling_fn(x, fn=fn, window_size=window_size, by_month=by_month)\n",
    "\n",
    "\n",
    "def get_rolling_mean(x, window_size=31, by_month=True):\n",
    "    \"\"\"Function to get rolling standard deviation ('sigma').\"\"\"\n",
    "\n",
    "    ## get sigma function\n",
    "    fn = lambda y: y.mean()\n",
    "\n",
    "    return rolling_fn(x, fn=fn, window_size=window_size, by_month=by_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333948ce-71b3-45c2-a758-89326cac7d36",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e39c0a-ccb3-476f-9d93-a13338805a88",
   "metadata": {},
   "source": [
    "### Set filepaths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65329af-344f-4b7e-92da-1d12401f1dd1",
   "metadata": {},
   "source": [
    "````{admonition} To-do\n",
    "Update the filepaths ```SERVER_FP``` and ```save_fp``` in the code cell below.\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eb8c3a-dd13-4c17-be12-a52d2e458682",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Path to file server\n",
    "# SERVER_FP = pathlib.Path(\"/vortexfs1/share\")\n",
    "SERVER_FP = pathlib.Path(\"/Volumes\")\n",
    "\n",
    "## Specify folder location for saving trimmed data (\"./\" means current directory)\n",
    "save_fp = pathlib.Path(\"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2174c18-f322-4761-8852-56831c0ad804",
   "metadata": {},
   "source": [
    "### Do the loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146b4707-46e8-40a6-8ac2-76355769fd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data\n",
    "data_hist = load_ensemble(\"SST\", \"hist\", preprocess_func=preprocess, save_fp=save_fp)\n",
    "data_rcp = load_ensemble(\"SST\", \"rcp85\", preprocess_func=preprocess, save_fp=save_fp)\n",
    "\n",
    "## concatenate in time\n",
    "data = xr.concat([data_hist, data_rcp], dim=\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d314c3-21bb-442d-a21e-9c3975c19be9",
   "metadata": {},
   "source": [
    "## Plot a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf7619b-ed04-4c0f-bcc2-66b659ff0a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "## blank canvas\n",
    "fig = plt.figure()\n",
    "\n",
    "## plot background\n",
    "fig, ax = plot_setup_woodshole(fig)\n",
    "\n",
    "\n",
    "## plot the data\n",
    "plot_data = ax.pcolormesh(\n",
    "    data.TLONG,\n",
    "    data.TLAT,\n",
    "    data.isel(member=0, time=0),\n",
    "    cmap=\"cmo.thermal\",\n",
    "    vmax=20,\n",
    "    vmin=5,\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "\n",
    "## make a colorbar\n",
    "cb = fig.colorbar(plot_data, fraction=0.015, pad=0.05, ticks=[5, 12.5, 20])\n",
    "\n",
    "## plot outline of region\n",
    "ax = plot_box_outline(ax, lon_range=[287.5, 293.5], lat_range=[39, 44])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d351eff-fdf0-42ac-ad9f-aaac49259080",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2c49dc-0c82-49d3-9045-1f1cc630f150",
   "metadata": {},
   "source": [
    "### Compute index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99dcfda-c529-43b4-b109-bcd9586dca29",
   "metadata": {},
   "source": [
    "Function to compute Niño 3.4 index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bb35d3-deaa-477b-8d6d-92a4ad2bba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_T_wh(x):\n",
    "    \"\"\"Compute Woods Hole temperature index\"\"\"\n",
    "\n",
    "    ## get subset of data inside the box\n",
    "    data_subset = trim(x, lon_range=[287.5, 293.5], lat_range=[39, 44])\n",
    "\n",
    "    ## compute spatial average\n",
    "    return data_subset.mean([\"nlon\", \"nlat\"])\n",
    "\n",
    "\n",
    "## do the computation here\n",
    "idx = compute_T_wh(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bea78c-1401-438a-853b-624f255ff55a",
   "metadata": {},
   "source": [
    "## Separate forced response from internal variability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650bce34-a919-4095-a9c2-7a263493e7d3",
   "metadata": {},
   "source": [
    "Estimate forced response and internval variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b91a62-1f48-42b1-9de6-7281c6c8e285",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define forced response as ensemble mean\n",
    "idx_forced = idx.mean(\"member\")\n",
    "\n",
    "## internal variability is the residual\n",
    "idx_iv = idx - idx_forced\n",
    "\n",
    "## compute annual means\n",
    "get_ann_mean = lambda x: x.groupby(\"time.year\").mean().sel(year=slice(None, 2080))\n",
    "idx_forced_ann = get_ann_mean(idx_forced)\n",
    "idx_iv_ann = get_ann_mean(idx_iv)\n",
    "idx_ann = get_ann_mean(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c2ed4c-4540-4fdf-be56-5d6b331e2718",
   "metadata": {},
   "source": [
    "Lets plot the annual mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba63602-95a7-4b87-af52-59682de06a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up plot\n",
    "fig, axs = plt.subplots(1, 2, figsize=(7, 2.75), layout=\"constrained\")\n",
    "\n",
    "## plot ensemble median and 10%/90% percentiles\n",
    "plot_quantiles(axs[0], idx_ann, c=\"k\", time_dim=\"year\", label=\"Ensemble median\")\n",
    "\n",
    "## plot forced response (ensemble mean)\n",
    "axs[0].plot(idx_forced_ann.year, idx_forced_ann, c=\"r\", lw=2, label=\"Ensemble mean\")\n",
    "\n",
    "## plot internval variability\n",
    "kwargs = dict(lw=0.5, alpha=0.5, c=\"gray\")\n",
    "for m in idx_iv_ann.member[:10]:\n",
    "    axs[1].plot(idx_iv_ann.year, idx_iv_ann.sel(member=m), **kwargs)\n",
    "\n",
    "\n",
    "## label plots\n",
    "for ax in axs:\n",
    "    ax.set_xticks([1920, 2000, 2080])\n",
    "    ax.set_xlabel(\"Year\")\n",
    "    ax.set_ylabel(r\"$^{\\circ}$C\")\n",
    "\n",
    "axs[0].set_yticks([18, 20, 22])\n",
    "axs[1].set_yticks([-1, 0, 1])\n",
    "axs[0].set_title(\"Forced response\")\n",
    "axs[1].set_title(\"Internal variability (10/35 members)\")\n",
    "axs[1].axhline(0, ls=\"--\", c=\"k\", zorder=0.5)\n",
    "axs[1].yaxis.tick_right()\n",
    "axs[1].yaxis.set_label_position(\"right\")\n",
    "axs[0].legend(prop=dict(size=8))\n",
    "\n",
    "## save fig\n",
    "fig.savefig(\"figs/forced-response.svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2445d40-5dc2-41ea-be4f-a1ed8d4cfb08",
   "metadata": {},
   "source": [
    "## Compare warming rates in Mar and Sep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e903f9bd-1bd1-4e85-a501-8ccde94b7dcb",
   "metadata": {},
   "source": [
    "Compute rolling mean temperature for March and September"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91868ff9-783a-4454-b400-63b8b512bdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to select month\n",
    "sel_month = lambda x, month: x.sel(time=(x.time.dt.month == month))\n",
    "\n",
    "## function to normalize by first 10 timesteps\n",
    "normalize = lambda x: x - x.isel(time=slice(None, 10)).mean([\"member\", \"time\"])\n",
    "\n",
    "## get smoothed version of index\n",
    "idx_smooth = get_rolling_mean(idx, by_month=True, window_size=9)\n",
    "\n",
    "## compute values for Mar/\n",
    "idx_mar_norm = normalize(sel_month(idx_smooth, 3))\n",
    "idx_sep_norm = normalize(sel_month(idx_smooth, 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d9f207-2985-4048-b371-a13a4852175e",
   "metadata": {},
   "source": [
    "Plot forced response for Mar/Sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c445fa55-ceb7-41ec-b21b-158fefd53945",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get colors for plot\n",
    "colors = sns.color_palette()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3.5, 2.75), layout=\"constrained\")\n",
    "\n",
    "## plot data\n",
    "plot_quantiles(ax, idx_mar_norm, c=colors[0], label=\"Mar\")\n",
    "plot_quantiles(ax, idx_sep_norm, c=colors[1], label=\"Sep\")\n",
    "\n",
    "## label\n",
    "ax.legend(prop=dict(size=8))\n",
    "ax.set_ylabel(r\"$\\Delta T$ ($^{\\circ}$C)\")\n",
    "ax.set_xticks([\"1920\", \"2000\", \"2080\"])\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
    "\n",
    "## save to file\n",
    "fig.savefig(\"figs/forced-response_by-seasonal.svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b09e6ad-b368-4369-8cb0-838ac205b19d",
   "metadata": {},
   "source": [
    "Compute temperature change over two pairs of periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f699497-e5e6-4716-a8b8-16d65e4b2a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta_T_pdf(T, t0, t1, bin_edges):\n",
    "    \"\"\"function to compute PDFs of temperature difference between two periods\"\"\"\n",
    "\n",
    "    ## get delta T\n",
    "    delta_T = T.sel(time=t1).squeeze() - T.sel(time=t0).squeeze()\n",
    "\n",
    "    ## create PDF\n",
    "    pdf, _ = get_empirical_pdf(delta_T, bin_edges)\n",
    "\n",
    "    return pdf\n",
    "\n",
    "\n",
    "## specify params for PDF\n",
    "kwargs0 = dict(t0=\"1924\", t1=\"2000\", bin_edges=np.arange(-0.3, 1.9, 0.15))\n",
    "kwargs1 = dict(t0=\"2000\", t1=\"2076\", bin_edges=np.arange(2, 4.5, 0.2))\n",
    "\n",
    "## compute PDFs for each period\n",
    "pdf_mar_0 = get_delta_T_pdf(idx_mar_norm, **kwargs0)\n",
    "pdf_sep_0 = get_delta_T_pdf(idx_sep_norm, **kwargs0)\n",
    "pdf_mar_1 = get_delta_T_pdf(idx_mar_norm, **kwargs1)\n",
    "pdf_sep_1 = get_delta_T_pdf(idx_sep_norm, **kwargs1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811623fb-7bfd-4d41-8bbc-0ff82ed330f0",
   "metadata": {},
   "source": [
    "Plot result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9371f7-d29b-47b7-b1de-b6207bfbfb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up plot\n",
    "fig, axs = plt.subplots(1, 2, figsize=(5, 2.75), layout=\"constrained\")\n",
    "\n",
    "## plot style for march\n",
    "mar_kwargs = dict(fill=True, alpha=0.3, label=\"Mar\")\n",
    "sep_kwargs = dict(lw=1.5, label=\"Sep\")\n",
    "\n",
    "## plot temperature change for first period\n",
    "axs[0].stairs(pdf_mar_0, edges=kwargs0[\"bin_edges\"], **mar_kwargs)\n",
    "axs[0].stairs(pdf_sep_0, edges=kwargs0[\"bin_edges\"], **sep_kwargs)\n",
    "\n",
    "## plot for second period\n",
    "axs[1].stairs(pdf_mar_1, edges=kwargs1[\"bin_edges\"], **mar_kwargs)\n",
    "axs[1].stairs(pdf_sep_1, edges=kwargs1[\"bin_edges\"], **sep_kwargs)\n",
    "\n",
    "## set axis limits\n",
    "axs[0].set_xlim([-0.75, 2.25])\n",
    "axs[1].set_xlim([1.5, 4.5])\n",
    "for ax in axs:\n",
    "    ax.set_ylim([0, 3])\n",
    "\n",
    "## label\n",
    "axs[0].legend(prop=dict(size=8))\n",
    "axs[0].set_title(f\"{kwargs0['t0']}-{kwargs0['t1']}\")\n",
    "axs[1].set_title(f\"{kwargs1['t0']}-{kwargs1['t1']}\")\n",
    "axs[0].set_xticks([-0.5, 0.5, 1.5])\n",
    "axs[1].set_xticks([2, 3, 4])\n",
    "axs[0].set_yticks([0, 1.5, 3])\n",
    "axs[1].set_yticks([])\n",
    "axs[0].set_ylabel(\"Prob. density\")\n",
    "for ax in axs:\n",
    "    ax.set_xlabel(r\"$\\Delta T$ ($^{\\circ}$C)\")\n",
    "\n",
    "## save to file\n",
    "fig.savefig(\"figs/histograms.svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f62f27-5356-440d-8241-044e82dd47a8",
   "metadata": {},
   "source": [
    "## Look at change in standard deviation (spatial pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca482d3-b0e2-4173-83d5-5ef5d87d4b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get internval variability signal\n",
    "data_iv = data - data.mean(\"member\")\n",
    "\n",
    "## compute standard dev over first/last 30 years of simulation\n",
    "std_init = data_iv.isel(time=slice(None, 360)).std([\"time\", \"member\"], skipna=False)\n",
    "std_end = data_iv.isel(time=slice(-360, None)).std([\"time\", \"member\"], skipna=False)\n",
    "\n",
    "## get percentage change\n",
    "std_pct_change = 100 * (std_end - std_init) / std_init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6107117-45ca-4ac3-b583-45e88e7af2a8",
   "metadata": {},
   "source": [
    "### Plot initial standard deviation result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14e829b-1e2b-4258-87ba-c3126415c37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## blank canvas\n",
    "fig = plt.figure()\n",
    "\n",
    "## plot background\n",
    "fig, ax = plot_setup_woodshole(fig)\n",
    "\n",
    "\n",
    "## plot the data\n",
    "plot_data = ax.pcolormesh(\n",
    "    std_init.TLONG,\n",
    "    std_init.TLAT,\n",
    "    std_init,\n",
    "    cmap=\"cmo.amp\",\n",
    "    vmax=1,\n",
    "    vmin=0.3,\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "\n",
    "## make a colorbar\n",
    "cb = fig.colorbar(\n",
    "    plot_data,\n",
    "    fraction=0.015,\n",
    "    pad=0.05,\n",
    "    ticks=[0.3, 1],\n",
    "    label=r\"Std. dev. ($^{\\circ}$C)\",\n",
    ")\n",
    "\n",
    "## plot outline of region\n",
    "ax = plot_box_outline(ax, lon_range=[287.5, 293.5], lat_range=[39, 44])\n",
    "\n",
    "## Label\n",
    "ax.set_title(\"Standard dev. of SST (1920-1950)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c14e81-8d7f-42dc-901d-4875026ce46c",
   "metadata": {},
   "source": [
    "### Plot % change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5c4912-f937-4348-b509-c88a044766bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## blank canvas\n",
    "fig = plt.figure(layout=\"constrained\")\n",
    "\n",
    "## plot background\n",
    "fig, ax = plot_setup_woodshole(fig)\n",
    "\n",
    "\n",
    "## plot the data\n",
    "plot_data = ax.pcolormesh(\n",
    "    std_init.TLONG,\n",
    "    std_init.TLAT,\n",
    "    std_pct_change,\n",
    "    cmap=\"cmo.balance\",\n",
    "    vmax=40,\n",
    "    vmin=-40,\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "\n",
    "## make a colorbar\n",
    "cb = fig.colorbar(\n",
    "    plot_data, fraction=0.015, pad=0.05, ticks=[-40, 0, 40], label=\"% change\"\n",
    ")\n",
    "\n",
    "## plot outline of region\n",
    "ax = plot_box_outline(ax, lon_range=[287.5, 293.5], lat_range=[39, 44])\n",
    "\n",
    "## label\n",
    "ax.set_title(\"Change in standard dev. of SST (1935-2065)\")\n",
    "\n",
    "## save to  file\n",
    "fig.savefig(\"figs/sigma-change.svg\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
