{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0294a2d1-ac11-44c6-8d4c-f09066b4ce27",
   "metadata": {},
   "source": [
    "# ENSO example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ea7642-50d7-4e56-b847-f9d0af63f9b5",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daaf53e-f603-40ac-b7a6-968a9eef13dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import cmocean\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.ticker as mticker\n",
    "import scipy.signal\n",
    "import copy\n",
    "import dask.distributed\n",
    "import pandas as pd\n",
    "\n",
    "## (optional) remove gridlines from plots\n",
    "sns.set(rc={\"axes.facecolor\": \"white\", \"axes.grid\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de6686d-1f50-4cd2-99e3-ec18c930e6c0",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ad8ace-6902-4bb7-8b3d-ea4c19d33506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_setup(fig, projection, lon_range, lat_range, xticks=None, yticks=None):\n",
    "    \"\"\"Add a subplot to the figure with the given map projection\n",
    "    and lon/lat range. Returns an Axes object.\"\"\"\n",
    "\n",
    "    ## increase resolution for projection\n",
    "    ## (otherwise lines plotted on surface won't follow curved trajectories)\n",
    "    projection.threshold /= 1000\n",
    "\n",
    "    ## Create subplot with given projection\n",
    "    ax = fig.add_subplot(projection=projection)\n",
    "\n",
    "    ## Subset to given region\n",
    "    extent = [*lon_range, *lat_range]\n",
    "    ax.set_extent(extent, crs=ccrs.PlateCarree())\n",
    "\n",
    "    ## draw coastlines\n",
    "    ax.coastlines(linewidths=0.5)\n",
    "\n",
    "    ## add tick labels\n",
    "    if xticks is not None:\n",
    "\n",
    "        ## add lon/lat labels\n",
    "        gl = ax.gridlines(\n",
    "            draw_labels=True,\n",
    "            linestyle=\"-\",\n",
    "            alpha=0.1,\n",
    "            linewidth=0.5,\n",
    "            color=\"k\",\n",
    "            zorder=1.05,\n",
    "        )\n",
    "\n",
    "        ## specify which axes to label\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "\n",
    "        ## specify ticks\n",
    "        gl.ylocator = mticker.FixedLocator(yticks)\n",
    "        gl.xlocator = mticker.FixedLocator(xticks)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_box_outline(ax, lon_range, lat_range, c=\"k\"):\n",
    "    \"\"\"\n",
    "    Plot box outlining the specifed lon/lat range on given\n",
    "    ax object.\n",
    "    \"\"\"\n",
    "\n",
    "    ## get width and height\n",
    "    height = lat_range[1] - lat_range[0]\n",
    "    width = lon_range[1] - lon_range[0]\n",
    "\n",
    "    ## add rectangle to plot\n",
    "    ax.add_patch(\n",
    "        mpatches.Rectangle(\n",
    "            xy=[lon_range[0], lat_range[0]],\n",
    "            height=height,\n",
    "            width=width,\n",
    "            transform=ccrs.PlateCarree(),\n",
    "            facecolor=\"none\",\n",
    "            edgecolor=c,\n",
    "            linewidth=1,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_correlation(plot_setup_fn, corr, x, y):\n",
    "    \"\"\"\n",
    "    Make spatial plot of correlation, using the specified\n",
    "    plot setup function and pre-computed correlation.\n",
    "    Args:\n",
    "        - plot_setup_fn: function that returns a fig, ax object\n",
    "        - corr: xarray with spatial correlation\n",
    "        - x, y: lon/lat points for plotting\n",
    "    \"\"\"\n",
    "\n",
    "    ## blank canvas to plot on\n",
    "    fig = plt.figure()\n",
    "\n",
    "    ## draw background map of Atlantic\n",
    "    fig, ax = plot_setup_fn(fig)\n",
    "\n",
    "    ## plot the data\n",
    "    plot_data = ax.contourf(\n",
    "        x,\n",
    "        y,\n",
    "        corr,\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        levels=make_cb_range(1, 0.1),\n",
    "        extend=\"both\",\n",
    "        cmap=\"cmo.balance\",\n",
    "    )\n",
    "\n",
    "    ## create colorbath\n",
    "    colorbar = fig.colorbar(plot_data, label=\"Corr.\", ticks=[-1, -0.5, 0, 0.5, 1])\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def plot_setup_pacific(fig):\n",
    "    \"\"\"Plot Atlantic region\"\"\"\n",
    "\n",
    "    ## adjust figure size\n",
    "    fig.set_size_inches(5, 3)\n",
    "\n",
    "    ## specify map projection\n",
    "    proj = ccrs.PlateCarree(central_longitude=-160)\n",
    "\n",
    "    ## get ax object\n",
    "    ax = plot_setup(\n",
    "        fig,\n",
    "        proj,\n",
    "        lon_range=[100, 300],\n",
    "        lat_range=[-30, 30],\n",
    "        xticks=[150, -160, -110],\n",
    "        yticks=[-20, 0, 20],\n",
    "    )\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def make_cb_range(amp, delta):\n",
    "    \"\"\"Make colorbar_range for cmo.balance\n",
    "    Args:\n",
    "        - 'amp': amplitude of maximum value for colorbar\n",
    "        - 'delta': increment for colorbar\n",
    "    \"\"\"\n",
    "    return np.concatenate(\n",
    "        [np.arange(-amp, 0, delta), np.arange(delta, amp + delta, delta)]\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_setup_timeseries():\n",
    "    \"\"\"\n",
    "    Create fig, ax objects and label time axis\n",
    "    \"\"\"\n",
    "\n",
    "    ## set up plot\n",
    "    fig, ax = plt.subplots(figsize=(4, 3))\n",
    "\n",
    "    ## restrict to last 50 years and label axes\n",
    "    ax.set_xlim([datetime.date(1970, 1, 1), None])\n",
    "\n",
    "    ax.set_xticks(\n",
    "        [\n",
    "            datetime.date(1979, 1, 1),\n",
    "            datetime.date(2000, 6, 30),\n",
    "            datetime.date(2021, 12, 31),\n",
    "        ]\n",
    "    )\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def plot_seasonal_cycle(mean, std):\n",
    "    \"\"\"\n",
    "    Plot the seasonal cycle (monthly mean ± 1 standard dev.)\n",
    "    \"\"\"\n",
    "\n",
    "    ## plot\n",
    "    fig, ax = plt.subplots(figsize=(4, 3))\n",
    "\n",
    "    ## mean\n",
    "    ax.plot(np.arange(1, 13), mean, c=\"k\", label=r\"$\\mu$\")\n",
    "\n",
    "    ## mean ± std\n",
    "    ax.plot(np.arange(1, 13), mean + std, c=\"k\", lw=0.5, label=r\"$\\mu \\pm \\sigma$\")\n",
    "    ax.plot(np.arange(1, 13), mean - std, c=\"k\", lw=0.5)\n",
    "\n",
    "    ## label\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def spatial_avg(data):\n",
    "    \"\"\"function to compute spatial average of data on grid with constant\n",
    "    longitude/latitude spacing.\"\"\"\n",
    "\n",
    "    ## first, compute cosine of latitude (after converting degrees to radians)\n",
    "    latitude_radians = np.deg2rad(data.latitude)\n",
    "    cos_lat = np.cos(latitude_radians)\n",
    "\n",
    "    ## get weighted average using xarray\n",
    "    avg = data.weighted(weights=cos_lat).mean([\"longitude\", \"latitude\"])\n",
    "\n",
    "    return avg\n",
    "\n",
    "\n",
    "def get_trend_coefs(data, dim=\"time\", deg=1):\n",
    "    \"\"\"get coefficients for trend\"\"\"\n",
    "    return data.polyfit(dim=dim, deg=deg)[\"polyfit_coefficients\"]\n",
    "\n",
    "\n",
    "def get_trend(data, dim=\"time\", deg=1):\n",
    "    \"\"\"\n",
    "    Get trend for an xr.dataarray along specified dimension,\n",
    "    by fitting polynomial of degree 'deg'.\n",
    "    \"\"\"\n",
    "\n",
    "    ## Get coefficients for best fit\n",
    "    polyfit_coefs = get_trend_coefs(data=data, dim=dim, deg=deg)\n",
    "\n",
    "    ## Get best fit line (linear trend in this case)\n",
    "    trend = xr.polyval(data[dim], polyfit_coefs)\n",
    "\n",
    "    return trend\n",
    "\n",
    "\n",
    "def detrend(data, dim=\"time\", deg=1):\n",
    "    \"\"\"\n",
    "    Remove trend of degree 'deg' from data, along dimension 'dim'.\n",
    "    \"\"\"\n",
    "\n",
    "    return data - get_trend(data, dim=dim, deg=deg)\n",
    "\n",
    "\n",
    "def get_empirical_pdf(x, bin_edges=None):\n",
    "    \"\"\"\n",
    "    Estimate the \"empirical\" probability distribution function for the data x.\n",
    "    In this case the result is a normalized histogram,\n",
    "    Normalized means that integrating over the histogram yields 1.\n",
    "    Returns the PDF (normalized histogram) and edges of the histogram bins\n",
    "    \"\"\"\n",
    "\n",
    "    ## compute histogram\n",
    "    if bin_edges is None:\n",
    "        hist, bin_edges = np.histogram(x)\n",
    "\n",
    "    else:\n",
    "        hist, _ = np.histogram(x, bins=bin_edges)\n",
    "\n",
    "    ## normalize to a probability distribution (PDF)\n",
    "    bin_width = bin_edges[1:] - bin_edges[:-1]\n",
    "    pdf = hist / (hist * bin_width).sum()\n",
    "\n",
    "    return pdf, bin_edges\n",
    "\n",
    "\n",
    "def get_gaussian_best_fit(x):\n",
    "    \"\"\"Get gaussian best fit to data, and evaluate\n",
    "    probabilities over the range of the data.\"\"\"\n",
    "\n",
    "    ## get normal distribution best fit\n",
    "    gaussian = scipy.stats.norm(loc=x.mean(), scale=x.std())\n",
    "\n",
    "    ## evaluate over range of data\n",
    "    amp = np.max(np.abs(x.values))\n",
    "    x_eval = np.linspace(-amp, amp)\n",
    "    pdf_eval = gaussian.pdf(x_eval)\n",
    "\n",
    "    return pdf_eval, x_eval\n",
    "\n",
    "\n",
    "def swap_longitude_range(data):\n",
    "    \"\"\"swap longitude range of xr.DataArray from [0,360) to (-180, 180]\"\"\"\n",
    "\n",
    "    ## copy of longitude coordinate to be modified\n",
    "    new_longitude = copy.deepcopy(data.longitude.values)\n",
    "\n",
    "    ## find index where longitude first exceeds 180.\n",
    "    ## (note: np.argmax returns first instance of \"True\" in boolean array)\n",
    "    swap_idx = np.argmax(new_longitude > 180)\n",
    "\n",
    "    ## relabel values >180\n",
    "    new_longitude[swap_idx:] = -360 + new_longitude[swap_idx:]\n",
    "\n",
    "    ## add this coordinate back to the array\n",
    "    data[\"longitude\"] = new_longitude\n",
    "\n",
    "    ## \"roll\" the data to be centered at zero\n",
    "    data = data.roll({\"longitude\": -swap_idx}, roll_coords=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_autocorr_helper(x, lag, month=None):\n",
    "    \"\"\"Get autocorrelation of data for single lag\"\"\"\n",
    "\n",
    "    ## return 1 for a lag of 0\n",
    "    if lag == 0:\n",
    "        return 1.0\n",
    "\n",
    "    ## get lagged version of x\n",
    "    elif lag > 0:\n",
    "        x_lagged = x.isel(time=slice(lag, None))\n",
    "        x_ = x.isel(time=slice(None, -lag))\n",
    "\n",
    "    else:\n",
    "        x_lagged = x.isel(time=slice(None, lag))\n",
    "        x_ = x.isel(time=slice(-lag, None))\n",
    "\n",
    "    ## re-label time axis so arrays match\n",
    "    x_lagged[\"time\"] = x_.time\n",
    "\n",
    "    ## subset for data from given month\n",
    "    if month is not None:\n",
    "        is_month = x_.time.dt.month == month\n",
    "        x_ = x_.isel(time=is_month)\n",
    "        x_lagged = x_lagged.isel(time=is_month)\n",
    "\n",
    "    return get_corr_coef(x_, x_lagged).item()\n",
    "\n",
    "\n",
    "def get_autocorr(x, lags, month=None):\n",
    "    \"\"\"Get autocorrelation for data for multiple lags\"\"\"\n",
    "\n",
    "    ## put autocorrelation for each lag in array\n",
    "    autocorr = [get_autocorr_helper(x, lag, month) for lag in lags]\n",
    "\n",
    "    ## convert to xr.DataArray\n",
    "    return xr.DataArray(autocorr, coords={\"lag\": lags})\n",
    "\n",
    "\n",
    "def get_autocorr_by_month(x, lags):\n",
    "    \"\"\"Get autocorrelation for each month, and stack in array\"\"\"\n",
    "\n",
    "    ## compute autocorrelation for each month\n",
    "    autocorr = [get_autocorr(x, lags, month=m) for m in np.arange(1, 13)]\n",
    "\n",
    "    ## convert to xarray\n",
    "    return xr.concat(autocorr, dim=pd.Index(np.arange(1, 13), name=\"month\"))\n",
    "\n",
    "\n",
    "def load_simulation(varname, member_id, simulation_type, preprocess_func=None):\n",
    "    \"\"\"\n",
    "    Load dataset for single simulation, for single variable.\n",
    "    Arguments:\n",
    "        - varname: name of variable to load, one of {\"SST\",\"PSL\"}\n",
    "        - member_id: ID of ensemble member to load, an integer in the range [1,10]\n",
    "        - simulation_type: one of {\"hist\", \"rcp85\"}\n",
    "        - preprocess func: optional preprocessing function to apply to the simulation\n",
    "    Returns:\n",
    "        - xarray dataarray with given data\n",
    "    \"\"\"\n",
    "\n",
    "    ## Filepath to the CESM LENS dataset\n",
    "    lens_fp = pathlib.Path(\"cmip6/data/cmip6/CMIP/NCAR/LENS\")\n",
    "\n",
    "    #### 1. get filepath to data\n",
    "    data_fp = SERVER_FP / lens_fp / pathlib.Path(varname)\n",
    "\n",
    "    #### 2. get naming pattern for files to open\n",
    "    if simulation_type == \"hist\":\n",
    "        file_pattern = f\"*20TRC*.{member_id:03d}.*.nc\"\n",
    "\n",
    "    elif simulation_type == \"rcp85\":\n",
    "        file_pattern = f\"*RCP85*.{member_id:03d}.*.nc\"\n",
    "\n",
    "    else:\n",
    "        print(\"Not a valid simulation type\")\n",
    "\n",
    "    #### 3. open the relevant datasets, applying preprocessing function\n",
    "    data = xr.open_mfdataset(\n",
    "        paths=data_fp.glob(file_pattern),\n",
    "        preprocess=preprocess_func,\n",
    "        chunks={\"time\": 60},\n",
    "    )\n",
    "\n",
    "    return data[varname].squeeze(drop=True)\n",
    "\n",
    "\n",
    "def trim(data, lon_range=[100, 300], lat_range=[-30, 30]):\n",
    "    \"\"\"select part of data in given longitude/latitude range\"\"\"\n",
    "\n",
    "    ## check if data is on the \"T\"-grid\n",
    "    on_Tgrid = \"TLONG\" in data.coords\n",
    "\n",
    "    ## handle trimming for T-grid\n",
    "    if on_Tgrid:\n",
    "\n",
    "        ## helper function to check if 'x' is in 'x_range'\n",
    "        isin_range = lambda x, x_range: (x_range[0] <= x) & (x <= x_range[1])\n",
    "\n",
    "        ## get mask for data in given lon/lat range\n",
    "        in_lon_range = isin_range(data[\"TLONG\"], lon_range)\n",
    "        in_lat_range = isin_range(data[\"TLAT\"], lat_range)\n",
    "        in_lonlat_range = in_lon_range & in_lat_range\n",
    "\n",
    "        ## load to memory\n",
    "        in_lonlat_range.load()\n",
    "\n",
    "        ## Retain all points with at least one valid grid cell\n",
    "        x_idx = in_lonlat_range.any(\"nlat\")\n",
    "        y_idx = in_lonlat_range.any(\"nlon\")\n",
    "\n",
    "        ## select given points\n",
    "        return data.isel(nlon=x_idx, nlat=y_idx)\n",
    "\n",
    "    else:\n",
    "        return data.sel(lon=slice(*lon_range), lat=slice(*lat_range))\n",
    "\n",
    "\n",
    "def load_ensemble_helper(varname, simulation_type, preprocess_func=None):\n",
    "    \"\"\"\n",
    "    Load all ensemble members for given simulation type and variable.\n",
    "    Arguments:\n",
    "        - varname: name of variable to load, one of {\"SST\",\"PSL\"}\n",
    "        - simulation_type: one of {\"hist\", \"rcp85\"}\n",
    "        - preprocess func: optional preprocessing function to apply to the simulation\n",
    "    Returns:\n",
    "        - xarray dataarray with given data and 'ensemble' dimension\n",
    "    \"\"\"\n",
    "\n",
    "    ## put arguments in dictionary\n",
    "    kwargs = dict(\n",
    "        varname=varname,\n",
    "        simulation_type=simulation_type,\n",
    "        preprocess_func=preprocess_func,\n",
    "    )\n",
    "\n",
    "    ## put results in list\n",
    "    data = [load_simulation(member_id=i, **kwargs) for i in np.arange(1, 11)]\n",
    "\n",
    "    ## concatenate data along the \"ensemble\" dimension\n",
    "    ensemble_dim = pd.Index(np.arange(1, 11), name=\"member\")\n",
    "    data = xr.concat(data, dim=ensemble_dim)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_ensemble(varname, simulation_type, preprocess_func=None, save_fp=None):\n",
    "    \"\"\"\n",
    "    Load all ensemble members for given simulation type and variable.\n",
    "    (Checks if data exists locally first).\n",
    "    Arguments:\n",
    "        - varname: name of variable to load, one of {\"SST\",\"PSL\"}\n",
    "        - simulation_type: one of {\"hist\", \"rcp85\"}\n",
    "        - preprocess func: optional preprocessing function to apply to the simulation\n",
    "        - save_fp: pathlib.Path object (save the result here if specified)\n",
    "    Returns:\n",
    "        - xarray dataarray with given data and 'ensemble' dimension\n",
    "    \"\"\"\n",
    "\n",
    "    ## put arguments in dictionary\n",
    "    kwargs = dict(\n",
    "        varname=varname,\n",
    "        simulation_type=simulation_type,\n",
    "        preprocess_func=preprocess_func,\n",
    "    )\n",
    "\n",
    "    ## load pre-computed data if it exists\n",
    "    if save_fp is not None:\n",
    "\n",
    "        ## path to file\n",
    "        save_fp = save_fp / f\"{varname}_{simulation_type}.nc\"\n",
    "\n",
    "        ## check if file exists:\n",
    "        if save_fp.is_file():\n",
    "            data = xr.open_dataarray(save_fp)\n",
    "\n",
    "        else:\n",
    "\n",
    "            ## load the data and save to file for next time\n",
    "            data = load_ensemble_helper(**kwargs)\n",
    "\n",
    "            print(\"saving to file\")\n",
    "            data.to_netcdf(save_fp)\n",
    "\n",
    "    else:\n",
    "\n",
    "        ## don't load/save the data\n",
    "        data = load_ensemble_helper(**kwargs)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def preprocess(data):\n",
    "    \"\"\"\n",
    "    Preprocessing steps:\n",
    "        1. remove data before Feb 1920\n",
    "        2. trim in lon/lat space\n",
    "        3. convert time dimension from cftime to datetime\n",
    "    \"\"\"\n",
    "\n",
    "    ## trim in time\n",
    "    data_ = data.sel(time=slice(\"1920-02\", None))\n",
    "\n",
    "    ## trim in space\n",
    "    data_ = trim(data_)\n",
    "\n",
    "    ## update time dimension\n",
    "    start_year = data_.time.isel(time=0).dt.year.item()\n",
    "    start_month = data_.time.isel(time=0).dt.month.item()\n",
    "    start_date = f\"{start_year}-{start_month}-01\"\n",
    "    data_[\"time\"] = pd.date_range(start=start_date, periods=len(data_.time), freq=\"MS\")\n",
    "\n",
    "    return data_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5bd9a1-60a1-4d16-ad38-12c57c595e4f",
   "metadata": {},
   "source": [
    "## Set up Dask dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded97ad9-4902-4097-85e2-357f89e0212f",
   "metadata": {},
   "source": [
    "I commented this out, as some people were getting \"HDF: error\"-like messages possibly related to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1fca5a-c33e-4a4f-bffe-05cf4eaea1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## set up local cluster on dask\n",
    "# client = dask.distributed.Client()\n",
    "\n",
    "# ## display information about cluster (including address of dashboard)\n",
    "# client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333948ce-71b3-45c2-a758-89326cac7d36",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e39c0a-ccb3-476f-9d93-a13338805a88",
   "metadata": {},
   "source": [
    "### Set filepaths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65329af-344f-4b7e-92da-1d12401f1dd1",
   "metadata": {},
   "source": [
    "````{admonition} To-do\n",
    "Update the filepaths ```SERVER_FP``` and ```save_fp``` in the code cell below.\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eb8c3a-dd13-4c17-be12-a52d2e458682",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Path to file server\n",
    "SERVER_FP = pathlib.Path(\"/Volumes\")\n",
    "\n",
    "## Specify folder location for saving trimmed data (\"./\" means current directory)\n",
    "save_fp = pathlib.Path(\"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2174c18-f322-4761-8852-56831c0ad804",
   "metadata": {},
   "source": [
    "### Do the loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146b4707-46e8-40a6-8ac2-76355769fd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data\n",
    "data_hist = load_ensemble(\"SST\", \"hist\", preprocess_func=preprocess, save_fp=save_fp)\n",
    "data_rcp = load_ensemble(\"SST\", \"rcp85\", preprocess_func=preprocess, save_fp=save_fp)\n",
    "\n",
    "## Optional: load into memory (warning: may be slow!)\n",
    "data_hist.load()\n",
    "data_rcp.load();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d314c3-21bb-442d-a21e-9c3975c19be9",
   "metadata": {},
   "source": [
    "## Plot a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf7619b-ed04-4c0f-bcc2-66b659ff0a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "## blank canvas\n",
    "fig = plt.figure(figsize=(10, 3))\n",
    "\n",
    "## make background of trop. Pacific\n",
    "fig, ax = plot_setup_pacific(fig)\n",
    "\n",
    "## plot the data\n",
    "plot_data = ax.pcolormesh(\n",
    "    data_hist.TLONG,\n",
    "    data_hist.TLAT,\n",
    "    data_hist.isel(member=0, time=0),\n",
    "    cmap=\"cmo.thermal\",\n",
    "    vmax=30,\n",
    "    vmin=15,\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "\n",
    "## make a colorbar\n",
    "cb = fig.colorbar(plot_data, ticks=[15, 20, 25, 30], fraction=0.015, pad=0.05)\n",
    "\n",
    "## plot outline of Niño 3.4 region\n",
    "ax = plot_box_outline(ax, lon_range=[190, 240], lat_range=[-5, 5])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d351eff-fdf0-42ac-ad9f-aaac49259080",
   "metadata": {},
   "source": [
    "## Statistics for \"historical\" scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc36d794-5832-405e-aaa5-dc4fccfe124c",
   "metadata": {},
   "source": [
    "### Spatial mean and standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c863c61a-c693-49bb-ab8c-6fcd3429f8b1",
   "metadata": {},
   "source": [
    "#### Compute spatial mean/variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b8bb86-0fb5-4405-98c2-4507e491ec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute climatology statistics\n",
    "spatial_mean = data_hist.groupby(\"time.month\").mean([\"time\", \"member\"], skipna=False)\n",
    "spatial_std = data_hist.groupby(\"time.month\").std([\"time\", \"member\"], skipna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f05805-93e6-4ed0-bc75-878ae55ecb95",
   "metadata": {},
   "source": [
    "#### Plot mean for january "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2a83e1-b252-4662-9ea7-613be34108ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## blank canvas\n",
    "fig = plt.figure(figsize=(10, 3))\n",
    "\n",
    "## make background of trop. Pacific\n",
    "fig, ax = plot_setup_pacific(fig)\n",
    "\n",
    "## plot the data\n",
    "plot_data = ax.pcolormesh(\n",
    "    spatial_mean.TLONG,\n",
    "    spatial_mean.TLAT,\n",
    "    spatial_mean.sel(month=12),\n",
    "    cmap=\"cmo.thermal\",\n",
    "    vmax=30,\n",
    "    vmin=15,\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "\n",
    "## make a colorbar\n",
    "cb = fig.colorbar(\n",
    "    plot_data, ticks=[15, 20, 25, 30], label=r\"$^{\\circ}C$\", fraction=0.015, pad=0.05\n",
    ")\n",
    "\n",
    "## plot outline of Niño 3.4 region\n",
    "ax = plot_box_outline(ax, lon_range=[190, 240], lat_range=[-5, 5])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0582fad-523e-41f0-a7ac-0b5114d27f46",
   "metadata": {},
   "source": [
    "#### Plot standard dev. for January"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746a8a04-14a3-4ff9-992b-15e7dabde5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## blank canvas\n",
    "fig = plt.figure(figsize=(10, 3))\n",
    "\n",
    "## make background of trop. Pacific\n",
    "fig, ax = plot_setup_pacific(fig)\n",
    "\n",
    "## plot the data\n",
    "plot_data = ax.pcolormesh(\n",
    "    spatial_std.TLONG,\n",
    "    spatial_std.TLAT,\n",
    "    spatial_std.sel(month=12),\n",
    "    cmap=\"cmo.amp\",\n",
    "    vmax=2,\n",
    "    vmin=0,\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "\n",
    "## make a colorbar\n",
    "cb = fig.colorbar(\n",
    "    plot_data, ticks=[0, 1, 2], label=r\"$^{\\circ}C$\", fraction=0.015, pad=0.05\n",
    ")\n",
    "\n",
    "## plot outline of Niño 3.4 region\n",
    "ax = plot_box_outline(ax, lon_range=[190, 240], lat_range=[-5, 5])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2c49dc-0c82-49d3-9045-1f1cc630f150",
   "metadata": {},
   "source": [
    "### Niño 3.4 index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99dcfda-c529-43b4-b109-bcd9586dca29",
   "metadata": {},
   "source": [
    "Function to compute Niño 3.4 index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bb35d3-deaa-477b-8d6d-92a4ad2bba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nino34_idx(data):\n",
    "    \"\"\"compute Niño34 index\"\"\"\n",
    "    return trim(data, lon_range=[190, 240], lat_range=[-5, 5]).mean([\"nlon\", \"nlat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5909d1b-c93f-4803-b535-37be9a6a2745",
   "metadata": {},
   "source": [
    "Compute the index and do some pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27617f22-1398-4760-93aa-1efd6f0844fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute nino 3.4 climatology\n",
    "nino34_raw = get_nino34_idx(data_hist)\n",
    "nino34_mean = nino34_raw.groupby(\"time.month\").mean([\"time\", \"member\"])\n",
    "nino34_std = nino34_raw.groupby(\"time.month\").std([\"time\", \"member\"])\n",
    "\n",
    "## Compute anomalies (spatial data and nino 3.4)\n",
    "data_anom = data_hist.groupby(\"time.month\") - spatial_mean\n",
    "nino34_anom = get_nino34_idx(data_anom)\n",
    "\n",
    "## compute detrended anomalies (spatial data and Niño 3.4)\n",
    "data_trend = get_trend(data_anom.mean(\"member\"))\n",
    "data_detrend = data_anom - data_trend\n",
    "nino34_detrend = get_nino34_idx(data_detrend)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407377f1-86ff-4eab-b4c6-556da029f54e",
   "metadata": {},
   "source": [
    "#### plot seasonal cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdbefcd-e513-43b4-b040-aa7046551563",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make the plot\n",
    "fig, ax = plot_seasonal_cycle(nino34_mean, nino34_std)\n",
    "\n",
    "## add some labels\n",
    "ax.set_xticks([1, 7, 12], labels=[\"Jan\", \"Jul\", \"Dec\"])\n",
    "ax.set_title(r\"Niño 3.4 climatology\")\n",
    "ax.set_ylabel(r\"$K$\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3512ed7f-b8ac-4e02-89bf-d731dc9a93e4",
   "metadata": {},
   "source": [
    "#### plot Niño 3.4 over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217c46ab-398a-4211-8c17-953d085701b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 3))\n",
    "\n",
    "## plot individual ensemble members\n",
    "for m in nino34_anom.member:\n",
    "    ax.plot(data_hist.time, nino34_anom.sel(member=m), alpha=0.5, c=\"gray\", lw=0.5)\n",
    "\n",
    "## plot ensemble mean\n",
    "ax.plot(\n",
    "    data_hist.time,\n",
    "    nino34_anom.mean(\"member\"),\n",
    "    c=\"r\",\n",
    "    lw=2,\n",
    "    zorder=2,\n",
    "    label=\"Ensemble mean\",\n",
    ")\n",
    "\n",
    "## label\n",
    "ax.set_ylabel(r\"Niño 3.4 ($^{\\circ}C$)\")\n",
    "ax.legend()\n",
    "ax.axhline(0, ls=\"--\", c=\"k\", lw=1)\n",
    "ax.set_xlim([datetime.datetime(1920, 1, 1), datetime.datetime(2006, 12, 31)])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075323ce-6a40-478d-ab61-946675f7e4d4",
   "metadata": {},
   "source": [
    "#### Estimate trend for historical simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfe221d-23de-43a3-84e0-c762456050ef",
   "metadata": {},
   "source": [
    "Function to estimate trend in units of [1/century]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af031689-a712-4309-9f5d-bd3138a9c5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trend_per_100yrs(x):\n",
    "    \"\"\"get trend of data in units of 100/yrs\"\"\"\n",
    "\n",
    "    ## Get timeseries of trend\n",
    "    x_trend_timeseries = get_trend(x)\n",
    "\n",
    "    ## get total trend change over time period\n",
    "    dx = x_trend_timeseries[-1] - x_trend_timeseries[0]\n",
    "\n",
    "    ## convert to units of 1/month by dividing by number of months\n",
    "    dt = len(x.time)\n",
    "    dx_dt = dx / dt\n",
    "\n",
    "    ## convert from 1/month to 1/(100 yrs)\n",
    "    months_per_100_yrs = 100 * 12\n",
    "    dx_dt *= months_per_100_yrs\n",
    "\n",
    "    return dx_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45241e29-a49d-4cfa-8624-d1a6fad66457",
   "metadata": {},
   "source": [
    "Compute trend in Niño 3.4 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2c01e5-fd33-4c2e-97f8-b3e37973c541",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute nino34_trend\n",
    "nino34_trend = get_trend_per_100yrs(nino34_anom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03111732-13ca-42d2-aa6d-6743cb9fea6f",
   "metadata": {},
   "source": [
    "Plot result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c169833-8d1c-4e80-a021-3cce42e75468",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(1, 3))\n",
    "ax.scatter(np.ones_like(nino34_trend), nino34_trend, c=\"k\", s=10)\n",
    "ax.axhline(nino34_trend.mean(), c=\"k\", ls=\"--\", label=\"Mean\")\n",
    "ax.axhline(0, c=\"gray\", alpha=0.5, lw=1)\n",
    "ax.set_yticks(\n",
    "    [\n",
    "        0,\n",
    "        0.3,\n",
    "        0.6,\n",
    "    ]\n",
    ")\n",
    "ax.set_xticks([])\n",
    "ax.set_ylim([-0.1, 0.8])\n",
    "ax.legend(prop={\"size\": 8})\n",
    "ax.set_title(\"Niño 3.4 trend by ensemble member\")\n",
    "ax.set_ylabel(r\"$^{\\circ}C$ / 100 yrs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672ad2e7-5034-4be9-8423-9f8f12c3ef93",
   "metadata": {},
   "source": [
    "Compute spatial trend (trend at each gridcell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf927d0b-4ef9-47d7-bb2e-f380ded4e6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute trend\n",
    "spatial_trend = get_trend_per_100yrs(data_anom).mean(\"member\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89a3260-6155-4154-a1f0-5b19a70e288c",
   "metadata": {},
   "source": [
    "Plot spatial trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae6514e-01b8-4d98-b479-56d852f87c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot\n",
    "fig = plt.figure(figsize=(10, 3))\n",
    "\n",
    "## make background of trop. Pacific\n",
    "fig, ax = plot_setup_pacific(fig)\n",
    "\n",
    "## plot the data\n",
    "plot_data = ax.pcolormesh(\n",
    "    data_hist.TLONG,\n",
    "    data_hist.TLAT,\n",
    "    spatial_trend,\n",
    "    cmap=\"cmo.balance\",\n",
    "    vmax=1,\n",
    "    vmin=-1,\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "\n",
    "## make a colorbar\n",
    "cb = fig.colorbar(\n",
    "    plot_data,\n",
    "    ticks=[-1, 0, 1],\n",
    "    label=r\"$^{\\circ}C$ / 100 yrs\",\n",
    "    fraction=0.015,\n",
    "    pad=0.05,\n",
    ")\n",
    "\n",
    "## plot outline of Niño 3.4 region\n",
    "ax = plot_box_outline(ax, lon_range=[190, 240], lat_range=[-5, 5])\n",
    "\n",
    "## label\n",
    "ax.set_title(\"Trend over historical simulation\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ba053e-33ff-40b0-8b21-dc10423893c6",
   "metadata": {},
   "source": [
    "### Spatial pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900b55b8-a9c3-4cc3-b821-faffde294648",
   "metadata": {},
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4554d41-391d-474b-8a25-fa9c50a79d75",
   "metadata": {},
   "source": [
    "Functions to compute regression and correlation coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a25ab0-2f9c-4931-ad73-fc1f8c247564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regression_coef(Y, X):\n",
    "    \"\"\"\n",
    "    Solves for 'M' in the regression equation Y = MX.\n",
    "    Compute covariance matrices over 'member' and 'time' dimensions.\n",
    "    Assumes data is already centered\n",
    "        Y.mean([\"time\",\"member\"]) == 0, and\n",
    "        X.mean([\"time\",\"member\"]) == 0\n",
    "    \"\"\"\n",
    "\n",
    "    ## compute covariance matrices\n",
    "    cov_xy = (X * Y).mean([\"member\", \"time\"])\n",
    "    cov_xx = (X * X).mean([\"member\", \"time\"])\n",
    "\n",
    "    ## least squares fit for 'M'\n",
    "    M = cov_xy / cov_xx\n",
    "\n",
    "    return M\n",
    "\n",
    "\n",
    "def get_corr_coef(Y, X):\n",
    "    \"\"\"\n",
    "    Finds correlation between X and Y.\n",
    "    Compute covariance matrices over 'member' and 'time' dimensions.\n",
    "    Assumes data is already centered\n",
    "        Y.mean([\"time\",\"member\"]) == 0, and\n",
    "        X.mean([\"time\",\"member\"]) == 0\n",
    "    \"\"\"\n",
    "\n",
    "    ## compute covariance matrices\n",
    "    cov_xy = (X * Y).mean([\"member\", \"time\"])\n",
    "    cov_xx = (X * X).mean([\"member\", \"time\"])\n",
    "    cov_yy = (Y * Y).mean([\"member\", \"time\"])\n",
    "\n",
    "    ## least squares fit for 'M'\n",
    "    r = cov_xy / np.sqrt(cov_xx * cov_yy)\n",
    "\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fc5c8a-a24e-462b-b1b6-728c6224d24b",
   "metadata": {},
   "source": [
    "Compute the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b168755f-d656-49ea-9bb4-414d8335b615",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute linear regression coefficient and correlation coefficient\n",
    "regression_coef = get_regression_coef(data_detrend, nino34_detrend)\n",
    "corr = get_corr_coef(data_detrend, nino34_detrend)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c441796-9b68-46fa-947b-c4b0f8b34717",
   "metadata": {},
   "source": [
    "Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aca28b-4438-44fe-9eab-0fb3c19d96f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot regression coefficient\n",
    "fig = plt.figure(figsize=(10, 3))\n",
    "\n",
    "## make background of trop. Pacific\n",
    "fig, ax = plot_setup_pacific(fig)\n",
    "\n",
    "## plot the data\n",
    "plot_data = ax.pcolormesh(\n",
    "    data_hist.TLONG,\n",
    "    data_hist.TLAT,\n",
    "    regression_coef,\n",
    "    cmap=\"cmo.balance\",\n",
    "    vmax=1.5,\n",
    "    vmin=-1.5,\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "\n",
    "## make a colorbar\n",
    "cb = fig.colorbar(\n",
    "    plot_data,\n",
    "    ticks=[-1.5, 0, 1.5],\n",
    "    label=r\"$^{\\circ}C$ / Niño$_{3.4}$\",\n",
    "    fraction=0.015,\n",
    "    pad=0.05,\n",
    ")\n",
    "\n",
    "## plot outline of Niño 3.4 region\n",
    "ax = plot_box_outline(ax, lon_range=[190, 240], lat_range=[-5, 5], c=\"w\")\n",
    "\n",
    "## label\n",
    "ax.set_title(r\"ENSO spatial pattern (historical)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d25b5cb-67d5-473e-9bbc-7e5831c417e1",
   "metadata": {},
   "source": [
    "#### Composite\n",
    "First, a function to compute composites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1324e4df-5288-43fa-a102-42c5da31e0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def composite(data, mask):\n",
    "    \"\"\"\n",
    "    Create composite (average) based on specified mask.\n",
    "    Args:\n",
    "        - data: dataarray to use for the composite\n",
    "        - mask: dataarray with dimensions [\"member\",\"time\"];\n",
    "            used to filter 'data' to create the composite\n",
    "    Returns:\n",
    "        - composite\n",
    "        - n_samples: number of samples in the composite\n",
    "    \"\"\"\n",
    "\n",
    "    ## average over masked entries\n",
    "    composite = data.where(mask).mean([\"member\", \"time\"], skipna=True)\n",
    "\n",
    "    ## get number of samples\n",
    "    n_samples = mask.sum()\n",
    "\n",
    "    return composite, n_samples\n",
    "\n",
    "\n",
    "## compute composites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0b3672-1488-4200-b8dc-9dea9bf951c9",
   "metadata": {},
   "source": [
    "Next, compute the composites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3e4d66-4ec3-4666-936a-c794d02cf1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get composite for warm and cold events\n",
    "comp_warm, n_warm = composite(data_detrend, mask=nino34_detrend > 1.5)\n",
    "comp_cold, n_cold = composite(data_detrend, mask=nino34_detrend < -1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c95445b-5248-4cf8-a323-f01b031e182a",
   "metadata": {},
   "source": [
    "Finally, plot the composites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc05b1c-ad46-4e4a-8b0a-8b6c67e17007",
   "metadata": {},
   "outputs": [],
   "source": [
    "## spatial pattern of composites\n",
    "for comp, count, label in zip(\n",
    "    [comp_warm, comp_cold], [n_warm, n_cold], [\"warm\", \"cold\"]\n",
    "):\n",
    "\n",
    "    ## plot regression coefficient\n",
    "    fig = plt.figure(figsize=(10, 3))\n",
    "\n",
    "    ## make background of trop. Pacific\n",
    "    fig, ax = plot_setup_pacific(fig)\n",
    "\n",
    "    ## plot the data\n",
    "    plot_data = ax.pcolormesh(\n",
    "        data_hist.TLONG,\n",
    "        data_hist.TLAT,\n",
    "        comp,\n",
    "        cmap=\"cmo.balance\",\n",
    "        vmax=3,\n",
    "        vmin=-3,\n",
    "        transform=ccrs.PlateCarree(),\n",
    "    )\n",
    "\n",
    "    ## make a colorbar\n",
    "    cb = fig.colorbar(\n",
    "        plot_data,\n",
    "        ticks=[-3, 0, 3],\n",
    "        label=r\"$^{\\circ}C$\",\n",
    "        fraction=0.015,\n",
    "        pad=0.05,\n",
    "    )\n",
    "\n",
    "    ## plot outline of Niño 3.4 region\n",
    "    ax = plot_box_outline(ax, lon_range=[190, 240], lat_range=[-5, 5], c=\"w\")\n",
    "\n",
    "    ## label\n",
    "    ax.set_title(f\"ENSO composite ({label}, n = {count.values.item()})\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "## Plot the asymmetry\n",
    "fig = plt.figure(figsize=(10, 3))\n",
    "\n",
    "## make background of trop. Pacific\n",
    "fig, ax = plot_setup_pacific(fig)\n",
    "\n",
    "## plot the data\n",
    "plot_data = ax.pcolormesh(\n",
    "    data_hist.TLONG,\n",
    "    data_hist.TLAT,\n",
    "    comp_warm + comp_cold,\n",
    "    cmap=\"cmo.balance\",\n",
    "    vmax=1.5,\n",
    "    vmin=-1.5,\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "\n",
    "## make a colorbar\n",
    "cb = fig.colorbar(\n",
    "    plot_data,\n",
    "    ticks=[-1.5, 0, 1.5],\n",
    "    label=r\"$^{\\circ}C$\",\n",
    "    fraction=0.015,\n",
    "    pad=0.05,\n",
    ")\n",
    "\n",
    "## plot outline of Niño 3.4 region\n",
    "ax = plot_box_outline(ax, lon_range=[190, 240], lat_range=[-5, 5], c=\"w\")\n",
    "\n",
    "## label\n",
    "ax.set_title(f\"Composite asymmetry (warm plus cold)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59bfdc8-de9f-45c8-a909-ebdbf61ed9d1",
   "metadata": {},
   "source": [
    "## Autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c792e3-93dd-427a-a5e7-2f50eb829592",
   "metadata": {},
   "source": [
    "Compute autocorrelation by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9196cef1-70a1-44e8-b4db-6c211645155a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute autocorrelation by month\n",
    "autocorr_by_month = get_autocorr_by_month(nino34_detrend, lags=np.arange(-24, 25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847c9c49-892e-491b-b7fc-0489a5b62f13",
   "metadata": {},
   "source": [
    "Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6898a55d-1503-425f-98fc-e564202ce542",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "## plot data\n",
    "lags = np.arange(0, 19)\n",
    "months = np.arange(1, 13)\n",
    "plot_data = ax.pcolormesh(\n",
    "    lags, months, autocorr_by_month.sel(lag=lags), cmap=\"cmo.balance\", vmin=-1, vmax=1\n",
    ")\n",
    "\n",
    "## colorbar\n",
    "cb = fig.colorbar(plot_data, label=\"corr. coef.\", ticks=[-1, 0, 1])\n",
    "\n",
    "## label\n",
    "ax.set_ylabel(\"Start month\")\n",
    "ax.set_xlabel(\"Lag (months)\")\n",
    "ax.set_xticks([0, 6, 12, 18])\n",
    "ax.set_yticks([2, 7, 12], labels=[\"Feb\", \"Jul\", \"Dec\"])\n",
    "ax.set_title(\"Niño 3.4 autocorrelation\")\n",
    "\n",
    "## swap direction of y-axis\n",
    "ax.set_ylim(ax.get_ylim()[::-1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cc1fa9-86ec-4e94-b38b-b3da01247ff0",
   "metadata": {},
   "source": [
    "## Future Projections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d569f6c-aef4-4ed2-89a0-816e2e5688e1",
   "metadata": {},
   "source": [
    "### Niño 3.4 Timeseries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2ca767-d860-433a-bf98-c13ac4ff65be",
   "metadata": {},
   "source": [
    "Compute Niño 3.4 in RCP 8.5 simulation and concatenate to Niño 3.4 from historical simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37332787-8ca7-457f-8f4a-16cf6969c0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute Niño 3.4 for RCP 8.5\n",
    "nino34_rcp_raw = get_nino34_idx(data_rcp)\n",
    "\n",
    "## concatenate with historical timeseries\n",
    "nino34_raw_long = xr.concat([nino34_raw, nino34_rcp_raw], dim=\"time\")\n",
    "\n",
    "## remove seasonal cycle\n",
    "deseason = lambda x: x.groupby(\"time.month\") - x.groupby(\"time.month\").mean(\n",
    "    [\"time\", \"member\"]\n",
    ")\n",
    "nino34_anom_long = deseason(nino34_raw_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf675e7-a0cb-4efe-9db8-60971b60d3d7",
   "metadata": {},
   "source": [
    "Plot concatenated timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077758a4-b60c-4466-ac86-4d181f7dd285",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot result\n",
    "fig, ax = plt.subplots(figsize=(7, 3))\n",
    "\n",
    "## plot individual ensemble members\n",
    "for m in nino34_anom_long.member:\n",
    "    ax.plot(\n",
    "        nino34_anom_long.time,\n",
    "        nino34_anom_long.sel(member=m),\n",
    "        alpha=0.5,\n",
    "        c=\"gray\",\n",
    "        lw=0.5,\n",
    "    )\n",
    "\n",
    "## plot ensemble mean\n",
    "ax.plot(\n",
    "    nino34_anom_long.time,\n",
    "    nino34_anom_long.mean(\"member\"),\n",
    "    c=\"r\",\n",
    "    lw=2,\n",
    "    zorder=2,\n",
    "    label=\"Ensemble mean\",\n",
    ")\n",
    "\n",
    "## label\n",
    "ax.set_ylabel(r\"Niño 3.4 ($^{\\circ}C$)\")\n",
    "ax.axhline(0, ls=\"--\", c=\"k\", lw=1)\n",
    "ax.axvline(datetime.datetime(2006, 1, 1), lw=0.5, c=\"k\")\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91350fea-c779-47b0-8fe0-1730c8fa9772",
   "metadata": {},
   "source": [
    "### Compare variance between 1920-1960 and 2160-2100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06895623-6861-4e84-9377-33aee3a6e080",
   "metadata": {},
   "source": [
    "Compute PDFs over early and late period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009a346d-4fd9-4a49-8b0a-0c8c1e788363",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Niño 3.4 over early and late periods\n",
    "nino34_anom_early = nino34_anom_long.sel(time=slice(\"1920\", \"1960\"))\n",
    "nino34_anom_late = nino34_anom_long.sel(time=slice(\"2060\", \"2100\"))\n",
    "\n",
    "## compute PDFs (normalized histograms)\n",
    "pdf_early, edges_early = get_empirical_pdf(nino34_anom_early)\n",
    "pdf_late, edges_late = get_empirical_pdf(nino34_anom_late)\n",
    "\n",
    "## compute PDFs on detrended data\n",
    "# helper function to detrend\n",
    "detrend_fn = lambda x: x - get_trend(x.mean(\"member\"))\n",
    "\n",
    "# specify bin edges for the histograms\n",
    "bin_edges = np.arange(-4 - 0.875, 4 + 1.25, 0.75)\n",
    "\n",
    "# compute the PDFs\n",
    "pdf_early_, edges_early_ = get_empirical_pdf(\n",
    "    detrend_fn(nino34_anom_early), bin_edges=bin_edges\n",
    ")\n",
    "pdf_late_, edges_late_ = get_empirical_pdf(\n",
    "    detrend_fn(nino34_anom_late), bin_edges=bin_edges\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fce35aa-6044-4622-baea-4b0073a705e6",
   "metadata": {},
   "source": [
    "Plot result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecf5283-dd5f-40f6-9366-2629436736b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Plot result\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 3))\n",
    "\n",
    "## plot histogram\n",
    "axs[0].stairs(values=pdf_early, edges=edges_early, label=\"1920-1960\")\n",
    "axs[0].stairs(values=pdf_late, edges=edges_late, label=\"2060-2100\")\n",
    "\n",
    "## label\n",
    "axs[0].set_xlabel(r\"$^{\\circ}C$ anomaly\")\n",
    "axs[0].set_ylabel(\"Probability\")\n",
    "\n",
    "axs[0].legend()\n",
    "axs[0].set_title(\"Niño 3.4 PDFs\")\n",
    "\n",
    "\n",
    "#### next, plot centered histograms\n",
    "axs[1].stairs(values=pdf_early_, edges=edges_early_, label=\"1920-1960\")\n",
    "axs[1].stairs(values=pdf_late_, edges=edges_late_, label=\"2060-2100\")\n",
    "\n",
    "## make sure y-axis is the same across plots and remove y-ticks from the RHS panel\n",
    "axs[0].set_ylim(axs[1].get_ylim())\n",
    "axs[1].set_yticks([])\n",
    "\n",
    "## label\n",
    "axs[1].set_xlabel(r\"$^{\\circ}C$ anomaly\")\n",
    "axs[1].set_title(\"Niño 3.4 PDFs (detrended data)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1834dae-73ae-4a3c-ba36-81c3581dab18",
   "metadata": {},
   "source": [
    "### Change in autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8c9ae5-e149-4b84-b881-cf143ff4d475",
   "metadata": {},
   "source": [
    "Estimate autocorrelation in early & late periods, and compute the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abc457e-3bec-49dd-b8ef-60aa02bdd63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify lags for autocorrelation\n",
    "lags = np.arange(1, 19)\n",
    "\n",
    "## compute autocorrelations and difference\n",
    "autocorr_early = get_autocorr_by_month(detrend_fn(nino34_anom_early), lags=lags)\n",
    "autocorr_late = get_autocorr_by_month(detrend_fn(nino34_anom_late), lags=lags)\n",
    "autocorr_diff = autocorr_late - autocorr_early"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c4da68-2023-422c-ad2c-895f1915dcda",
   "metadata": {},
   "source": [
    "Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b8146c-9bd7-4924-a1c2-a69fcafd5474",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot autocorelation for early time series\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "## plot data\n",
    "plot_data = ax.pcolormesh(\n",
    "    autocorr_early.lag,\n",
    "    autocorr_early.month,\n",
    "    autocorr_early,\n",
    "    cmap=\"cmo.balance\",\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    ")\n",
    "\n",
    "## colorbar\n",
    "cb = fig.colorbar(plot_data, label=\"corr. coef.\", ticks=[-1, 0, 1])\n",
    "\n",
    "## label\n",
    "ax.set_ylabel(\"Start month\")\n",
    "ax.set_xlabel(\"Lag (months)\")\n",
    "ax.set_xticks([0, 6, 12, 18])\n",
    "ax.set_yticks([2, 7, 12], labels=[\"Feb\", \"Jul\", \"Dec\"])\n",
    "ax.set_title(\"Niño 3.4 autocorrelation (1920-1940)\")\n",
    "\n",
    "## swap direction of y-axis\n",
    "ax.set_ylim(ax.get_ylim()[::-1])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "## plot difference (late minus early)\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "## plot data\n",
    "plot_data = ax.pcolormesh(\n",
    "    autocorr_diff.lag,\n",
    "    autocorr_diff.month,\n",
    "    autocorr_diff,\n",
    "    cmap=\"cmo.balance\",\n",
    "    vmin=-0.3,\n",
    "    vmax=0.3,\n",
    ")\n",
    "\n",
    "## colorbar\n",
    "cb = fig.colorbar(plot_data, label=\"corr. coef.\", ticks=[-1, 0, 1])\n",
    "\n",
    "## label\n",
    "ax.set_ylabel(\"Start month\")\n",
    "ax.set_xlabel(\"Lag (months)\")\n",
    "ax.set_xticks([0, 6, 12, 18])\n",
    "ax.set_yticks([2, 7, 12], labels=[\"Feb\", \"Jul\", \"Dec\"])\n",
    "ax.set_title(\"Change in autocorr. (2060-2100 minus 1920-1960)\")\n",
    "\n",
    "## swap direction of y-axis\n",
    "ax.set_ylim(ax.get_ylim()[::-1])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
