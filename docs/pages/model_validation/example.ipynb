{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa9da500-5ed5-4244-85ae-f5b2df368c45",
   "metadata": {},
   "source": [
    "# Example\n",
    "In this example, we'll compare ERA5 reanalysis outputs with a single climate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e188e288-9c30-414d-932a-45c2895bf513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import cmocean\n",
    "import copy\n",
    "import os\n",
    "import xesmf as xe\n",
    "import intake\n",
    "import scipy.stats\n",
    "\n",
    "## (optional) remove gridlines from plots\n",
    "sns.set(rc={\"axes.facecolor\": \"white\", \"axes.grid\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f149bb11-d5b0-4557-9500-138bda68e4e1",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57649248-5e04-4572-96e8-2383b0acf969",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbce73b-85d6-4563-bdf3-61188ff7a6fa",
   "metadata": {},
   "source": [
    "#### for loading from cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57edc896-433d-4b96-8ecc-416450df95e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_lsm(lsm, lon_range, lat_range):\n",
    "    \"\"\"Prepare land-sea mask by renaming coords,\n",
    "    downsampling to 1x1 grid, and selecting specified lon/lat range\"\"\"\n",
    "\n",
    "    ## rename coords\n",
    "    lsm = lsm.rename({\"latitude\": \"lat\", \"longitude\": \"lon\"})\n",
    "\n",
    "    ## get coords for interpolation (downscale to 1x1 grid)\n",
    "    lon = np.arange(lon_range[0], lon_range[1] + 1, 1)\n",
    "    lat = np.arange(lat_range[0], lat_range[1] + 1, 1)\n",
    "    new_coords = dict(lon=lon, lat=lat)\n",
    "\n",
    "    ## interpolate to grid\n",
    "    lsm = lsm.interp(new_coords)\n",
    "\n",
    "    ## add binary mask for regridding\n",
    "    lsm[\"mask\"] = (lsm < 0.5).astype(int)\n",
    "\n",
    "    return lsm.transpose(\"lat\", \"lon\")\n",
    "\n",
    "\n",
    "def load_lsm_from_cloud(lon_range, lat_range):\n",
    "    \"\"\"Load ERA5 land-sea-mask from Google server\"\"\"\n",
    "\n",
    "    ## use ERA5 land-sea mask\n",
    "    data = xr.open_zarr(\n",
    "        \"gs://weatherbench2/datasets/era5/1959-2023_01_10-wb13-6h-1440x721_with_derived_variables.zarr\",\n",
    "    )\n",
    "\n",
    "    ## load lsm into memory\n",
    "    lsm = data[\"land_sea_mask\"].compute()\n",
    "\n",
    "    return prep_lsm(lsm, lon_range=lon_range, lat_range=lat_range)\n",
    "\n",
    "\n",
    "def load_era5_from_cloud(lon_range, lat_range, apply_ocean_mask=True):\n",
    "    \"\"\"Load ERA5 from Google server with consistent processing\"\"\"\n",
    "\n",
    "    ## open data and get 2m temperature\n",
    "    data = xr.open_zarr(\n",
    "        \"gs://weatherbench2/datasets/era5/1959-2023_01_10-6h-240x121_equiangular_with_poles_conservative.zarr\",\n",
    "        chunks=dict(time=1024),\n",
    "    )[\"2m_temperature\"]\n",
    "\n",
    "    ## subset for lon/lat range\n",
    "    lonlat_idx = dict(longitude=slice(*lon_range), latitude=slice(*lat_range))\n",
    "    data = data.sel(**lonlat_idx)\n",
    "\n",
    "    ## load into memory\n",
    "    data.load()\n",
    "\n",
    "    ## convert kelvin to celsius\n",
    "    data_celsius = data.copy() - 273.15\n",
    "\n",
    "    ## resample from 6-hourly to monthly\n",
    "    data = data_celsius.resample({\"time\": \"MS\"}).mean()\n",
    "\n",
    "    ## transpose data (consistent with data on server)\n",
    "    data = data.transpose(\"time\", \"latitude\", \"longitude\")\n",
    "\n",
    "    ## Apply ocean mask if requested\n",
    "    if apply_ocean_mask:\n",
    "        lsm = load_lsm_from_cloud(lon_range=lon_range, lat_range=lat_range)\n",
    "        ocean_mask = lsm[\"mask\"]\n",
    "        ocean_mask = ocean_mask.rename({\"lat\": \"latitude\", \"lon\": \"longitude\"})\n",
    "\n",
    "        # Interpolate ocean mask to ERA5 grid\n",
    "        ocean_mask_interp = ocean_mask.interp(\n",
    "            latitude=data.latitude, longitude=data.longitude\n",
    "        )\n",
    "\n",
    "        # Apply mask (keep only ocean points)\n",
    "        data = data.where(ocean_mask_interp == 1)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_cesm_from_cloud(\n",
    "    lon_range,\n",
    "    lat_range,\n",
    "    varname=\"TREFHT\",\n",
    "    load_ssp370=False,\n",
    "    member_id=1,\n",
    "    apply_ocean_mask=True,\n",
    "):\n",
    "    \"\"\"Load CESM data from cloud with consistent processing\"\"\"\n",
    "\n",
    "    ## get catalog of available data\n",
    "    catalog = intake.open_esm_datastore(\n",
    "        \"https://raw.githubusercontent.com/NCAR/cesm2-le-aws/main/intake-catalogs/aws-cesm2-le.json\"\n",
    "    )\n",
    "\n",
    "    ## subset for temperature data\n",
    "    catalog_subset = catalog.search(variable=varname, frequency=\"monthly\")\n",
    "\n",
    "    ## kwargs for opening data\n",
    "    kwargs = dict(\n",
    "        aggregate=True,\n",
    "        xarray_open_kwargs=dict(engine=\"zarr\", decode_timedelta=True),\n",
    "        zarr_kwargs={\"consolidated\": True},\n",
    "        storage_options={\"anon\": True},\n",
    "    )\n",
    "\n",
    "    ## open data (but don't load to memory)\n",
    "    dsets = catalog_subset.to_dataset_dict(**kwargs)\n",
    "    data = dsets[\"atm.historical.monthly.cmip6\"]\n",
    "\n",
    "    ## optionally load ssp data as well\n",
    "    if load_ssp370:\n",
    "        data = xr.concat([data, dsets[\"atm.ssp370.monthly.cmip6\"]], dim=\"time\")\n",
    "\n",
    "    ## trim data (select ensemble members and lon/lat space)\n",
    "    lonlat_idx = dict(lon=slice(*lon_range), lat=slice(*lat_range))\n",
    "    data = data.sel(lonlat_idx).isel(member_id=member_id)\n",
    "\n",
    "    ## convert kelvin to celsius\n",
    "    data = data[varname] - 273.15\n",
    "\n",
    "    ## swap longitude range\n",
    "    data = swap_longitude_range(data)\n",
    "\n",
    "    ## load to memory\n",
    "    data = data.compute()\n",
    "\n",
    "    ## Regrid to regular grid and optionally apply ocean mask\n",
    "    lsm = load_lsm_from_cloud(lon_range=lon_range, lat_range=lat_range)\n",
    "    regridder = xe.Regridder(data, lsm, \"bilinear\", ignore_degenerate=False)\n",
    "    data = regridder(data)\n",
    "\n",
    "    ## Apply ocean mask if requested\n",
    "    if apply_ocean_mask:\n",
    "        ocean_mask = lsm[\"mask\"]\n",
    "        data = data.where(ocean_mask == 1)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee1d402-52ce-41a8-8eb9-b5603ba7afd6",
   "metadata": {},
   "source": [
    "#### for loading from server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7aa0ef6-bc45-4a7a-94a5-6a39639272c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_simulation(\n",
    "    server_fp, varname, member_id, simulation_type, preprocess_func=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Load dataset for single simulation, for single variable.\n",
    "    Arguments:\n",
    "        - varname: name of variable to load, one of {\"SST\",\"PSL\"}\n",
    "        - member_id: ID of ensemble member to load, an integer in the range [1,10]\n",
    "        - simulation_type: one of {\"hist\", \"rcp85\"}\n",
    "    Returns:\n",
    "        - xarray dataarray with given data\n",
    "    \"\"\"\n",
    "\n",
    "    ## Filepath to the CESM LENS dataset\n",
    "    lens_fp = pathlib.Path(\"cmip6/data/cmip6/CMIP/NCAR/LENS\")\n",
    "\n",
    "    #### 1. get filepath to data\n",
    "    data_fp = server_fp / lens_fp / pathlib.Path(varname)\n",
    "\n",
    "    #### 2. get naming pattern for files to open\n",
    "    if simulation_type == \"hist\":\n",
    "        file_pattern = f\"*20TRC*.{member_id:03d}.*.nc\"\n",
    "\n",
    "    elif simulation_type == \"rcp85\":\n",
    "        file_pattern = f\"*RCP85*.{member_id:03d}.*.nc\"\n",
    "\n",
    "    else:\n",
    "        print(\"Not a valid simulation type\")\n",
    "\n",
    "    #### 3. open the relevant datasets, applying preprocessing function\n",
    "\n",
    "    ## filepath to data\n",
    "    fp = list(data_fp.glob(file_pattern))[0]\n",
    "\n",
    "    ## load data\n",
    "    data = xr.open_dataset(fp, chunks=None, decode_timedelta=True)\n",
    "\n",
    "    ## apply (optional) preprocessing\n",
    "    if preprocess_func is not None:\n",
    "        data = preprocess_func(data)\n",
    "\n",
    "    return data[varname].squeeze(drop=True)\n",
    "\n",
    "\n",
    "def load_lsm_from_server(server_fp, lon_range=[0, 360], lat_range=[-90, 90]):\n",
    "    \"\"\"Load ERA5 land-sea-mask from CMIP6 server\"\"\"\n",
    "\n",
    "    ## get server path to ERA5 land sea mask\n",
    "    lsm_fp = server_fp / pathlib.Path(\n",
    "        \"cmip6/data/era5/reanalysis/single-levels/monthly-means/land_sea_mask/2020_land_sea_mask.nc\"\n",
    "    )\n",
    "\n",
    "    ## open lsm\n",
    "    lsm = xr.open_dataarray(lsm_fp).isel(time=0).drop_vars(\"time\")\n",
    "\n",
    "    return prep_lsm(lsm, lon_range=lon_range, lat_range=lat_range)\n",
    "\n",
    "\n",
    "def load_cesm_from_server(lon_range, lat_range, server_fp, varname, member_id=10):\n",
    "    \"\"\"Load CESM SST data with minimal preprocessing - SST datasets are typically already ocean-masked\"\"\"\n",
    "    ## shared arguments for loading data\n",
    "    load_kwargs = dict(server_fp=server_fp, varname=varname, member_id=member_id)\n",
    "\n",
    "    ## Load data\n",
    "    data_hist = load_simulation(simulation_type=\"hist\", **load_kwargs).compute()\n",
    "    data_rcp = load_simulation(simulation_type=\"rcp85\", **load_kwargs).compute()\n",
    "\n",
    "    ## concatenate in time\n",
    "    data = xr.concat([data_hist, data_rcp], dim=\"time\")\n",
    "\n",
    "    ## rename coordinates for convenience\n",
    "    data = data.rename({\"TLONG\": \"lon\", \"TLAT\": \"lat\"})\n",
    "\n",
    "    ## subset data by longitude and latitude\n",
    "    data = trim(data, lon_range=lon_range, lat_range=lat_range)\n",
    "\n",
    "    ## swap longitude range from [0,360) to (-180, 180] if needed\n",
    "    data = swap_longitude_range(data)\n",
    "\n",
    "    ## make sure longitude is in ascending order\n",
    "    data = sort_longitude(data)\n",
    "\n",
    "    # Only apply basic masking to remove obvious invalid values (like 0 or very negative values)\n",
    "    # SST datasets should already be ocean-masked\n",
    "    data = data.where(data > -10, other=np.nan)  # Remove obviously invalid SST values\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_era5_from_server(server_fp, lon_range, lat_range):\n",
    "    \"\"\"Load ERA5 data from CMIP6 server\"\"\"\n",
    "\n",
    "    ## Filepath to the ERA5 reanalysis\n",
    "    era5_fp = pathlib.Path(\"cmip6/data/era5/reanalysis/single-levels/monthly-means\")\n",
    "\n",
    "    ## sea surface temperature (SST) filepaths\n",
    "    era5_fp_sst = server_fp / era5_fp / pathlib.Path(\"sea_surface_temperature\")\n",
    "\n",
    "    ## open the data\n",
    "    data = xr.open_mfdataset(era5_fp_sst.glob(\"*.nc\"))[\"sst\"]\n",
    "\n",
    "    ## convert kelvin to celsius\n",
    "    data_celsius = data.copy() - 273.15\n",
    "\n",
    "    ## select lon/lat range\n",
    "    lonlat_idx = dict(longitude=slice(*lon_range), latitude=slice(*lat_range[::-1]))\n",
    "    data = data_celsius.sel(lonlat_idx).compute()\n",
    "\n",
    "    ## put latitudes in ascending order\n",
    "    data = data.reindex({\"latitude\": data[\"latitude\"].values[::-1]})\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806be17c-2d8d-4653-96d0-2f01cbc29360",
   "metadata": {},
   "source": [
    "#### utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ba9279-ad03-4e26-9a20-23933c39fa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(data, lon_range, lat_range):\n",
    "    \"\"\"select part of data in given longitude/latitude range\"\"\"\n",
    "\n",
    "    ## helper function to check if 'x' is in 'x_range'\n",
    "    isin_range = lambda x, x_range: (x_range[0] <= x) & (x <= x_range[1])\n",
    "\n",
    "    ## get mask for data in given lon/lat range\n",
    "    in_lon_range = isin_range(data[\"lon\"], lon_range)\n",
    "    in_lat_range = isin_range(data[\"lat\"], lat_range)\n",
    "    in_lonlat_range = in_lon_range & in_lat_range\n",
    "\n",
    "    ## load to memory\n",
    "    in_lonlat_range.load()\n",
    "\n",
    "    if \"nlon\" in data.dims:\n",
    "\n",
    "        ## Retain all points with at least one valid grid cell\n",
    "        x_idx = in_lonlat_range.any(\"nlat\")\n",
    "        y_idx = in_lonlat_range.any(\"nlon\")\n",
    "\n",
    "        return data.isel(nlon=x_idx, nlat=y_idx)\n",
    "\n",
    "    else:\n",
    "\n",
    "        return data.isel(lon=in_lon_range, lat=in_lat_range)\n",
    "\n",
    "\n",
    "def sort_longitude(data):\n",
    "    \"\"\"shuffles data so that longitude is monotonically increasing\"\"\"\n",
    "\n",
    "    ## Transpose data so that longitude is last dimension\n",
    "    ## (we'll do all the sorting along this dimension)\n",
    "    data = data.transpose(..., \"nlon\")\n",
    "\n",
    "    ## Get indices needed to sort longitude to be monotonic increasing\n",
    "    lon_sort_idx = np.argsort(data[\"lon\"].values, axis=-1)\n",
    "\n",
    "    ## sort the lon/lat coordindates\n",
    "    sort = lambda X, idx: np.take_along_axis(X.values, indices=idx, axis=-1)\n",
    "    data[\"lon\"].values = sort(data[\"lon\"], idx=lon_sort_idx)\n",
    "    data[\"lat\"].values = sort(data[\"lat\"], idx=lon_sort_idx)\n",
    "\n",
    "    #### sort the data\n",
    "\n",
    "    # first, check to see if data has more than two dimensions\n",
    "    if data.ndim > 2:\n",
    "        extra_dims = [i for i in range(data.ndim - 2)]\n",
    "        lon_sort_idx = np.expand_dims(lon_sort_idx, axis=extra_dims)\n",
    "\n",
    "    ## now, do the actual sorting\n",
    "    data.values = sort(data, idx=lon_sort_idx)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def swap_longitude_range(data):\n",
    "    \"\"\"swap longitude range of xr.DataArray from [0,360) to (-180, 180].\"\"\"\n",
    "\n",
    "    ## make copy of longitude coordinate to be modified\n",
    "    lon_new = copy.deepcopy(data.lon.values)\n",
    "\n",
    "    ## relabel values greater than 180\n",
    "    exceeds_180 = lon_new > 180\n",
    "    lon_new[exceeds_180] = -360 + lon_new[exceeds_180]\n",
    "\n",
    "    ## Update the coordinate on the xarray object\n",
    "    if \"lon\" in data.dims:\n",
    "        data = data.assign_coords({\"lon\": lon_new})\n",
    "\n",
    "    else:\n",
    "        data[\"lon\"].values = lon_new\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdfce2b-2ed5-41d4-a07f-5fba6a0a0e36",
   "metadata": {},
   "source": [
    "#### Data-handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb0cda3-a638-433a-bbb3-4ffec884350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_consistent_grids(era5_data, cesm_data, target_grid=None):\n",
    "    \"\"\"Ensure both datasets are on the same spatial grid\"\"\"\n",
    "\n",
    "    if target_grid is None:\n",
    "        # Use ERA5 grid as target by default\n",
    "        target_grid = era5_data\n",
    "\n",
    "    # Check if CESM needs regridding to match ERA5\n",
    "    if not (\n",
    "        np.array_equal(cesm_data.lat.values, target_grid.latitude.values)\n",
    "        and np.array_equal(cesm_data.long.values, target_grid.longitude.values)\n",
    "    ):\n",
    "\n",
    "        print(\"Regridding CESM data to match ERA5 grid...\")\n",
    "        regridder = xe.Regridder(\n",
    "            cesm_data, target_grid, \"bilinear\", ignore_degenerate=False\n",
    "        )\n",
    "        cesm_regridded = regridder(cesm_data)\n",
    "        return era5_data, cesm_regridded\n",
    "\n",
    "    return era5_data, cesm_data\n",
    "\n",
    "\n",
    "def load_comparable_datasets(\n",
    "    server_fp=None,\n",
    "    lon_range=[260, 360],\n",
    "    lat_range=[10, 70],\n",
    "    member_id=10,\n",
    "    load_from_cloud=True,\n",
    "    load_ssp370=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Load ERA5 and CESM datasets with consistent processing for comparison\n",
    "\n",
    "    Args:\n",
    "        server_fp: Path to server data (only needed if load_from_cloud=False)\n",
    "        lon_range: Longitude range [min, max]\n",
    "        lat_range: Latitude range [min, max]\n",
    "        member_id: CESM ensemble member ID\n",
    "        load_from_cloud: Whether to load from cloud (True) or server (False)\n",
    "        load_ssp370: Whether to include SSP370 scenario for CESM\n",
    "\n",
    "    Returns:\n",
    "        tuple: (era5_data, cesm_data) - aligned and comparable datasets\n",
    "    \"\"\"\n",
    "\n",
    "    kwargs = dict(lon_range=lon_range, lat_range=lat_range)\n",
    "\n",
    "    if load_from_cloud:\n",
    "        print(\"Loading from cloud...\")\n",
    "        print(\"- ERA5: 2m temperature with ocean mask\")\n",
    "        print(\"- CESM: 2m temperature with ocean mask\")\n",
    "\n",
    "        # Load atmospheric 2m temp with ocean mask for both\n",
    "        era5_data = load_era5_from_cloud(apply_ocean_mask=True, **kwargs)\n",
    "        cesm_data = load_cesm_from_cloud(\n",
    "            varname=\"TREFHT\",\n",
    "            load_ssp370=load_ssp370,\n",
    "            member_id=member_id,\n",
    "            apply_ocean_mask=True,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        print(\"Loading from server...\")\n",
    "        print(\"- ERA5: SST (ocean only)\")\n",
    "        print(\"- CESM: SST (ocean only)\")\n",
    "\n",
    "        # Load ocean-only SST data\n",
    "        era5_data = load_era5_from_server(server_fp, **kwargs)\n",
    "        cesm_data = load_cesm_from_server(\n",
    "            varname=\"SST\", server_fp=server_fp, member_id=member_id, **kwargs\n",
    "        )\n",
    "\n",
    "    # Align temporal bounds\n",
    "    # era5_data, cesm_data = align_temporal_bounds(era5_data, cesm_data)\n",
    "\n",
    "    # Ensure consistent spatial grids\n",
    "    era5_data, cesm_data = ensure_consistent_grids(era5_data, cesm_data)\n",
    "\n",
    "    # Print summary statistics\n",
    "    print(f\"\\nDataset summary:\")\n",
    "    print(f\"ERA5 shape: {era5_data.shape}\")\n",
    "    print(f\"CESM shape: {cesm_data.shape}\")\n",
    "\n",
    "    return era5_data, cesm_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916b7e4c-08f7-43ba-8c33-82f7477bf666",
   "metadata": {},
   "source": [
    "### Do the data-loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a12a41-0390-4052-a3c0-1f3e4f0aa1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Execute data loading\n",
    "SERVER_FP = pathlib.Path(\"/Volumes\")\n",
    "LON_RANGE = [260, 359.9]\n",
    "LAT_RANGE = [0, 70]\n",
    "LOAD_FROM_CLOUD = False\n",
    "\n",
    "## try to suppress file locking\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\"\n",
    "\n",
    "## Load comparable datasets\n",
    "t0 = time.time()\n",
    "era5_data, cesm_data = load_comparable_datasets(\n",
    "    server_fp=SERVER_FP,\n",
    "    lon_range=LON_RANGE,\n",
    "    lat_range=LAT_RANGE,\n",
    "    member_id=10,\n",
    "    load_from_cloud=LOAD_FROM_CLOUD,\n",
    "    load_ssp370=True,\n",
    ")\n",
    "\n",
    "print(f\"\\nTotal loading time: {time.time() - t0:.1f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d6b5d4-f333-4226-b712-31368f6d1f84",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Lets do a similar timeseries analysis as we did in tutorial 1 but now compare the two datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a16b47-7ef9-45b8-81d8-c1783b37b9b5",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75d3bdb-612e-4533-87b5-612c869c37b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_avg(data):\n",
    "    \"\"\"function to compute spatial average of data on grid with constant\n",
    "    longitude/latitude spacing.\"\"\"\n",
    "\n",
    "    ## determine coordinate names based on what's available\n",
    "    if \"latitude\" in data.coords:\n",
    "        lat_name = \"latitude\"\n",
    "        lon_name = \"longitude\"\n",
    "    elif \"lat\" in data.coords:\n",
    "        lat_name = \"lat\"\n",
    "        lon_name = \"lon\"\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Data must have either 'latitude'/'longitude' or 'lat'/'lon' coordinates\"\n",
    "        )\n",
    "\n",
    "    ## first, compute cosine of latitude (after converting degrees to radians)\n",
    "    latitude_radians = np.deg2rad(data[lat_name])\n",
    "    cos_lat = np.cos(latitude_radians)\n",
    "\n",
    "    ## get weighted average using xarray\n",
    "    avg = data.weighted(weights=cos_lat).mean([lon_name, lat_name])\n",
    "\n",
    "    return avg\n",
    "\n",
    "\n",
    "def compute_T_wh(x, ERA=False):\n",
    "    \"\"\"Compute Woods Hole temperature index\"\"\"\n",
    "    # ERA = True for era5, False for cesm\n",
    "    ERA = bool(ERA)\n",
    "\n",
    "    if ERA == True:\n",
    "        lonlat_idx = dict(longitude=slice(287.5, 293.5), latitude=slice(39, 44))\n",
    "    elif ERA == False:\n",
    "        lonlat_idx = dict(lon=slice(287.5, 293.5), lat=slice(39, 44))\n",
    "    else:\n",
    "        raise ValueError(\"ERA must be True or False\")\n",
    "\n",
    "    ## get subset of data inside the box\n",
    "    data_subset = x.sel(lonlat_idx)\n",
    "\n",
    "    return spatial_avg(data_subset)\n",
    "\n",
    "\n",
    "def compute_T_wh(x):\n",
    "    \"\"\"Compute Woods Hole temperature index\"\"\"\n",
    "\n",
    "    lonlat_idx = dict(longitude=slice(287.5, 293.5), latitude=slice(39, 44))\n",
    "\n",
    "    ## get subset of data inside the box\n",
    "    data_subset = x.sel(lonlat_idx)\n",
    "\n",
    "    return spatial_avg(data_subset)\n",
    "\n",
    "\n",
    "def get_empirical_pdf(x, bin_edges=None):\n",
    "    \"\"\"\n",
    "    Estimate the \"empirical\" probability distribution function for the data x.\n",
    "    In this case the result is a normalized histogram,\n",
    "    Normalized means that integrating over the histogram yields 1.\n",
    "    Returns the PDF (normalized histogram) and edges of the histogram bins\n",
    "    \"\"\"\n",
    "\n",
    "    ## compute histogram\n",
    "    if bin_edges is None:\n",
    "        hist, bin_edges = np.histogram(x)\n",
    "\n",
    "    else:\n",
    "        hist, _ = np.histogram(x, bins=bin_edges)\n",
    "\n",
    "    ## normalize to a probability distribution (PDF)\n",
    "    bin_width = bin_edges[1:] - bin_edges[:-1]\n",
    "    pdf = hist / (hist * bin_width).sum()\n",
    "\n",
    "    return pdf, bin_edges\n",
    "\n",
    "\n",
    "def get_gaussian_best_fit(x):\n",
    "    \"\"\"Get gaussian best fit to data, and evaluate\n",
    "    probabilities over the range of the data.\"\"\"\n",
    "\n",
    "    ## get normal distribution best fit\n",
    "    gaussian = scipy.stats.norm(loc=x.mean(), scale=x.std())\n",
    "\n",
    "    ## evaluate over range of data\n",
    "    # Fix: x is already a numpy array, so use x directly instead of x.values\n",
    "    amp = np.max(np.abs(x))\n",
    "    x_eval = np.linspace(-amp, amp)\n",
    "    pdf_eval = gaussian.pdf(x_eval)\n",
    "\n",
    "    return pdf_eval, x_eval\n",
    "\n",
    "\n",
    "# Compute JAS (July-August-September) seasonal averages\n",
    "def get_jas_averages(data):\n",
    "    \"\"\"Extract JAS seasonal averages from monthly data\"\"\"\n",
    "    # Get month numbers\n",
    "    months = data.time.dt.month\n",
    "\n",
    "    # Create mask for JAS months (7, 8, 9)\n",
    "    jas_mask = (months >= 7) & (months <= 9)\n",
    "\n",
    "    # Select JAS months\n",
    "    jas_data = data.isel(time=jas_mask)\n",
    "\n",
    "    # Group by year and compute mean for each JAS season\n",
    "    jas_yearly = jas_data.groupby(\"time.year\").mean(\"time\")\n",
    "\n",
    "    return jas_yearly\n",
    "\n",
    "\n",
    "def make_cb_range(amp, delta):\n",
    "    \"\"\"Make colorbar_range for cmo.balance\n",
    "    Args:\n",
    "        - 'amp': amplitude of maximum value for colorbar\n",
    "        - 'delta': increment for colorbar\n",
    "    \"\"\"\n",
    "    return np.concatenate(\n",
    "        [np.arange(-amp, 0, delta), np.arange(delta, amp + delta, delta)]\n",
    "    )\n",
    "\n",
    "\n",
    "def get_trend(data, dim=\"time\", deg=1):\n",
    "    \"\"\"\n",
    "    Get trend for an xr.dataarray along specified dimension,\n",
    "    by fitting polynomial of degree 'deg'.\n",
    "    \"\"\"\n",
    "\n",
    "    ## Get coefficients for best fit\n",
    "    polyfit_coefs = data.polyfit(dim=dim, deg=deg)[\"polyfit_coefficients\"]\n",
    "\n",
    "    ## Get best fit line (linear trend in this case)\n",
    "    trend = xr.polyval(data[dim], polyfit_coefs)\n",
    "\n",
    "    return trend\n",
    "\n",
    "\n",
    "def detrend(data, dim=\"time\", deg=1):\n",
    "    \"\"\"\n",
    "    Remove trend of degree 'deg' from data, along dimension 'dim'.\n",
    "    \"\"\"\n",
    "\n",
    "    return data - get_trend(data, dim=dim, deg=deg)\n",
    "\n",
    "\n",
    "def detrend_by_month(data, deg=1):\n",
    "    \"\"\"\n",
    "    Remove trend of degree \"deg\" from data along \"dim\", for each month separately\n",
    "    \"\"\"\n",
    "\n",
    "    return data.groupby(\"time.month\").map(detrend, dim=\"time\", deg=deg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d36f8b-1591-440f-bef6-09fe7cf6a75c",
   "metadata": {},
   "source": [
    "### 1. Timeseries of $T_{wh}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0b2506-9815-441e-8f67-796176f36334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute T_wh for both datasets\n",
    "print(\"Computing Woods Hole temperature index...\")\n",
    "t_wh_era5 = compute_T_wh(era5_data)\n",
    "t_wh_cesm = compute_T_wh(cesm_data)\n",
    "\n",
    "# Select time period 1979-2006 first\n",
    "t_wh_era5_1979_2006 = t_wh_era5.sel(time=slice(\"1979-01-01\", \"2006-12-31\"))\n",
    "t_wh_cesm_1979_2006 = t_wh_cesm.sel(time=slice(\"1979-01-01\", \"2006-12-31\"))\n",
    "\n",
    "# Compute JAS averages for both datasets\n",
    "era5_jas = get_jas_averages(t_wh_era5_1979_2006)\n",
    "cesm_jas = get_jas_averages(t_wh_cesm_1979_2006)\n",
    "\n",
    "# Create timeseries plot\n",
    "plt.figure(figsize=(5, 3), layout=\"constrained\")\n",
    "plt.plot(\n",
    "    era5_jas.year,\n",
    "    era5_jas.values,\n",
    "    \"b-o\",\n",
    "    linewidth=2,\n",
    "    markersize=6,\n",
    "    alpha=0.8,\n",
    "    label=\"ERA5\",\n",
    ")\n",
    "plt.plot(\n",
    "    cesm_jas.year,\n",
    "    cesm_jas.values,\n",
    "    \"r-s\",\n",
    "    linewidth=2,\n",
    "    markersize=6,\n",
    "    alpha=0.8,\n",
    "    label=\"CESM\",\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"JAS Temperature (°C)\")\n",
    "plt.title(\"Woods Hole Temperature Index (JAS season; 1979-2006)\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# ## save to file\n",
    "# plt.savefig(\"figs/timeseries.svg\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Print some statistics\n",
    "print(f\"\\nERA5 JAS statistics (1979-2006):\")\n",
    "print(f\"  Mean: {era5_jas.mean().values:.2f}°C\")\n",
    "print(f\"  Std:  {era5_jas.std().values:.2f}°C\")\n",
    "print(f\"  Min:  {era5_jas.min().values:.2f}°C\")\n",
    "print(f\"  Max:  {era5_jas.max().values:.2f}°C\")\n",
    "\n",
    "print(f\"\\nCESM JAS statistics (1979-2006):\")\n",
    "print(f\"  Mean: {cesm_jas.mean().values:.2f}°C\")\n",
    "print(f\"  Std:  {cesm_jas.std().values:.2f}°C\")\n",
    "print(f\"  Min:  {cesm_jas.min().values:.2f}°C\")\n",
    "print(f\"  Max:  {cesm_jas.max().values:.2f}°C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02883804-5a11-4886-a421-6c628035aecf",
   "metadata": {},
   "source": [
    "### 2. Histogram of $T_{wh}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db866c3-3abf-45b0-b6f7-1f1ba3688888",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocess: remove linear trend\n",
    "cesm_detrend = detrend_by_month(t_wh_cesm_1979_2006)\n",
    "era5_detrend = detrend_by_month(t_wh_era5_1979_2006)\n",
    "\n",
    "## Compute histograms\n",
    "if LOAD_FROM_CLOUD:\n",
    "    edges = np.arange(-4.5, 4.5, 0.5) + 0.25\n",
    "else:\n",
    "    edges = np.arange(-2.4, 2.4, 0.3) + 0.15\n",
    "\n",
    "pdf_era5, _ = get_empirical_pdf(era5_detrend, bin_edges=edges)\n",
    "pdf_cesm, _ = get_empirical_pdf(cesm_detrend, bin_edges=edges)\n",
    "\n",
    "#### Plot result\n",
    "fig, ax = plt.subplots(figsize=(3, 2.5), layout=\"constrained\")\n",
    "\n",
    "## plot histogram\n",
    "ax.stairs(values=pdf_era5, edges=edges, label=\"ERA5\", fill=True, alpha=0.3)\n",
    "ax.stairs(values=pdf_cesm, edges=edges, label=\"CESM\")\n",
    "\n",
    "\n",
    "## plot zero line\n",
    "ax.axvline(0, ls=\"--\", c=\"k\", lw=0.8)\n",
    "\n",
    "## label\n",
    "ax.set_xlabel(r\"$K$ anomaly\")\n",
    "ax.set_ylabel(\"Prob. density\")\n",
    "\n",
    "ax.legend(prop=dict(size=8))\n",
    "\n",
    "# ## save to file\n",
    "# fig.savefig(\"figs/histogram.svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d8ee7e-9697-43fb-97e5-585ee320eb47",
   "metadata": {},
   "source": [
    "### 3. Spatial bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5ca060-057e-44b0-b238-68f496b85cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align datasets to common time period (1979-2006)\n",
    "era5_common = era5_data.sel(time=slice(\"1979-01-01\", \"2006-12-31\"))\n",
    "cesm_common = cesm_data.sel(time=slice(\"1979-01-01\", \"2006-12-31\"))\n",
    "\n",
    "# Compute JAS averages for both datasets\n",
    "era5_jas_mean = get_jas_averages(era5_common).mean(\"year\")\n",
    "cesm_jas_mean = get_jas_averages(cesm_common).mean(\"year\")\n",
    "\n",
    "# Compute error (ERA5 - CESM)\n",
    "error = cesm_jas_mean - era5_jas_mean\n",
    "\n",
    "# Create spatial error plot with shared colorbar\n",
    "fig = plt.figure(figsize=(20, 6))\n",
    "\n",
    "# Create GridSpec for better control of subplot layout\n",
    "gs = fig.add_gridspec(1, 4, width_ratios=[1, 1, 1, 0.1], wspace=0.3)\n",
    "\n",
    "# ERA5 mean\n",
    "ax1 = fig.add_subplot(gs[0], projection=ccrs.PlateCarree())\n",
    "im1 = ax1.contourf(\n",
    "    era5_jas_mean.longitude,\n",
    "    era5_jas_mean.latitude,\n",
    "    era5_jas_mean.values,\n",
    "    levels=np.arange(-3, 33, 3),\n",
    "    cmap=\"cmo.thermal\",\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "ax1.set_title(\"ERA5 Mean Temperature (1979-2006)\")\n",
    "ax1.coastlines()\n",
    "\n",
    "# CESM mean\n",
    "ax2 = fig.add_subplot(gs[1], projection=ccrs.PlateCarree())\n",
    "im2 = ax2.contourf(\n",
    "    cesm_jas_mean.longitude,\n",
    "    cesm_jas_mean.latitude,\n",
    "    cesm_jas_mean.values,\n",
    "    levels=np.arange(-3, 33, 3),\n",
    "    cmap=\"cmo.thermal\",\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "ax2.set_title(\"CESM Mean Temperature (1979-2006)\")\n",
    "ax2.coastlines()\n",
    "\n",
    "# Error (CESM - ERA5)\n",
    "ax3 = fig.add_subplot(gs[2], projection=ccrs.PlateCarree())\n",
    "im3 = ax3.contourf(\n",
    "    error.longitude,\n",
    "    error.latitude,\n",
    "    error.values,\n",
    "    levels=make_cb_range(5, 0.5),\n",
    "    cmap=\"cmo.balance\",\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "ax3.set_title(\"Error: CESM - ERA5\")\n",
    "ax3.coastlines()\n",
    "\n",
    "# Shared colorbar for ERA5 and CESM (left side)\n",
    "cbar_ax1 = fig.add_axes([0.05, 0.25, 0.02, 0.5])  # [left, bottom, width, height]\n",
    "cbar1 = plt.colorbar(im1, cax=cbar_ax1, orientation=\"vertical\")\n",
    "cbar1.set_label(\"Temperature (°C)\")\n",
    "\n",
    "# Separate colorbar for error (right side)\n",
    "cbar_ax2 = fig.add_axes([0.85, 0.25, 0.02, 0.5])  # [left, bottom, width, height]\n",
    "cbar2 = plt.colorbar(im3, cax=cbar_ax2, orientation=\"vertical\")\n",
    "cbar2.set_label(\"Temperature Difference (°C)\")\n",
    "\n",
    "# ## save to file\n",
    "# fig.savefig(\"figs/spatial-bias.svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a228f1fc-40a2-4297-b16e-4dd749e4f430",
   "metadata": {},
   "source": [
    "The mean temperature plots look fairly similar; however, the error plot reveals some differences between the datasets.\n",
    "\n",
    "***Note:*** The errors differ for the server/cloud (sst/2m atmospheric temp) data sets. If you are able it is worth reading in both to have a look at the differeces. \n",
    "\n",
    "***Potential extension***: How does this error behave for another region or variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df51887a-f34f-40c4-87b7-0b3fe3868ba5",
   "metadata": {},
   "source": [
    "### 4. Histogram of gridcell-level bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968de3f2-0c84-48e0-8dac-3ec9b1d633ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Cape Cod region (similar to Woods Hole but slightly larger)\n",
    "# Cape Cod roughly: lon 287-295, lat 40-43\n",
    "wh_lon = slice(287.5, 293.5)\n",
    "wh_lat = slice(39, 44)\n",
    "\n",
    "# Extract Cape Cod subset\n",
    "error_wh = error.sel(longitude=wh_lon, latitude=wh_lat)\n",
    "\n",
    "# Flatten both datasets\n",
    "error_flat = error.values.flatten()\n",
    "error_wh_flat = error_wh.values.flatten()\n",
    "\n",
    "# Remove NaN values\n",
    "error_flat = error_flat[~np.isnan(error_flat)]\n",
    "error_wh_flat = error_wh_flat[~np.isnan(error_wh_flat)]\n",
    "\n",
    "# Create bin edges for both histograms (use same range for comparison)\n",
    "all_errors = np.concatenate([error_flat, error_wh_flat])\n",
    "bin_edges = np.linspace(all_errors.min(), all_errors.max(), 50)\n",
    "\n",
    "# Compute PDFs using your get_empirical_pdf function\n",
    "error_pdf, error_edges = get_empirical_pdf(error_flat, bin_edges=bin_edges)\n",
    "error_wh_pdf, error_wh_edges = get_empirical_pdf(error_wh_flat, bin_edges=bin_edges)\n",
    "\n",
    "# Compute Gaussian fits\n",
    "error_gauss, error_gauss_pts = get_gaussian_best_fit(error_flat)\n",
    "error_cape_cod_gauss, error_cape_cod_gauss_pts = get_gaussian_best_fit(error_wh_flat)\n",
    "\n",
    "# Create subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot 1: Whole Region\n",
    "ax1.stairs(\n",
    "    values=error_pdf,\n",
    "    edges=error_edges,\n",
    "    color=\"blue\",\n",
    "    alpha=0.7,\n",
    "    label=\"Whole Region\",\n",
    "    linewidth=2,\n",
    ")\n",
    "ax1.plot(\n",
    "    error_gauss_pts, error_gauss, \"b--\", linewidth=1.5, alpha=0.8, label=\"Gaussian Fit\"\n",
    ")\n",
    "ax1.set_xlabel(\"Temperature Error (°C)\")\n",
    "ax1.set_ylabel(\"Probability Density\")\n",
    "ax1.set_title(\"Error Distribution: Whole Region (CESM - ERA5)\")\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Cape Cod Region\n",
    "ax2.stairs(\n",
    "    values=error_wh_pdf,\n",
    "    edges=error_wh_edges,\n",
    "    color=\"red\",\n",
    "    alpha=0.7,\n",
    "    label=\"Cape Cod Region\",\n",
    "    linewidth=2,\n",
    ")\n",
    "ax2.plot(\n",
    "    error_cape_cod_gauss_pts,\n",
    "    error_cape_cod_gauss,\n",
    "    \"r--\",\n",
    "    linewidth=1.5,\n",
    "    alpha=0.8,\n",
    "    label=\"Gaussian Fit\",\n",
    ")\n",
    "ax2.set_xlabel(\"Temperature Error (°C)\")\n",
    "ax2.set_ylabel(\"Probability Density\")\n",
    "ax2.set_title(\"Error Distribution: Cape Cod Region (CESM - ERA5)\")\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023a2aef-1334-461b-b04a-721e0b59a9b6",
   "metadata": {},
   "source": [
    "What do you think are reasons for the bias? Try plotting the data set without applying the contours (ie make a more simple plot than we did above–you can use xarray's built in plotting command ds.plot() )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
